# 操作

[官方文档](https://clickhouse.tech/docs/en/sql-reference/statements/select/)

## 登录退出

登录

```sql
clickhouse-client -mn --password=xxx
```

退出

```
exit
```

## 对用户操作

创建账号

```sql
SHOW USERS

SHOW CREATE USER [name1 [, name2 ...] | CURRENT_USER]


# 创建账号
CREATE USER [IF NOT EXISTS | OR REPLACE] name1 [ON CLUSTER cluster_name1] 
        [, name2 [ON CLUSTER cluster_name2] ...]
    [NOT IDENTIFIED | IDENTIFIED {[WITH {no_password | plaintext_password | sha256_password | sha256_hash | double_sha1_password | double_sha1_hash}] BY {'password' | 'hash'}} | {WITH ldap SERVER 'server_name'} | {WITH kerberos [REALM 'realm']}]
    [HOST {LOCAL | NAME 'name' | REGEXP 'name_regexp' | IP 'address' | LIKE 'pattern'} [,...] | ANY | NONE]
    [DEFAULT ROLE role [,...]]
    [GRANTEES {user | role | ANY | NONE} [,...] [EXCEPT {user | role} [,...]]]
    [SETTINGS variable [= value] [MIN [=] min_value] [MAX [=] max_value] [READONLY | WRITABLE] | PROFILE 'profile_name'] [,...]

# 创建账号密码
CREATE USER mira HOST IP '127.0.0.1' IDENTIFIED WITH sha256_password BY 'qwerty';
# 设置账号角色
CREATE USER john DEFAULT ROLE role1, role2;
CREATE USER john DEFAULT ROLE ALL;
CREATE USER john DEFAULT ROLE ALL EXCEPT role1, role2;
# 创建账号并授权给jack
CREATE USER john GRANTEES jack;
```

设置角色

```sql
SHOW [CURRENT|ENABLED] ROLES

SHOW CREATE ROLE name1 [, name2 ...]

# 设置角色
SET DEFAULT ROLE {NONE | role [,...] | ALL | ALL EXCEPT role [,...]} TO {user|CURRENT_USER} [,...]

SET DEFAULT ROLE role1, role2, ... TO user
SET DEFAULT ROLE ALL TO user
SET DEFAULT ROLE NONE TO user
SET DEFAULT ROLE ALL EXCEPT role1, role2 TO user
```

赋权

```sql
SHOW GRANTS [FOR user1 [, user2 ...]]

GRANT [ON CLUSTER cluster_name] privilege[(column_name [,...])] [,...] ON {db.table|db.*|*.*|table|*} TO {user | role | CURRENT_USER} [,...] [WITH GRANT OPTION]

GRANT [ON CLUSTER cluster_name] role [,...] TO {user | another_role | CURRENT_USER} [,...] [WITH ADMIN OPTION]

```

删除

```sql
DROP USER [IF EXISTS] name [,...] [ON CLUSTER cluster_name]

DROP ROLE [IF EXISTS] name [,...] [ON CLUSTER cluster_name]
```

## 数据库操作

```sql
SHOW DATABASES [LIKE | ILIKE | NOT LIKE '<pattern>'] [LIMIT <N>] [INTO OUTFILE filename] [FORMAT format]

SHOW CREATE [TEMPORARY] [TABLE|DICTIONARY] [db.]table [INTO OUTFILE filename] [FORMAT format]

# 查看所有数据库
show databases;
# 查看创建数据库的语句
show create database demo;
# 切换数据库
use xxx;
# 显示数据库版本
select version();
# 显示时间
select now();
# 查看当前使用得数据库
select database();

# 创建数据库
CREATE DATABASE [IF NOT EXISTS] db_name [ON CLUSTER cluster] [ENGINE = engine(...)]

create database tutorial;  # 默认使用Atomic引擎
create database if not exists tutorial;
create database if not exists temp_db ENGINE = Memory;

# 重命名
RENAME DATABASE atomic_database1 TO atomic_database2 [ON CLUSTER cluster]

# 删除数据库
DROP DATABASE [IF EXISTS] db [ON CLUSTER cluster]
```

## 数据表操作

### 创建

```sql
# 基本语法
CREATE [TEMPORARY] TABLE [IF NOT EXISTS] [db.]name
(
 name1 [type1] [DEFAULT | MATERIALIZED | ALIAS expr1],
 name2 [type2] [DEFAULT | MATERIALIZED | ALIAS expr2],
 ...
) ENGINE = engine

# 创建一个跟指定表完全一样的表，但是可以更换不同的引擎。
CREATE [TEMPORARY] TABLE [IF NOT EXISTS] [db.]name AS [db2.]name2 [ENGINE = engine]
 
# 建表并填充，表字段会自动根据 SELECT 的返回内容设置，并且，返回内容会作为新表内容填充进去。
CREATE [TEMPORARY] TABLE [IF NOT EXISTS] [db.]name ENGINE = engine AS SELECT * FROM [db2.]name2
```

MergeTree
```sql
create table if not exists test.tb_test(
    id Int64,
    datetime DateTime,
    content Nullable(String),
    value Nullable(Float64),
    date Date
)
ENGINE = MergeTree                  # 使用mergeTree引擎，ch主要引擎
partition by toYYYYMM(datetime)     # 按照datetime这个字段的月进行分区
order by id                         # 按照id进行排序，使用MergeTree表引擎时，数据在各个分区内，按照指定规则进行排序，是一种分区内的局部排序。在没有PRIMARY KEY 语句时，MergeTree表引擎使用ORDER BY 语句中定义的排序键（sorting key）作为表的主键。
TTL datetime + INTERVAL 3 DAY ;     # 三天过期
```
SummingMergeTree

```sql
CREATE TABLE IF NOT EXISTS tb_stat(
    regionId String,    # 门店id
    groupId String,     # 统计组id
    in int,             # 进客流
    out int,            # 出客流
    statDate DateTime   # 统计时间
)
ENGINE = SummingMergeTree
partition by (toYYYYMM(statDate), regionId)
ORDER BY (toStartOfHour(statDate), regionId, groupId);

insert into tb_stat values ('1232364', '111',  32, 2,  '2020-03-25 12:56:00');
insert into tb_stat values ('1232364', '111',  34, 44, '2020-03-25 12:21:00');
insert into tb_stat values ('1232364', '111',  54, 12, '2020-03-25 12:20:00');
insert into tb_stat values ('1232364', '222',  45, 11, '2020-03-25 12:13:00');
insert into tb_stat values ('1232364', '222',  32, 33, '2020-03-25 12:44:00');
insert into tb_stat values ('1232364', '222',  12, 23, '2020-03-25 12:22:00');
insert into tb_stat values ('1232364', '333',  54, 54, '2020-03-25 12:11:00');
insert into tb_stat values ('1232364', '333',  22, 74, '2020-03-25 12:55:00');
insert into tb_stat values ('1232364', '333',  12, 15, '2020-03-25 12:34:00');

select toStartOfHour(statDate), regionId, groupId, sum(in), sum(out)
from tb_stat group by toStartOfHour(statDate), regionId, groupId;
```

Merge

```sql
create t1 (id UInt16, name String) ENGINE=TinyLog;
create t2 (id UInt16, name String) ENGINE=TinyLog;
create t3 (id UInt16, name String) ENGINE=TinyLog;

insert into t1(id, name) values (1, 'first');
insert into t2(id, name) values (2, 'xxxx');
insert into t3(id, name) values (12, 'i am in t3');

create table t (id UInt16, name String) ENGINE=Merge(currentDatabase(), '^t');

select _table,* from t order by id desc;
```

Distributed

```sql
# 默认情况下，CREATE、DROP、ALTER、RENAME操作仅仅在当前执行该命令的server上生效。在集群环境下，可以使用ON CLUSTER语句，这样就可以在整个集群发挥作用。
# 创建分布式表
CREATE TABLE IF NOT EXISTS user_cluster ON CLUSTER cluster_3shards_1replicas
(
    id Int32,
    name String
)ENGINE = Distributed(cluster_3shards_1replicas, default, user_local,id);

# 参数
"""
cluster_name：集群名称，与集群配置中的自定义名称相对应。
database_name：数据库名称
table_name：表名称
sharding_key：可选的，用于分片的key值，在数据写入的过程中，分布式表会依据分片key的规则，将数据分布到各个节点的本地表。
"""

# 创建本地表
CREATE TABLE IF NOT EXISTS user_local (
    id Int32,
    name String
)
ENGINE = MergeTree()
ORDER BY id
PARTITION BY id
PRIMARY KEY id;

# 有两台服务器cdh04,cdh05组成集群
# 在cdh04对user_local插入数据
INSERT INTO user_local VALUES(1,'tom'),(2,'jack');
# 查询user_cluster，发现同步了数据，通过user_cluster表可以操作所有的user_local表
select * from user_cluster;  
# 向user_cluster中插入一些数据
INSERT INTO user_cluster VALUES(3,'lilei'),(4,'lihua');
select * from user_cluster;
# 查询cdh04的user_local，发现有一部分user_cluster
select * from user_local;
# 查询cdh05的user_local，发现有一部分user_cluster，与cdh04共同组成了user_cluster
select * from user_local;
```

### 修改

```sql
# 重命名表
RENAME TABLE [db11.]name11 TO [db12.]name12, [db21.]name21 TO [db22.]name22, ... [ON CLUSTER cluster]

# 修改表中列
ALTER TABLE [db].name [ON CLUSTER cluster] ADD|DROP|CLEAR|COMMENT|MODIFY COLUMN ...

# 增加列
ALTER TABLE alter_test ADD COLUMN Added1 UInt32 FIRST;
ALTER TABLE alter_test ADD COLUMN Added2 UInt32 AFTER NestedColumn;
ALTER TABLE alter_test ADD COLUMN Added3 UInt32 AFTER ToDrop;
DESC alter_test FORMAT TSV;

# 删除分区，可用于定时任务删除旧数据
alter table tb_test drop partition '202005';
# 删除列
ALTER TABLE visits DROP COLUMN browser


# 修改列名
ALTER TABLE visits RENAME COLUMN webBrowser TO browser
# 清空列数据
ALTER TABLE visits CLEAR COLUMN browser IN PARTITION tuple()
# 备注
ALTER TABLE visits COMMENT COLUMN browser 'The table shows the browser used for accessing the site.'
# 修改列
ALTER TABLE visits MODIFY COLUMN browser Array(String)
ALTER TABLE table_with_ttl MODIFY COLUMN column_ttl REMOVE TTL;

# 修改表中数据过期时间，到期后数据会在merge时被删除
ALTER TABLE test.tb_test
MODIFY TTL datetime + INTERVAL 1 DAY;


# 删除表
DROP [TEMPORARY] TABLE [IF EXISTS] [db.]name [ON CLUSTER cluster]

drop table employee;
drop table tutorial.employee;
```

### 分区

按时间分区

```
toYYYYMM(EventDate)：按月分区
toMonday(EventDate)：按周分区
toDate(EventDate)：按天分区
```

按指定列分区

```
PARTITION BY cloumn_name
```

对分区的操作

```sql
alter table test1 DROP PARTITION [partition]   #删除分区
alter table test1 DETACH PARTITION [partition]	#下线分区
alter table test1 ATTACH PARTITION [partition]	#恢复分区
alter table .test1 FREEZE PARTITION [partition]	#备份分区
```

### 查看

```sql
SHOW [TEMPORARY] TABLES [{FROM | IN} <db>] [LIKE | ILIKE | NOT LIKE '<pattern>'] [LIMIT <N>] [INTO OUTFILE <filename>] [FORMAT <format>]

SHOW CREATE [TEMPORARY] [TABLE|DICTIONARY] [db.]table [INTO OUTFILE filename] [FORMAT format]

# 查看数据库下所有表
show tables;

# 查看表详情
DESC|DESCRIBE TABLE [db.]table [INTO OUTFILE filename] [FORMAT format]

desc table employee;
desc table tutorial.employee;

# 查看创建表的语句
show create table employe;
show create table tutorial.employee;

# 查一张表的列名
select distinct name from system.columns where database='xxx' and table='xxx';
```

## 数据操作

### 增

```sql
# values
INSERT INTO [db.]table [(c1, c2, c3)] VALUES (v11, v12, v13), (v21, v22, v23), ...

CREATE TABLE insert_select_testtable(
    `a` Int8,
    `b` String,
    `c` Int8
)ENGINE = MergeTree()
ORDER BY a

INSERT INTO insert_select_testtable VALUES (1, 'a', 1) ;
INSERT INTO insert_select_testtable (*) VALUES (1, 'a', 1) ;
INSERT INTO insert_select_testtable (* EXCEPT(b)) VALUES (1, 1) ;

# format
INSERT INTO [db.]table [(c1, c2, c3)] FORMAT format_name data_set
INSERT INTO [db.]table [(c1, c2, c3)] FORMAT Values (v11, v12, v13), (v21, v22, v23), ...

# 查询子句
INSERT INTO [db.]table [(c1, c2, c3)] SELECT ...
```

### 改

```sql
# 修改数据，不推荐使用
alter table tb_test update content = 'hello click' where id=52;

# 删除数据，不推荐使用
alter table tb_test delete WHERE id=56;
```

### 查

查询语法

```sql
[WITH expr_list|(subquery)]
SELECT [DISTINCT] expr_list
[FROM [db.]table | (subquery) | table_function] [FINAL]
[SAMPLE sample_coeff]
[ARRAY JOIN ...]
[GLOBAL] [ANY|ALL|ASOF] [INNER|LEFT|RIGHT|FULL|CROSS] [OUTER|SEMI|ANTI] JOIN (subquery)|table (ON <expr_list>)|(USING <column_list>)
[PREWHERE expr]
[WHERE expr]
[GROUP BY expr_list] [WITH TOTALS]
[HAVING expr]
[ORDER BY expr_list] [WITH FILL] [FROM expr] [TO expr] [STEP expr]
[LIMIT [offset_value, ]n BY columns]
[LIMIT [n, ]m] [WITH TIES]
[UNION ALL ...]
[INTO OUTFILE filename]
[FORMAT format]
```

ClickHouse的SELECT语句的语法和通用的SQL的SELECT语句非常类似

```sql
SELECT: 指定返回结果字段
DISTINCT：去重
FROM: 指定要查询的表或子查询
JOIN：表连接，支持内连接和外连接、左连接和右连接
WHERE：筛选条件
GROUP BY：分组，和聚合函数一起使用
HAVING：分组后筛选
ORDER BY：排序
LIMIT：限制返回记录数
UNION ALL：并集；ClickHouse目前只支持UNION ALL，还不支持UNION
```

ClickHouse的SELECT语句中也有一些特殊的用法：

```sql
WITH: 设置查询中要用到的变量
SAMPLE: 数据取样，类似Pandas库的sample()函数
PREWHERE: 预筛选，起到提升性能作用
ARRAY JOIN：数组连接，用来展开数组或嵌套字段，一行变多行
LIMIT BY: 分组，再从每组中取前n条记录
INTO OUTFILE: 到处表数据到文件，再用FORMAT指定文件格式
```

#### 字符串拼接

```sql
concat(name, '+', id)  # 可对不同的列进行拼接
groupArray(column_name)  # 对同一列的行值组成列表
arrayStringConcat(arrayList, '-') # 对字符串组成的列表，按照分隔符（默认逗号）进行拼接，返回字符串   
groupUniqArray(column_name)  # 对同一列的行值进行去重，组成列表
```

示例

```sql
select platform, arrayStringConcat(groupArray(concat(platform_name, '-+-',mall_name)),'+-+') as info from t_hub_analyze_stock_mall group by platform;


SELECT 
    emp_no,
    groupArray(performance) AS kpi_asc,   # ['A','A','C','B','A','A']
    arrayStringConcat(kpi_asc, '-') AS kpi_list,   # A-A-C-B-A-A 
    arrayReverse(kpi_asc) AS kpi_desc,  # ['A','A','B','C','A','A']
    groupUniqArray(performance) AS kpis,  # ['B','A','C'] 
    arraySort(kpis) AS kpi_uniq,  # ['A','B','C'] 
    countEqual(kpi_asc, 'A') AS A_cnt,
    countEqual(kpi_asc, 'B') AS B_cnt,
    countEqual(kpi_asc, 'C') AS C_cnt,
    countEqual(kpi_asc, 'D') AS D_cnt
FROM kpi
GROUP BY emp_no
ORDER BY emp_no ASC;
```

#### WITH

```sql
# 在WITH子句中定义一个变量并赋值，然后在SELECT子句中通过别名使用该变量
WITH '2019-08-01 15:23:00' as ts_upper_bound
SELECT *
FROM hits
WHERE
    EventDate = toDate(ts_upper_bound) AND
    EventTime <= ts_upper_bound;

# 从SELECT子句列列表中取出sum(bytes)表达式结果
WITH sum(bytes) as s
SELECT
    formatReadableSize(s),
    table
FROM system.parts
GROUP BY table
ORDER BY s;

# 在WITH子句中定义一个子查询，然后在SELECT子句中通过别名使用该子查询
/* this example would return TOP 10 of most huge tables */
WITH
    (
        SELECT sum(bytes)
        FROM system.parts
        WHERE active
    ) AS total_disk_usage
SELECT
    (sum(bytes) / total_disk_usage) * 100 AS table_disk_usage,
    table
FROM system.parts
GROUP BY table
ORDER BY table_disk_usage DESC
LIMIT 10;

# 在子句中重用表达式
WITH test1 AS (SELECT i + 1, j + 1 FROM test1) 
SELECT * FROM test1;
```

#### SAMPLE

对使用了MergeTree表引擎的表，并且设置了SAMPLE BY的表，可以使用SAMPLE子句来对数据进行抽样。

表

```sql
CREATE TABLE tutorial.hits_v1 \ 
( 
  ...
)
ENGINE = MergeTree() \ 
PARTITION BY toYYYYMM(EventDate) \ 
ORDER BY (CounterID, EventDate, intHash32(UserID)) \ 
SAMPLE BY intHash32(UserID) \ 
SETTINGS index_granularity = 8192;
```

SAMPLE子句分为：

| 分类               | 语法                | 描述                                                         |
| ------------------ | ------------------- | ------------------------------------------------------------ |
| 按比例采样         | `SAMPLE k`          | k值为0到1，比如k为0.1时表示采样10%的表数据。                 |
| 按记录数采样       | `SAMPLE n`          | n为一个足够大的数，一般大于索引粒度index_granularity； n较小时，采样结果数据可能为0条记录。 |
| 按比例和偏移量采样 | `SAMPLE k OFFSET m` | k值为0到1，比如k为0.1时表示采样10%的表数据。 m值为0到1，比如0.3表示从从后面70%的表数据中采样。 |

SAMPLE子句数据采样具有幂等性和近似性的特点：

- 幂等性：采样条件不变时，两次采样的结果**可能**一样
- 近似性：采样范围和采样结果不保证精确

查询

```sql
-- 按比例采样
-- 采样结果记录数
select count(1) from hits_v1 sample 0.1
-- 采样数据，默认限制返回10000条
select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 0.1
-- 采样数据，限制返回10条
select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 0.1 limit 10


-- 按记录数采样
-- 采样记录数较小时，采样结果数据为0条
select count(1) from hits_v1 sample 100
-- 采样记录数大过索引粒度时，采样结果数据记录数接近采样记录数
elect count(1) from hits_v1 sample 10000
-- 采样数据，默认限制返回10000条
select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 20000
-- 采样数据，限制返回10条
select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 20000 limit 10


-- 按比例和偏移量采样，类似于按比例采样
select CounterID, UserID, EventDate, EventTime  from hits_v1 sample 0.1 offset 0.3 limit 10
```

#### PREWHERE

只有MergeTree表引擎的表才能使用PREWHERE子句，可以将PREWHERE看作是ClickHouse对WHERE子句的优化。

ClickHouse默认将WHERE自动优化为PREWHERE:

```sql
-- optimize_move_to_prewhere为1时，表示开始PREWHERE自动优化
select name, value from system.settings where name like '%prewhere%'
```

#### ARRAY JOIN

可以用ARRAY JOIN子句来对数组（Array）或嵌套（Nested）类型做链接查询，可以将一行数组展成多行。

数组

```sql
# 创建数据
CREATE TABLE arrays_test
(
    s String,
    arr Array(UInt8)
) ENGINE = Memory;

INSERT INTO arrays_test
VALUES ('Hello', [1,2]), ('World', [3,4,5]), ('Goodbye', []);

# 查询
SELECT s, arr FROM arrays_test ARRAY JOIN arr; 
SELECT s, arr FROM arrays_test LEFT ARRAY JOIN arr;
```

别名

```sql
SELECT s, arr, a FROM arrays_test ARRAY JOIN arr AS a;

SELECT s, arr_external
FROM arrays_test
ARRAY JOIN [1, 2, 3] AS arr_external;

SELECT s, arr, a, num, mapped
FROM arrays_test
ARRAY JOIN arr AS a, arrayEnumerate(arr) AS num, arrayMap(x -> x + 1, arr) AS mapped;

SELECT s, arr, a, num, arrayEnumerate(arr)
FROM arrays_test
ARRAY JOIN arr AS a, arrayEnumerate(arr) AS num;
```

嵌套

```sql
# 创建数据
CREATE TABLE nested_test
(
    s String,
    nest Nested(
    x UInt8,
    y UInt32)
) ENGINE = Memory;

INSERT INTO nested_test
VALUES ('Hello', [1,2], [10,20]), ('World', [3,4,5], [30,40,50]), ('Goodbye', [], []);

# 查询
SELECT s, `nest.x`, `nest.y`
FROM nested_test
ARRAY JOIN nest;

SELECT s, `nest.x`, `nest.y`
FROM nested_test
ARRAY JOIN `nest.x`, `nest.y`;

SELECT s, `nest.x`, `nest.y`
FROM nested_test
ARRAY JOIN `nest.x`;

SELECT s, `n.x`, `n.y`, `nest.x`, `nest.y`
FROM nested_test
ARRAY JOIN nest AS n;

SELECT s, `n.x`, `n.y`, `nest.x`, `nest.y`, num
FROM nested_test
ARRAY JOIN nest AS n, arrayEnumerate(`nest.x`) AS num;

```

#### LIMIT BY

`LIMIT n BY expression` 对SELECT结果先按expression分组，再在每组里选出前n个，类似分类排行榜的概念。

```sql
# 创建数据
CREATE TABLE limit_by(id Int, val Int) ENGINE = Memory;
INSERT INTO limit_by VALUES (1, 10), (1, 11), (1, 12), (2, 20), (2, 21);

# 查询
SELECT * FROM limit_by ORDER BY id, val LIMIT 2 BY id

SELECT * FROM limit_by ORDER BY id, val LIMIT 1, 2 BY id  # 偏移
SELECT * FROM limit_by ORDER BY id, val LIMIT 2 OFFSET 1 BY id

SELECT
    domainWithoutWWW(URL) AS domain,
    domainWithoutWWW(REFERRER_URL) AS referrer,
    device_type,
    count() cnt
FROM hits
GROUP BY domain, referrer, device_type
ORDER BY cnt DESC
LIMIT 5 BY domain, device_type
LIMIT 100

```

#### INTO OUTFILE

```sql
-- 输出到当前目录
-- 默认格式为TSV
-- 注意文件名必须用单引号来括起来，且不能用双引号括起来，否则会报错：Expected string literal
-- 目录下不能存在同名文件，否则会报错
select WatchID, JavaEnable, EventDate  from hits_v1 limit 10 into outfile 'test.tsv'

-- 设置格式为CSV，CSV需要为全大小
select WatchID, JavaEnable, EventDate  from hits_v1 limit 10 into outfile 'out.csv' format CSV
```

## 视图

```sql
# 创建视图
# 普通
CREATE [OR REPLACE] VIEW [IF NOT EXISTS] [db.]table_name [ON CLUSTER] AS SELECT ...
# 物化
CREATE MATERIALIZED VIEW [IF NOT EXISTS] [db.]table_name [ON CLUSTER] [TO[db.]name] [ENGINE = engine] [POPULATE] AS SELECT ...

# 查询
SELECT a, b, c FROM view  # 等价于 SELECT a, b, c FROM (SELECT ...)

# 删除
DROP VIEW [IF EXISTS] [db.]name [ON CLUSTER cluster]
```

## 数据同步

- 交互式命令

```shell
# 在存放样本数据的当前目录，使用非交互式的clickhouse-client --query命令来导入数据到指定表中
clickhouse-client --query "INSERT INTO tutorial.hits_v1 FORMAT TSV" --max_insert_block_size=100000 < hits_v1.tsv

clickhouse-client --query "INSERT INTO tutorial.visits_v1 FORMAT TSV" --max_insert_block_size=100000 < visits_v1.tsv
```

- 分区拷贝

```sql
# DETACH/FREEZE分区，进行SCP拷贝，然后再ATTACH
alter table db.table DETACH PARTITION [partition];  	# 下线分区
alter table db.table FREEZE PARTITION [partition];   	# 备份分区
alter table db.table ATTACH PARTITION [partition];  	# 上线分区
```

- 采用remote函数
```sql
insert into db.table select * from remote('目标IP',db.table,'user','passwd')
```
- csv文件导入clickhouse
```sql
cat test.csv | clickhouse-client -u user --password password --query="INSERT INTO db.table FORMAT CSV"
```
- 同步mysql库中表
```sql
CREATE TABLE tmp ENGINE = MergeTree ORDER BY id AS SELECT * FROM mysql('hostip:3306', 'db', 'table', 'user', 'passwd') ;
```
- clickhouse-copier 工具

