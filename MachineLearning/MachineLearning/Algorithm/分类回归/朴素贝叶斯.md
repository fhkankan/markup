# 朴素贝叶斯

优缺点

```
# 优点
1.朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。
2.对缺失数据不太敏感，算法也比较简单，常用于文本分类。
3.分类准确度高，速度快
4.容易解释
5.可调参数非常少

# 缺点
1.需要知道先验概率P(F1,F2,…|C)，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳
```

适用场景

```
1.假设分布函数与数据匹配
2.各种类型的区分度很高，模型复杂度不重要
3.非常高维度的数据，模型复杂度不重要
```

## 原理

- 贝叶斯定理

$$
P(A|B)=\frac{P(A)P(B|A)}{P(B)}
$$

当事件(特征)相互独立时，贝叶斯准则转变为朴素贝叶斯，朴素贝叶斯是贝叶斯准则中的一种特殊情况。

在贝叶斯分类中，将事件A视为被分类标签，事件B视为数据特征。由于通常数据特征是$n$维向量，所以$P(B)$演变成了n个特征的联合概率。

在机器学习语境下，贝叶斯公式演化为
$$
P(y|x_1,x_2,\cdots,x_n) = \frac{P(y)P(x_1,\cdots,x_n|y)}{p(x_1,x_2,\cdots, x_n)}
$$
假如需要确定两种标签，定义为 $L_1,L_2$，一种方法就是计算这两个标签的后验概率的比值
$$
\frac{P(L_1|特征)}{P(L_2|特征)} = \frac{P(特征｜L_1)P(L_1)}{P(特征｜L_2)P(L_2)}
$$
现在需要一种模型，帮我们计算每个标签的 $P(特征|L_i)$。这种模型称为**生成模型**。因为它可以训练出生成数据的假设随机过程（或称为概率分布）。为每个标签生成模型是贝叶斯分类器训练过程的主要部分。虽然这个训练步骤通常很难做，但是可以通过对模型进行随机分布的假设，来简化训练工作。

- 参数求解

在给定输入数据x的条件下，它属于类别c的概率为
$$
p(c|x ) = \frac{p(x|c)*p(c)}{p(x)}
$$
贝叶斯的分类思想是，不直接求取$p(c|x)$，而是通过求取$p(x|c),p(c)$，利用条件概率公式来寻找最优分类。

在一般情况下，不需要考虑$p(x)$ 的值，因为对于同一个输入数据，$p(x)$ 的值是相同的。

贝叶斯分类的难点在于求取 $p(x|c)$，则要求取在条件c的条件下，输入属性值的联合分布，当输入属性很多时，计算量非常大，为此考虑这样一个假设，即输入数据的向量中，属性值时按类别条件独立，满足
$$
p(x|c) = p(x_1|c)*p(x_2|c)*\cdots p(x_n|c)
$$
要使用朴素贝叶斯模型进行分类，需要确定其参数，也就是求解$p(c_k),p(x_i|c_k)$。

设由m个训练数据构成的数据集D
$$
D = \{(x^1, y^1),(x^2, y^2),\cdots,(x^m, y^m)\}
$$
其中，
$$
x^i = (x_1^i, x_2^i,\cdots,x_n^i)\\
y^i \in \{c_1,c_2,\cdots,c_r\}\\
x_j^i \in \{a_1, a_2,\cdots, a_p\}
$$
$x^i$ 表示第i个样本数据的输入，$y^i$ 表示第i个样本数据的输出，$x_j^i$ 表示第i个样本数据的输入特征向量的第j个特征。

参数训练采用极大似然估计，也就是用训练的频率来估计概率。

对于$p(c_k)$这个先验概率，可以根据经验直接给出，或者自动计算：统计巡览数据中每个标签出现次数除以训练总数 
$$
p(c_k) = \frac{\sum_{i=1}^{m}1_{y^i=c_k}}{m}
$$
其中，$1_{y^i=c_k}$ 是一个指示函数，满足
$$
1_{y^i=c_k}=
\begin{cases}
1 & y^i=c_k\\
0 & y^i\ne c_k
\end{cases}
$$
对于$p(x_i|c_k)$ ，
$$
p(x_j^i=a_t|y^i=c_k) = \frac{\sum_{i=1}^{m}1_{y^i=c_k,x_j^i=a_t}}{\sum_{i=1}^{m}1_{y^i=c_k}}
$$

> 注意

使用朴素贝叶斯网络进行分类时，需要注意零概率问题，由于训练数据是有限的，因此极有可能出现 $p(x_i|c)=0$ 的情形，这时要用到平滑的策略来解决零概率问题。

## 分类

训练似然度条件概率中的元素$P(x_1|y),p(x_2|y)...$的方法是假定特征符合某种分布，然后通过训练集数据估计该分布的参数。之所以称为**朴素**，是因为如果对每种标签的生成模型进行非常简单的假设，就能找到每种类型生成模型的近似解，然后就可以使用贝叶斯分类。不同类型的朴素贝叶斯分类器是由对数据的不同假设决定的。

- 高斯朴素贝叶斯

假设每个标签的数据都服从简单的高斯分布，即正态分布。

- 多项式朴素贝叶斯

假设特征是由一个简单多项式分布生成。假设某事件的结果有k种可能，在实验了n次之后每种结果出现了若干次，多项式分布用于描述在实验了n次之后每种结果发生次数概率的分布。

由于其实际衡量的是特征在不同标签之间的分布比例关系，因此多项式朴素贝叶斯非常适合用于描述出现次数或者出现次数比例的特征，如文本分类。

- 伯努利朴素贝叶斯

使用伯努利分布作为似然度概率模型。所谓伯努利分布也称为二值分布，用来描述一次实验只能出现两种结果的事件概率分布。

## sklearn

### API

```python
# 高斯朴素贝叶斯
from sklearn.naive_bayes import GaussianNB
# 多项式朴素贝叶斯
from sklearn.naive_bayes import MultinomialNB
# 伯努利朴素贝叶斯
from sklearn.naive_bayes import BernoulliNB
```

- 拉普拉斯平滑

```python
由于样本数较少，会出现p(A|B)的概率为0，防止此情况出现，使用拉普莱斯平滑

拉普拉斯平滑系数ɑ, 默认为1
p=Ni/N    ---> p=(Ni+a)/(N+am)
m为训练文档中特征词个数，Ni为xi在分类ci下出现的次数，N为分类ci下词频总数。

MultinomialNB(alpha=0.1)
```

### 高斯朴素贝叶斯

示例1

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.naive_bayes import GaussianNB

X, y = make_blobs(100, 2, centers=2, random_state=2, cluster_std=1.5)
# plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')
# plt.show()
# 训练
model = GaussianNB()
model.fit(X, y)

# 预测新数据
rng = np.random.RandomState(0)
Xnew = [-6, -14] + [14, 18] * rng.rand(2000, 2)
ynew = model.predict(Xnew)

# 画图寻找决策边界的位置
plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')
lim = plt.axis()
plt.scatter(Xnew[:, 0], Xnew[:, 1], c=ynew, s=20, cmap='RdBu', alpha=0.1)
plt.axis(lim)
plt.show()

# 计算某个样本属于某个标签的概率
yprob = model.predict_proba(Xnew)
print(yprob[-8:].round(2))
# [[0.89 0.11]
#  [1.   0.  ]
#  [1.   0.  ]
#  [1.   0.  ]
#  [1.   0.  ]
#  [1.   0.  ]
#  [0.   1.  ]
#  [0.15 0.85]]
# 前两个标签的后验概率。若要评估分类器的不确定性，这类贝叶斯方法很有用
```

示例2

```python
from __future__ import print_function

import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import make_classification
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc


# For reproducibility
np.random.seed(1000)

nb_samples = 300


def show_dataset(X, Y):
    fig, ax = plt.subplots(1, 1, figsize=(30, 25))

    ax.grid()
    ax.set_xlabel('X')
    ax.set_ylabel('Y')

    for i in range(nb_samples):
        if Y[i] == 0:
            ax.scatter(X[i, 0], X[i, 1], marker='o', color='r')
        else:
            ax.scatter(X[i, 0], X[i, 1], marker='^', color='b')

    plt.show()


if __name__ == '__main__':
    # Create dataset
    X, Y = make_classification(n_samples=nb_samples, n_features=2, n_informative=2, n_redundant=0)

    # Show dataset
    show_dataset(X, Y)

    # Split dataset
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)

    # Create and train Gaussian Naive Bayes classifier
    gnb = GaussianNB()
    gnb.fit(X_train, Y_train)

    # Create and train a Logistic regressor (for comparison)
    lr = LogisticRegression()
    lr.fit(X_train, Y_train)

    # Compute ROC Curve
    Y_gnb_score = gnb.predict_proba(X_test)
    Y_lr_score = lr.decision_function(X_test)

    fpr_gnb, tpr_gnb, thresholds_gnb = roc_curve(Y_test, Y_gnb_score[:, 1])
    fpr_lr, tpr_lr, thresholds_lr = roc_curve(Y_test, Y_lr_score)

    # Plot ROC Curve
    plt.figure(figsize=(30, 25))

    plt.plot(fpr_gnb, tpr_gnb, color='red', label='Naive Bayes (AUC: %.2f)' % auc(fpr_gnb, tpr_gnb))
    plt.plot(fpr_lr, tpr_lr, color='green', label='Logistic Regression (AUC: %.2f)' % auc(fpr_lr, tpr_lr))
    plt.plot([0, 1], [0, 1], color='blue', linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.01])
    plt.title('ROC Curve')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc="lower right")

    plt.show()
```

### 多项式朴素贝叶斯

简单示例

```python
import numpy as np
from sklearn.feature_extraction import DictVectorizer
from sklearn.naive_bayes import MultinomialNB


# For reproducibility
np.random.seed(1000)


if __name__ == '__main__':
    # Prepare a dummy dataset
    data = [
        {'house': 100, 'street': 50, 'shop': 25, 'car': 100, 'tree': 20},
        {'house': 5, 'street': 5, 'shop': 0, 'car': 10, 'tree': 500, 'river': 1}
    ]

    # Create and train a dictionary vectorizer
    dv = DictVectorizer(sparse=False)
    X = dv.fit_transform(data)
    Y = np.array([1, 0])

    # Create and train a Multinomial Naive Bayes classifier
    mnb = MultinomialNB()
    mnb.fit(X, Y)

    # Create dummy test data
    test_data = data = [
        {'house': 80, 'street': 20, 'shop': 15, 'car': 70, 'tree': 10, 'river': 1},
        {'house': 10, 'street': 5, 'shop': 1, 'car': 8, 'tree': 300, 'river': 0}
    ]

    Yp = mnb.predict(dv.fit_transform(test_data))
    print(Yp)
```

用于文本分类

```python
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix

data = fetch_20newsgroups()
print(data.target_names)
# ['alt.atheism', 'comp.graphics', ..., 'talk.politics.misc', 'talk.religion.misc']

# 选择四类新闻，分割测试、训练集
categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics']
train = fetch_20newsgroups(subset='train', categories=categories)
test = fetch_20newsgroups(subset='test', categories=categories)

# 创建管道，将TF-IDF向量化同多项式朴素贝叶斯分类器组合
model = make_pipeline(TfidfVectorizer(), MultinomialNB())

# 训练数据
model.fit(train.data, train.target)
labels = model.predict(test.data)

# 评估评估器性能
# 使用混淆矩阵统计测试数据的真是标签与预测标签的结果
mat = confusion_matrix(test.target, labels)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
            xticklabels=train.target_names, yticklabels=train.target_names)
plt.xlabel('true label')
plt.ylabel('predicted label')
plt.show()


# 快速返回字符串的预测结果
def predict_category(s, train=train, model=model):
    pred = model.predict([s])
    return train.target_names[pred[0]]


res = predict_category('sending a payload to the ISS')
print(res)  # sci.space

```

### 伯努利朴素贝叶斯

```python
from __future__ import print_function

import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.naive_bayes import BernoulliNB


# For reproducibility
np.random.seed(1000)

nb_samples = 300


def show_dataset(X, Y):
    fig, ax = plt.subplots(1, 1, figsize=(30, 25))

    ax.grid()
    ax.set_xlabel('X')
    ax.set_ylabel('Y')

    for i in range(nb_samples):
        if Y[i] == 0:
            ax.scatter(X[i, 0], X[i, 1], marker='o', color='r')
        else:
            ax.scatter(X[i, 0], X[i, 1], marker='^', color='b')

    plt.show()


if __name__ == '__main__':
    # Create dataset
    X, Y = make_classification(n_samples=nb_samples, n_features=2, n_informative=2, n_redundant=0)

    # Show dataset
    show_dataset(X, Y)

    # Split dataset
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)

    # Create and train Bernoulli Naive Bayes classifier
    bnb = BernoulliNB(binarize=0.0)
    bnb.fit(X_train, Y_train)

    print('Bernoulli Naive Bayes score: %.3f' % bnb.score(X_test, Y_test))

    # Compute CV score
    bnb_scores = cross_val_score(bnb, X, Y, scoring='accuracy', cv=10)
    print('Bernoulli Naive Bayes CV average score: %.3f' % bnb_scores.mean())

    # Predict some values
    data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    Yp = bnb.predict(data)
    print(Yp)
```

# 判别分析

```python
from __future__ import print_function

import matplotlib.pyplot as plt
import numpy as np

from sklearn.datasets import make_blobs
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.model_selection import cross_val_score


# For reproducibility
np.random.seed(1000)


# Total number of samples
nb_samples = 1000


if __name__ == '__main__':
    # Create the dataset
    X, Y = make_blobs(n_samples=nb_samples, n_features=2, centers=2, cluster_std=[1.0, 10.0], random_state=1000)

    # Show the dataset
    fig, ax = plt.subplots(figsize=(11, 7))

    ax.scatter(X[Y == 0, 0], X[Y == 0, 1], label='Class 0')
    ax.scatter(X[Y == 1, 0], X[Y == 1, 1], label='Class 1')
    ax.set_xlabel(r'$x_0$')
    ax.set_ylabel(r'$x_1$')
    ax.grid()
    ax.legend()

    plt.show()

    # Show the covariance matrices
    print('Covariance matrix for class 0:')
    print(np.cov(X[Y == 0].T))

    print('\nCovariance matrix for class 1:')
    print(np.cov(X[Y == 1].T))

    # Show the CV scores
    lda = LinearDiscriminantAnalysis()
    print('\nLDA average CV accuracy: %.3f' % cross_val_score(lda, X, Y, cv=10).mean())

    qda = QuadraticDiscriminantAnalysis()
    print('QDA average CV accuracy: %.3f' % cross_val_score(qda, X, Y, cv=10).mean())


```

