# 基函数回归

可以通过**基函数**对原始数据进行变换，从而将变量间的线性回归模型转换为非线性回归模型。这个方法的多维模型是
$$
y = a_0 + a_1x_1 + a_2x_2 + a_3x_3 + \cdots
$$
其中，以为的输入变量 $x$ 转换成了三维变量 $x_1,x_2,x_3$。让 $x_n=f_n(x)$，这里的 $f_n()$ 是转换数据的函数。

假如 $f_n(x)=x^n$，那么模型会变成多项式回归
$$
y = a_0 + a_1x + a_2x^2 + a_3x^3 + \cdots
$$
这个模型仍然是一个线性模型，也就是说系数 $a_n$彼此不会相乘或相除。其实是将一维的 $x$ 投影到了高维空间，因此通过线性模型就可以拟合出 $x,y$ 间更复杂的关系。

## 多项式基函数

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression

# PolynomialFeatures转换器实现多项式投影
# 这个新的高维数组之后可以放在多项式回归模型中
x = np.array([2, 3, 4])
poly = PolynomialFeatures(3, include_bias=False)  # 通过指数函数，将一维数组转换成了三维数组。
res = poly.fit_transform(x[:, None])
print(res)
# [[ 2.  4.  8.]
#  [ 3.  9. 27.]
#  [ 4. 16. 64.]]

# 创建管道
poly_model = make_pipeline(PolynomialFeatures(7), LinearRegression())  # 创建一个7次多项式回归模型

rng = np.random.RandomState(1)
x = 10 * rng.rand(50)
y = np.sin(x) + 0.1 * rng.randn(50)  # 带噪的正弦波

poly_model.fit(x[:, np.newaxis], y)
xfit = np.linspace(0, 10, 1000)
yfit = poly_model.predict(xfit[:, np.newaxis])
plt.scatter(x, y)
plt.plot(xfit, yfit)
plt.show()

```

## 高斯基函数

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression
from sklearn.base import BaseEstimator, TransformerMixin

# 多项式基函数
# PolynomialFeatures转换器实现多项式投影
# 这个新的高维数组之后可以放在多项式回归模型中
x = np.array([2, 3, 4])
poly = PolynomialFeatures(3, include_bias=False)  # 通过指数函数，将一维数组转换成了三维数组。
res = poly.fit_transform(x[:, None])
print(res)
# [[ 2.  4.  8.]
#  [ 3.  9. 27.]
#  [ 4. 16. 64.]]

# 创建管道
poly_model = make_pipeline(PolynomialFeatures(7), LinearRegression())  # 创建一个7次多项式回归模型

rng = np.random.RandomState(1)
x = 10 * rng.rand(50)
y = np.sin(x) + 0.1 * rng.randn(50)  # 带噪的正弦波

poly_model.fit(x[:, np.newaxis], y)
xfit = np.linspace(0, 10, 1000)
yfit = poly_model.predict(xfit[:, np.newaxis])


# plt.scatter(x, y)
# plt.plot(xfit, yfit)
# plt.show()


# 高斯基函数
class GaussianFeatures(BaseEstimator, TransformerMixin):
    """一维输入均匀分布的高斯特征"""

    def __init__(self, N, width_factor=2.0):
        self.N = N
        self.width_factor = width_factor

    @staticmethod
    def _gauss_basis(x, y, width, axis=None):
        arg = (x - y) / width
        return np.exp(-0.5 * np.sum(arg ** 2, axis))

    def fit(self, X, y=None):
        # 在数据区间中创建N个高斯分布中心
        self.centers_ = np.linspace(X.min(), X.max(), self.N)
        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])
        return self

    def transform(self, X):
        return self._gauss_basis(X[:, :, np.newaxis], self.centers_, self.width_, axis=1)


gauss_model = make_pipeline(GaussianFeatures(20), LinearRegression())
gauss_model.fit(x[:, np.newaxis], y)
yfit = gauss_model.predict(xfit[:, np.newaxis])
plt.scatter(x, y)
plt.plot(xfit, yfit)
plt.xlim(0, 10)
plt.show()
```

