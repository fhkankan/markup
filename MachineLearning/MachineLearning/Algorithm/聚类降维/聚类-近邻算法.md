# 近邻算法

近邻算法(Affinity Propagation, AP)的基本目标与K-Means一致，都会追求找出组内距离平方和最小的划分方法。但AP算法具有结果稳定可重现(K-means结果在一定程度上依赖于开始的随机中心点)、训练前无须指定分组数目等优点，只是算法的事件复杂度较k-means高

## 概念

假设场景：某门课程的期末考试通过组建小组完成指定项目的方式进行，要哭同学分自行分组，对每组人数上限没有要求，但每组需要有一名组长。

- 质心：同学组长，是聚类中的每一组的核心成员

- 参考度：是每一个同学相当组长的意愿程度，在聚类之前可以为每一个成员设置参考值

- 相似度：$s(i,k)$， 可以看成同学i与k在讨论之前的熟悉程度，该值越高则两个同学越可能分成一组。普通聚类中，就是两个特征向量之间的距离
- 责任度：$r(i,k)$，是同学i对同学k说的一句话，其内容是"我想选你做组长的意愿是多少",当然该值越高说明i越想加入k的一组。
- 可用度：$a(i,k)$，是同学k对同学i说的一句话，其内容是“我想当组长饿意愿是多少”，该值越高说明k越可能成为质心。

其中，质心在聚类完成之后正式产生；参考度和相似度是在聚类之前需要给出的超参数；责任度和可用度是在聚类过程中使用的算法概念。

## 原理

与K-means类似，AP也是用迭代的方式逐渐找到质心/中心点。近邻算法中的质心与k-means的中心点略有不同，k-means的中心点可以是特征取值空间中的任意一个点，而质心必须是样本数据中的某个点。

每两个结点之间都有相应的$r(i,k),a(i,k)$，因此可以将系统整体的责任度和可用度各自看成一个二维矩阵，AP算法迭代的目标是逐步更新责任度和可用度矩阵。每个迭代分两步执行。

- 更新责任度矩阵

每个$r(i,k)$新的值等于原始相似度$s(i,k)$减去上一轮迭代$i$ 结点收到的最大“相似度+可用度”组合（第一轮迭代所有结果的可用度为零）。可以理解成“如果有其他节点更愿意做质心，则结点i发给k的责任度降低”。

- 更新可用度矩阵

每个$a(i,k)$新的值等于其自责任$a(k,k)$ 加上其他节点发给k的所有正向责任度的和。可以理解为"有越多的结点希望k做质心，则其越自告奋勇争当质心"。

每一轮迭代其实都是一个聚类结果的瞬间状态。在该状态中将责任度矩阵与可用度矩阵相加，则对于每一个结点i来说能够获得$r(i,k)+a(i, k)$最大值的那个k结点就是i所在组的质心。该迭代过程的收敛停止条件可以达到最大的迭代次数，或者连续若干次迭代聚类结果没有发生变化。

## 实现

API

```python
from sklearn.cluster import AffinityPropagation

# 初始化参数
damping
# 阻尼因子，范围在0.5～1之间，该值越大每次迭代中责任度矩阵和可用度矩阵更新越慢，因此算法收敛也越慢。但较大的damping可以防止这些值在更新中的都懂，降低无法收敛的风险。
convergenve_iter
# 聚类结果连续convergenve_iter次迭代没有变化时，认为已经达到稳定状态，算法完成。
max_iter
# 算法的最大的迭代次数，到达该值时即使没有达到稳定状态也不再继续。
preference
# 结点参考度，可以是一个数值(所有样本数据使用相同参考度),也可以是一个数组(每个样本有各自的参考度)
affinity
# 相似度计算方法，可以是cuclidean或precomputed。前者是默认值，指用特征向量之间的欧几里得距离计算相似度s(i,k):后者是指开发者自己计算s(i,k)，此时在给fit(),predict()等函数传递参数时需要传入相似度矩阵，而不是特征向量列表。

# 训练完成后模型的属性
cluster_centers_indices   # 质心样本在训练集中的索引号
cluster_centers_					# 质心结点的特征向量数组
labels_										# 训练样本的聚类结果
affinity_matrix_					# 近邻矩阵，也就是责任度矩阵与可用度矩阵的和
n_iter_										# 算法收敛所用的迭代次数
```

示例

```python
import numpy as np
from sklearn.cluster import AffinityPropagation

# 训练数据
X = np.array([[1, 2],[1, 4], [0.7, 0], [0.2, 5], [0, 4], [1.3, 0], [0.1, 2], [0, 4], [0.4, 0]])

af = AffinityPropagation(preference=-5, ).fit(X)
print(af.labels_)  # 查看聚类结果
af2 = AffinityPropagation(preference=-8,).fit(X)
print(af2.labels_)
print(af2.n_iter_)  # 迭代进行的次数
print(af2.cluster_centers_)  # 质心的坐标 
```

近邻传播算法会找出数据中每个集群的代表性数据点，会找到数据点间的相似性度量值，并把所有数据点看成潜在的代表性数据点，也称为**取样器**(example)。

```python
import json
import datetime

import numpy as np
import matplotlib.pyplot as plt
from sklearn import covariance, cluster
from matplotlib.finance import quotes_historical_yahoo_ochl as quotes_yahoo

# 输入符号信息文件
symbol_file = 'symbol_map.json'

# 选择时间段
start_date = datetime.datetime(2004, 4, 5)
end_date = datetime.datetime(2007, 6, 2)

# 加载符号映射信息
with open(symbol_file, 'r') as f:
    symbol_dict = json.loads(f.read())

symbols, names = np.array(list(symbol_dict.items())).T

quotes = [quotes_yahoo(symbol, start_date, end_date, asobject=True)
                for symbol in symbols]

# 提取开盘价和收盘价
opening_quotes = np.array([quote.open for quote in quotes]).astype(np.float)
closing_quotes = np.array([quote.close for quote in quotes]).astype(np.float)

# 计算每日股价波动
delta_quotes = closing_quotes - opening_quotes

# 从相关性中建立协方差图模型
edge_model = covariance.GraphLassoCV()

# 数据标准化
X = delta_quotes.copy().T
X /= X.std(axis=0)

# 训练模型
with np.errstate(invalid='ignore'):
    edge_model.fit(X)

# 使用近邻传播算法建立聚类模型
_, labels = cluster.affinity_propagation(edge_model.covariance_)
num_labels = labels.max()

# Print the results of clustering
for i in range(num_labels + 1):
    print("Cluster", i+1, "-->", ', '.join(names[labels == i]))
```

