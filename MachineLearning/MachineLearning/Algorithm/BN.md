# 贝叶斯网络

Bayesian Network

基于条件概率结点的网络模型，用贝叶斯理论推测被预测时间发生的概率。

## 原理

贝叶斯网络是一种用点表示事件条件概率、用边表示事件以来关系的有向无环图（Directed Acyclic Graph,DAG），时间丧该网络表达了场景内所有事件的联合概率分布，因此可以完成后续任何基于条件概率、边际概率的推理应用。因此贝叶斯网络也被称为信念网（Belief Network）。

概率是对不确定时间的定量表达方式，贝叶斯公式是基本的概率规律。

### 静态结构

贝叶斯网络与隐马尔可夫模型是独立发展的两种基于图论的概率建模手段。与HMM按时间轴排序的两层链状模型不同，贝叶斯网络可以是任意的有向图。途中的每个结点都是对系统中一个事件的概率描述，并且用肩头线表达非独立事件之间的依赖关系。

- 结点CPD

在BN中描述概率的方式是每个结点上的条件概率分布(Conditional Probability Distributions,CPD)，其中的条件就是每个结点的父结点。网络中没有父结点的结点是独立结点，它的CPD也就是该结点本身的概率分布。

- BN的实质是对联合概率的描述。

一个完整的贝叶斯网络，实质是用DAG和CPD描述场景中所有事件的联合概率。根据该联合概率可以计算出任何香瓜你的条件概率和边际概率。

- 多项式分布情况

一种极端简单的清咖滚，其中每个结点的状态只有两种，即二项分布。而理论上贝叶斯网络中允许结点用任何分布描述CPD。随着结点状态的复杂化，计算CPD的过程也将越来越繁琐。

- 连续变量的情况

当事件的状态是可枚举值的时候，无论如何都可以通过二项分布、多项式分布等离散分布等形式进行计算。但有时系统中会有用连续变量描述肚饿结点，比如金额，此时可以有两种处理策略：1.将连续变量离散化后进行多项式等分布的建模；2.在CPD中引入连续分布，最常见的是高斯分布$N(\mu,\sigma)$.

### 联合/边缘/条件概率换算

- 联合概率分布

联合概率是在多元变量描述的系统中“每个变量分别满足各自条件时”的概率。如果将联合概率看成由多元变量到概率值的映射，那么该函数就是联合概率分布的函数，它的所有"自变量->因变量"对构成了联合概率分布。联合概率一般用$P(a,b,c,\cdots,n)$这样的符号表示，或者在不引起歧义的情况下成为$P(abc\cdots n)$，其中$a,b,c,d,\cdots,n$是系统中的所有变量。

- 边缘概率分布

设连恶化概率分布是函数$f(a,b,c,d)$，用该函数查找概率值时需要给出系统中所有变量的值。但有时需要在某些变量未知的情况下查询概率，这样的函数就是边缘概率函数。边缘概率的表达方式与联合概率一样，其区别是通过边缘概率查询概率时只需给出系统中的部分变量。比如系统中有变量$a,b,c,\cdots,n$，那么任意的概率函数$g(a,b),g(b,d,g,n),g(b)、\cdots$ 都是该系统的边缘概率分布函数。

- 条件概率分布

条件概率用$P(a,b|i=?,j=?)$这样的形式表达，白噢熵自爱已知某些变量的情况下求另一些变量$(a,b)$给定值的概率。

- 用联合分布求边缘分布

设已知联合概率分布函数$f(x,y,z)$，要求边缘分布$g(y)$只需在联合分布上逐个对未知变量进行积分，即
$$
g(y) = {\iint}_{-\infty}^{\infty}{f(x,y,z)\mathrm{d}x\mathrm{d}z}
$$
对于离散变量
$$
g(y) = \sum_z\sum_x{f(x,y,z)}
$$

- 用联合概率分布求条件概率分布

$$
P(x|y=?) = \frac{P(x,y=?)}{P(y=?)}
$$

- 用条件概率和边缘概率求联合概率

在概率论中，如果已知系统中的所有条件分布，是无法获得联合分布的。但如果同时已知条件概率与条件变量的边缘概率，则可以求得联合概率，即
$$
P(x,y) = P(x|y)P(y)
$$

- 贝叶斯公式

$$
P(x|y) = \frac{P(x,y)}{P(y)}= \frac{P(y,x)}{P(y)}= \frac{P(y|x)P(x)}{P(y)}
$$

### 链式法则与变量消元

- 链式法则

贝叶斯网络中保存了所有结点的条件分布，求系统的联合分布步骤：

1. 贝叶斯网络是一个有向无环图，所以至少会有一个没有父亲的“根”结点。

2. 由于没有任何“条件”，则根结点的CPD本身就构成了自己的边缘分布。

3. 结合根结点边缘分布与第一层子结点的CPD条件分布，就可以计算出根结点与子结点的联合分布，该联合分布也就构成下一层结点的边缘分布。

4. 如此逐层向DAG的深处遍历，可以计算出所有结点的联合分布。

而这个步骤用概率公式表达，就是联合分布可通过所有结点的CPD连乘获得
$$
P(a,b,c,d)=P(a)\cdot P(b|a) \cdot P(c|a,b) \cdot P(d|b,c)
$$
这就是贝叶斯网络链式法则。

- 变量消元

通过链式法则获得的联合概率公式能确切地计算出所有事件组合的概率，但现实中的问题往往只是求系统中的某些条件概率和边缘概率问题。如
$$
P(a|d=1) = \frac{P(a,d=1)}{P(d=1)}=\frac{\sum_c\sum_b{(P(a)P(b|a)P(c|a,b)P(d=1|b,c))}}{\sum_c\sum_b\sum_a{(P(a)P(b|a)P(c|a,b)P(d=1|b,c))}}
$$
这个过程非常繁琐，如果使用计算机编程会产生$O(n^3)$级别的时间复杂度。这仅是在系统中只有四个结点的情况，随着网络规模的增大，是一个$O(n^{n-1})$ 级别的问题。

变量消元法对隐藏变量(如b,c)进行逐个消元的方式简化了这种运算，从编程的角度出发它就是常说的动态规划。对上述计算问题，用变量消元的步骤可以是

1. 首先消除变量c，设函数$f(a,b)=\sum_c{P(c|a,b)P(d=1|b,c)}$，原等式变为

$$
\frac{\sum_b{(P(a)P(b|a)P(a,b))}}{\sum_b\sum_a{(P(a)P(b|a)P(a,b))}}
$$

2. 再消除变量b，设函数$g(a)=\sum_b{P(b|a)\cdot f(a,b)}$，原等式变为

$$
\frac{P(a)\cdot g(a)}{\sum_a(P(a)\cdot g(a))}
$$

这样灯饰完全变为了变量a的函数。将这样的步骤应用在计算机编程中，其时间复杂度就是$O(n)+O(n)+O(n)$，如果网络规模增大时间复杂度也只是$n\cdot O(n)$，比原始的链式法则计算公式的指数级别复杂度有显著的减少。

## 网络构建

构建贝叶斯网络一般分三步进行：1.确定是领域中有哪些重要的变量及其分布类型（二项分布、多项式分布、高斯分布等）；2.确定DAG图结构；3.学习网络中每个结点CPD中的参数。第一项工作主要由领域专家完成；第二项既可以由专家确定也可以通过数据训练获得；第三项式有监督学习中的参数估计，主要由数据训练完成参数。

### 网络参数估计

如果已经确定了网络的DAG结构和每个结点的概率分布函数类型，则可通过参数估计学习概率函数中的刹那火速。精确的网络参数估计的典型代表是最大似然度估计和最大后验估计。近似推理也被用于在无法承受精确推理时间要求的情况下来近似估计网络参数。

- 最大似然估计

贝叶斯公式中似然度指贝叶斯公式$P(A|D) = \frac{P(D|A)P(A)}{P(D)}$中的$P(D|A)$。在贝叶斯网络中，此处的数据D就是所有训练数据集，而A是使用的CPD参数。因此最大似然估计就是求如下优化目标中A的值
$$
arg\max_A P(D|A)
$$
由于有监督学习中假设所有数据样本是被独立采样的，因此该目标等于
$$
arg\max_A \prod_{d\in D}{P(d|A)}
$$
其中d是每一个独立样本。对于似然函数是多项式分布的离散变量，参数组A的值可以直接通过样本中各类型样本占样本总数的比例解得。对于符合高斯分布等的连续变量，这样的无条件求极值问题可设院函数骗到方程组为0并求解参数组A。而在计算机中，为了降低计算时间复杂度，通常使用梯度下降的方法求近似解。

- 最大后验估计

ML方法完全凭数据说话，没有办法加入任何人类的已有经验，如果能够获得的训练数据非常有限无法代表数据整体，这就成了ML的最大缺点。而最大后燕估计MAP方法则把优化目标由似然函数变为了后验函数，通过人为输入先验$P(A)$，MAP的优化目标是
$$
arg\max_A P(A|D) = \frac{P(D|A)P(A)}{P(D)}
$$
由于无论A取值如何都不影响P(D)的值，因此该公式等价于
$$
arg\max_A P(A|D)\cdot P(A)
$$
为了便于计算，通常对上式取$\log$，拆分概率分布的乘法，最终公式变为
$$
arg\max_A P(A|D) + \log P(A)
$$
对目标的求值方法则与ML完全一样，可以用数学推导或梯度下降的方法求解。

### 启发式搜索

如果网络结构不确定，就需要从数据中学习DAG网络结构。学习该结构的出发点非常简单，就是搜索所有可能的有向图结构，找出分值最高的结构作为结果，即目标
$$
arg\max_G{Score(G)}
$$
其中,Score是对有向图G的打分函数。打分函数有很多种形式，比如log-Likelihood(LL)、Minimum Description Length(MDL)、Bayesian Dirichlet(DB)等，它们的作用都是评估一个网络与给定数据的拟合程度。

- 穷举遍历有向图是NP-hard问题

遍历所有可能的图形当然是可能的，其方法是逐个跳出每个结点与已搜索的结点组合，然后递归完成搜索。用这种方法遍历所有DAG图是一个NP-hard问题，即这样问题的时间复杂度过高而不适用于解决通用问题。

- 启发式搜索(Heuristic Search)原理

由于穷举所有可能的策略实现性不强，现在对构架你贝叶斯网络结构的主流做法是用启发式搜索方法。所谓启发式搜索也是逐个排查可能图形的方式，与穷举法不同的是它不机械地查找所有可能值，而是采取“走一步看一步”的策略，在每一步用评估函数$f(G_n)$挑选出下一个候选图形中哪一个是最优选择。

相对广度优先的穷举搜索法，启发式搜索在每一层只选择一个后继进行下一步搜索，大大缩减了搜索空间。当然，启发式搜索不确保能找到全局最优解，但在配置了合适的评估函数时通常会获得很好的效果。

- 启发函数与启发搜索策略

按照"走一步看一步"的具体策略不同，常见启发式搜索又分为贪婪与A*策略两种。它们的根本不同在于采用了不同的评估函数形式。

在贪婪策略中，评估函数$f(G_n)$等于启发函数$h(G_n)$，启发函数是在启发式搜索中衡量某个状态与目标状态之间距离的函数。启发函数是一个估计值，无须精确计算距离，但一般不应该估计得比真实距离高。如果启发函数高估了该距离，则此启发函数是不可接受的。

在A*策略的评估函数由两部分组成，即$f(G_n)=g(G_n)+h(G_n)$，其中$h(G_n)$仍然是启发函数，而$g(G_n)$被称为成本函数。成本函数是衡量从搜索出发点到当前状态的距离，$g(G_n)$是实实在在产生的成本，而不是一个估计值。

从直观角度比较两者的区别：贪婪策略只需对未来的估计选择下一状态，而A*同时兼顾已经发生的成本和对未来的估计。

### Chow-Liu Tree算法

启发式搜索虽然不再盲目地穷举所有可能图形，但其待搜索的图空间仍然没有变化，同时启发式搜索也不能保证寻找到最优解。而另一种为了加快组网过程而产生的近似求解策略是缩减可能图的候选空间，即只寻找“树形”的贝叶斯网络结构。

所谓树形贝叶斯网络是DAG，它可看成FAG的子集，它要求即使将有向图原样变为无向图后，图中仍不存在环结构。

Chow-Liu Tree算法是搜索树形网络空间的典型算法，其主要原理是从空树开始逐个加入结点，而加入的条件是随着该结点加入后产生的变的权重最大。边的权重被定义为两个结点的互信息，即
$$
I(x_i;x_j) = \sum_{x_i,x_j}{P(x_i,x_j)\log{\frac{P(x_i,x_j)}{P(x_i)P(x_j)}}}
$$
其中$x_i,x_j$是边两端的结点变量，$I(x_i;x_j)$整个公式的作用是衡量两个随机变量的相似程度。在用这种方法确定了所有的边后选取任意结点作为根结点并逐级生成树即可。

在Chow-Liu算法的论文中证明了用这种寻找最大权重生成树的方法最终得到的树结构的联合分布与真实样本联合分布最相近。论文中衡量两个分布的方法是Kullback-Leiber散度。

## 近似推理

虽然有基于链式法则和变量消元(VE)的推理，但VE推理中的大量积分（对于离散变量则是求和）运算使得推理在大规模复杂网络中的计算时间变得不饿哭接受。同样，在确定网络结构后从数据样本训练网络参数的ML和MAP也有类似问题。因此只能寻找一些近似推理（Approximate Inference）算法，虽然不能保证找到理论最佳解，但在推理时间和效果上都变得可以接受。

这样的贝叶斯网络近似推理算法可以分为随机方法（Stochastic）和确定性方法（Deterministic）两种，马尔可夫链蒙特卡洛（Markov chain Monte Carlo,MCMC）和变分贝叶斯（Variational Bayes,VB）分别是它们的代表。

### 蒙特卡洛方法

蒙特卡洛是一种用随机模拟的方式实现计算目的的方法。随机模拟计算方法来自于18世界用于计算圆周率$\pi$ 的实验，该实验随机想一个方形区域投针，然后用被投入内嵌圆中针的数量来计算圆周率，其计算公式为
$$
\frac{内嵌圆面积}{方形面积} \approx \frac{圆内针数}{方形内针数} = \frac{\pi r^2}{(2r)^2}= \frac{\pi}{4}
$$
可以发现随着投针数（随机事件）的增加，计算结果越来越趋于真实值。

蒙特卡洛方法虽然不再用于计算圆周率，但是被启发用于解决各种越来越复杂的问题。

### 马尔可夫链收敛定理

马尔可夫链是一种状态链，其中每个结点的状态值概率只依赖于它的紧前结点而与其他结点无关。其中每个状态在下一结点变换为其他状态的概率被称为“转移概率”(Transform Prob)，此外为了约束该链中第一个结点的状态还定义了"初始概率"(Initial Prob)的概念，而通常不太关注初始概率，而只关心转移概率。

马尔可夫收敛定理可以说明原因：如果一个非周期马尔可夫链具有转移概率矩阵P且它的任何两个状态是连通的，那么$\lim_{n\to \infty} P_{ij}^n$存在且与i无关，记平稳概率分布(stationary distribution)$\lim_{n\to \infty}P_{ij}^n=\pi(j)$.

在一个马尔可夫链上总会找到结点n，从该结点开始每个后续结点的状态概率分布固定，只与转移概率有关而与初始概率无关。

验证马氏链收敛定理的代码

```python
import numpy as np

# 初始概率矩阵
init_probs = np.array([0.1, 0.3, 0.6])
# 转移概率矩阵
transform_probs = np.array([[0.7, 0.1, 0.2], [0.2, 0.5, 0.3], [0.2, 0.4, 0.4]])
# 马尔可夫状态概率分布链
chain = [init_probs]

# 检查chain变量是否已经平稳
def check_stable():
    if len(chain) < 3:
        return False
    for i in range(-2, -1):
        if not np.array_equal(np.around(chain[i], 2), np.around(chain[i-1], 2)):
            return False
    return True

for i in range(10000):
    chain.append(chain[-1].dot(transform_probs))  # 生成新的结点
    print("iter %s: %s" % (i, np.around(chain[-1], 2)))
    if check_stable():  # 如果进入平稳状态则退出
        print("stabel!")
        break
        
        
# 修改代码中的init_probs为任意其他分布，则仍然最后收敛于相同分布
# 修改代码中的transform_probs，则会收敛于一个不同的分布
```

### MCMC推理框架

用蒙特卡洛方法进行贝叶斯推理的基本想法是，在贝叶斯网络所表达的联合分布上进行若干次采样，然后用采样后的样本通过参数估计的方法解决推理问题。比如当需要求某离散型变量网络中概率$P(x=1,y=0)$时，只需采样若干样本，然后求其中取到$x=1,y=0$的样本所占采样总数的比例，就可得到$P(x=1,y=0)$的估计值。这样，蒙特卡洛推理的关键就转移到了"如何进行样本采样"上。

MCMC就是使用马尔可夫链进行采样的蒙特卡洛过程，该方法由M etropolis于1953年提出。如果能在马尔可夫链上构造一个转换概率矩阵，使它在进入平稳状态后收敛于采样的联合分布，则在该马尔可夫链上每个平稳状态结点都是一个取自目标联合分布的样本点。只要用转移矩阵产生新的结点就能不断地得到新的样本。与马氏链收敛定理的python代码不同的是，此时的马尔可夫链上状态通常是多元状态，因此转移概率分布也会是多元概率分布如多元高斯分布多项式分布等，用这些样本就可以进行贝叶斯推理了。

具体实现有集中不同的算法：Metropolis的经典算法基于细致平稳条件(Detailed Balance)、接受率(Acceptance Ratio)等；后来Hastings改进该算法使马氏链能更快收敛，称为Metropolis-Hastings算法；而Stuart和Donald Geman提出的Metropolis-Hastings的一种特殊形式Gibbs sampling是目前贝叶斯MCMC推理的主流采样算法。

### Gibbs采样

### 变分贝叶斯

## 利用共轭建模

### 共轭分布

### 隐含变量与显式变量

## 实战