# 贝叶斯网络

Bayesian Network

基于条件概率结点的网络模型，用贝叶斯理论推测被预测时间发生的概率。

## 原理

贝叶斯网络是一种用点表示事件条件概率、用边表示事件以来关系的有向无环图（Directed Acyclic Graph,DAG），时间丧该网络表达了场景内所有事件的联合概率分布，因此可以完成后续任何基于条件概率、边际概率的推理应用。因此贝叶斯网络也被称为信念网（Belief Network）。

概率是对不确定时间的定量表达方式，贝叶斯公式是基本的概率规律。

### 静态结构

贝叶斯网络与隐马尔可夫模型是独立发展的两种基于图论的概率建模手段。与HMM按时间轴排序的两层链状模型不同，贝叶斯网络可以是任意的有向图。途中的每个结点都是对系统中一个事件的概率描述，并且用肩头线表达非独立事件之间的依赖关系。

- 结点CPD

在BN中描述概率的方式是每个结点上的条件概率分布(Conditional Probability Distributions,CPD)，其中的条件就是每个结点的父结点。网络中没有父结点的结点是独立结点，它的CPD也就是该结点本身的概率分布。

- BN的实质是对联合概率的描述。

一个完整的贝叶斯网络，实质是用DAG和CPD描述场景中所有事件的联合概率。根据该联合概率可以计算出任何香瓜你的条件概率和边际概率。

- 多项式分布情况

一种极端简单的清咖滚，其中每个结点的状态只有两种，即二项分布。而理论上贝叶斯网络中允许结点用任何分布描述CPD。随着结点状态的复杂化，计算CPD的过程也将越来越繁琐。

- 连续变量的情况

当事件的状态是可枚举值的时候，无论如何都可以通过二项分布、多项式分布等离散分布等形式进行计算。但有时系统中会有用连续变量描述肚饿结点，比如金额，此时可以有两种处理策略：1.将连续变量离散化后进行多项式等分布的建模；2.在CPD中引入连续分布，最常见的是高斯分布$N(\mu,\sigma)$.

### 联合/边缘/条件概率换算

- 联合概率分布

联合概率是在多元变量描述的系统中“每个变量分别满足各自条件时”的概率。如果将联合概率看成由多元变量到概率值的映射，那么该函数就是联合概率分布的函数，它的所有"自变量->因变量"对构成了联合概率分布。联合概率一般用$P(a,b,c,\cdots,n)$这样的符号表示，或者在不引起歧义的情况下成为$P(abc\cdots n)$，其中$a,b,c,d,\cdots,n$是系统中的所有变量。

- 边缘概率分布

设连恶化概率分布是函数$f(a,b,c,d)$，用该函数查找概率值时需要给出系统中所有变量的值。但有时需要在某些变量未知的情况下查询概率，这样的函数就是边缘概率函数。边缘概率的表达方式与联合概率一样，其区别是通过边缘概率查询概率时只需给出系统中的部分变量。比如系统中有变量$a,b,c,\cdots,n$，那么任意的概率函数$g(a,b),g(b,d,g,n),g(b)、\cdots$ 都是该系统的边缘概率分布函数。

- 条件概率分布

条件概率用$P(a,b|i=?,j=?)$这样的形式表达，白噢熵自爱已知某些变量的情况下求另一些变量$(a,b)$给定值的概率。

- 用联合分布求边缘分布

设已知联合概率分布函数$f(x,y,z)$，要求边缘分布$g(y)$只需在联合分布上逐个对未知变量进行积分，即
$$
g(y) = {\iint}_{-\infty}^{\infty}{f(x,y,z)\mathrm{d}x\mathrm{d}z}
$$
对于离散变量
$$
g(y) = \sum_z\sum_x{f(x,y,z)}
$$

- 用联合概率分布求条件概率分布

$$
P(x|y=?) = \frac{P(x,y=?)}{P(y=?)}
$$

- 用条件概率和边缘概率求联合概率

在概率论中，如果已知系统中的所有条件分布，是无法获得联合分布的。但如果同时已知条件概率与条件变量的边缘概率，则可以求得联合概率，即
$$
P(x,y) = P(x|y)P(y)
$$

- 贝叶斯公式

$$
P(x|y) = \frac{P(x,y)}{P(y)}= \frac{P(y,x)}{P(y)}= \frac{P(y|x)P(x)}{P(y)}
$$

### 链式法则与变量消元

- 链式法则

贝叶斯网络中保存了所有结点的条件分布，求系统的联合分布步骤：

1. 贝叶斯网络是一个有向无环图，所以至少会有一个没有父亲的“根”结点。

2. 由于没有任何“条件”，则根结点的CPD本身就构成了自己的边缘分布。

3. 结合根结点边缘分布与第一层子结点的CPD条件分布，就可以计算出根结点与子结点的联合分布，该联合分布也就构成下一层结点的边缘分布。

4. 如此逐层向DAG的深处遍历，可以计算出所有结点的联合分布。

而这个步骤用概率公式表达，就是联合分布可通过所有结点的CPD连乘获得
$$
P(a,b,c,d)=P(a)\cdot P(b|a) \cdot P(c|a,b) \cdot P(d|b,c)
$$
这就是贝叶斯网络链式法则。

- 变量消元

通过链式法则获得的联合概率公式能确切地计算出所有事件组合的概率，但现实中的问题往往只是求系统中的某些条件概率和边缘概率问题。如
$$
P(a|d=1) = \frac{P(a,d=1)}{P(d=1)}=\frac{\sum_c\sum_b{(P(a)P(b|a)P(c|a,b)P(d=1|b,c))}}{\sum_c\sum_b\sum_a{(P(a)P(b|a)P(c|a,b)P(d=1|b,c))}}
$$
这个过程非常繁琐，如果使用计算机编程会产生$O(n^3)$级别的时间复杂度。这仅是在系统中只有四个结点的情况，随着网络规模的增大，是一个$O(n^{n-1})$ 级别的问题。

变量消元法对隐藏变量(如b,c)进行逐个消元的方式简化了这种运算，从编程的角度出发它就是常说的动态规划。对上述计算问题，用变量消元的步骤可以是

1. 首先消除变量c，设函数$f(a,b)=\sum_c{P(c|a,b)P(d=1|b,c)}$，原等式变为

$$
\frac{\sum_b{(P(a)P(b|a)P(a,b))}}{\sum_b\sum_a{(P(a)P(b|a)P(a,b))}}
$$

2. 再消除变量b，设函数$g(a)=\sum_b{P(b|a)\cdot f(a,b)}$，原等式变为

$$
\frac{P(a)\cdot g(a)}{\sum_a(P(a)\cdot g(a))}
$$

这样灯饰完全变为了变量a的函数。将这样的步骤应用在计算机编程中，其时间复杂度就是$O(n)+O(n)+O(n)$，如果网络规模增大时间复杂度也只是$n\cdot O(n)$，比原始的链式法则计算公式的指数级别复杂度有显著的减少。

## 网络构建

构建贝叶斯网络一般分三步进行：1.确定是领域中有哪些重要的变量及其分布类型（二项分布、多项式分布、高斯分布等）；2.确定DAG图结构；3.学习网络中每个结点CPD中的参数。第一项工作主要由领域专家完成；第二项既可以由专家确定也可以通过数据训练获得；第三项式有监督学习中的参数估计，主要由数据训练完成参数。

### 网络参数估计

如果已经确定了网络的DAG结构和每个结点的概率分布函数类型，则可通过参数估计学习概率函数中的刹那火速。精确的网络参数估计的典型代表是最大似然度估计和最大后验估计。近似推理也被用于在无法承受精确推理时间要求的情况下来近似估计网络参数。

- 最大似然估计

贝叶斯公式中似然度指贝叶斯公式$P(A|D) = \frac{P(D|A)P(A)}{P(D)}$中的$P(D|A)$。在贝叶斯网络中，此处的数据D就是所有训练数据集，而A是使用的CPD参数。因此最大似然估计就是求如下优化目标中A的值
$$
arg\max_A P(D|A)
$$
由于有监督学习中假设所有数据样本是被独立采样的，因此该目标等于
$$
arg\max_A \prod_{d\in D}{P(d|A)}
$$
其中d是每一个独立样本。对于似然函数是多项式分布的离散变量，参数组A的值可以直接通过样本中各类型样本占样本总数的比例解得。对于符合高斯分布等的连续变量，这样的无条件求极值问题可设院函数骗到方程组为0并求解参数组A。而在计算机中，为了降低计算时间复杂度，通常使用梯度下降的方法求近似解。

- 最大后验估计

ML方法完全凭数据说话，没有办法加入任何人类的已有经验，如果能够获得的训练数据非常有限无法代表数据整体，这就成了ML的最大缺点。而最大后燕估计MAP方法则把优化目标由似然函数变为了后验函数，通过人为输入先验$P(A)$，MAP的优化目标是
$$
arg\max_A P(A|D) = \frac{P(D|A)P(A)}{P(D)}
$$
由于无论A取值如何都不影响P(D)的值，因此该公式等价于
$$
arg\max_A P(A|D)\cdot P(A)
$$
为了便于计算，通常对上式取$\log$，拆分概率分布的乘法，最终公式变为
$$
arg\max_A P(A|D) + \log P(A)
$$
对目标的求值方法则与ML完全一样，可以用数学推导或梯度下降的方法求解。

### 启发式搜索

如果网络结构不确定，就需要从数据中学习DAG网络结构。学习该结构的出发点非常简单，就是搜索所有可能的有向图结构，找出分值最高的结构作为结果，即目标
$$
arg\max_G{Score(G)}
$$
其中,Score是对有向图G的打分函数。打分函数有很多种形式，比如log-Likelihood(LL)、Minimum Description Length(MDL)、Bayesian Dirichlet(DB)等，它们的作用都是评估一个网络与给定数据的拟合程度。

- 穷举遍历有向图是NP-hard问题

遍历所有可能的图形当然是可能的，其方法是逐个跳出每个结点与已搜索的结点组合，然后递归完成搜索。用这种方法遍历所有DAG图是一个NP-hard问题，即这样问题的时间复杂度过高而不适用于解决通用问题。

- 启发式搜索(Heuristic Search)原理

由于穷举所有可能的策略实现性不强，现在对构架你贝叶斯网络结构的主流做法是用启发式搜索方法。所谓启发式搜索也是逐个排查可能图形的方式，与穷举法不同的是它不机械地查找所有可能值，而是采取“走一步看一步”的策略，在每一步用评估函数$f(G_n)$挑选出下一个候选图形中哪一个是最优选择。

相对广度优先的穷举搜索法，启发式搜索在每一层只选择一个后继进行下一步搜索，大大缩减了搜索空间。当然，启发式搜索不确保能找到全局最优解，但在配置了合适的评估函数时通常会获得很好的效果。

- 启发函数与启发搜索策略

按照"走一步看一步"的具体策略不同，常见启发式搜索又分为贪婪与A*策略两种。它们的根本不同在于采用了不同的评估函数形式。

在贪婪策略中，评估函数$f(G_n)$等于启发函数$h(G_n)$，启发函数是在启发式搜索中衡量某个状态与目标状态之间距离的函数。启发函数是一个估计值，无须精确计算距离，但一般不应该估计得比真实距离高。如果启发函数高估了该距离，则此启发函数是不可接受的。

在A*策略的评估函数由两部分组成，即$f(G_n)=g(G_n)+h(G_n)$，其中$h(G_n)$仍然是启发函数，而$g(G_n)$被称为成本函数。成本函数是衡量从搜索出发点到当前状态的距离，$g(G_n)$是实实在在产生的成本，而不是一个估计值。

从直观角度比较两者的区别：贪婪策略只需对未来的估计选择下一状态，而A*同时兼顾已经发生的成本和对未来的估计。

### Chow-Liu Tree算法

启发式搜索虽然不再盲目地穷举所有可能图形，但其待搜索的图空间仍然没有变化，同时启发式搜索也不能保证寻找到最优解。而另一种为了加快组网过程而产生的近似求解策略是缩减可能图的候选空间，即只寻找“树形”的贝叶斯网络结构。

所谓树形贝叶斯网络是DAG，它可看成FAG的子集，它要求即使将有向图原样变为无向图后，图中仍不存在环结构。

Chow-Liu Tree算法是搜索树形网络空间的典型算法，其主要原理是从空树开始逐个加入结点，而加入的条件是随着该结点加入后产生的变的权重最大。边的权重被定义为两个结点的互信息，即
$$
I(x_i;x_j) = \sum_{x_i,x_j}{P(x_i,x_j)\log{\frac{P(x_i,x_j)}{P(x_i)P(x_j)}}}
$$
其中$x_i,x_j$是边两端的结点变量，$I(x_i;x_j)$整个公式的作用是衡量两个随机变量的相似程度。在用这种方法确定了所有的边后选取任意结点作为根结点并逐级生成树即可。

在Chow-Liu算法的论文中证明了用这种寻找最大权重生成树的方法最终得到的树结构的联合分布与真实样本联合分布最相近。论文中衡量两个分布的方法是Kullback-Leiber散度。

## 近似推理

虽然有基于链式法则和变量消元(VE)的推理，但VE推理中的大量积分（对于离散变量则是求和）运算使得推理在大规模复杂网络中的计算时间变得不饿哭接受。同样，在确定网络结构后从数据样本训练网络参数的ML和MAP也有类似问题。因此只能寻找一些近似推理（Approximate Inference）算法，虽然不能保证找到理论最佳解，但在推理时间和效果上都变得可以接受。

这样的贝叶斯网络近似推理算法可以分为随机方法（Stochastic）和确定性方法（Deterministic）两种，马尔可夫链蒙特卡洛（Markov chain Monte Carlo,MCMC）和变分贝叶斯（Variational Bayes,VB）分别是它们的代表。

### 蒙特卡洛方法

蒙特卡洛是一种用随机模拟的方式实现计算目的的方法。随机模拟计算方法来自于18世界用于计算圆周率$\pi$ 的实验，该实验随机想一个方形区域投针，然后用被投入内嵌圆中针的数量来计算圆周率，其计算公式为
$$
\frac{内嵌圆面积}{方形面积} \approx \frac{圆内针数}{方形内针数} = \frac{\pi r^2}{(2r)^2}= \frac{\pi}{4}
$$
可以发现随着投针数（随机事件）的增加，计算结果越来越趋于真实值。

蒙特卡洛方法虽然不再用于计算圆周率，但是被启发用于解决各种越来越复杂的问题。

### 马尔可夫链收敛定理

马尔可夫链是一种状态链，其中每个结点的状态值概率只依赖于它的紧前结点而与其他结点无关。其中每个状态在下一结点变换为其他状态的概率被称为“转移概率”(Transform Prob)，此外为了约束该链中第一个结点的状态还定义了"初始概率"(Initial Prob)的概念，而通常不太关注初始概率，而只关心转移概率。

马尔可夫收敛定理可以说明原因：如果一个非周期马尔可夫链具有转移概率矩阵P且它的任何两个状态是连通的，那么$\lim_{n\to \infty} P_{ij}^n$存在且与i无关，记平稳概率分布(stationary distribution)$\lim_{n\to \infty}P_{ij}^n=\pi(j)$.

在一个马尔可夫链上总会找到结点n，从该结点开始每个后续结点的状态概率分布固定，只与转移概率有关而与初始概率无关。

验证马氏链收敛定理的代码

```python
import numpy as np

# 初始概率矩阵
init_probs = np.array([0.1, 0.3, 0.6])
# 转移概率矩阵
transform_probs = np.array([[0.7, 0.1, 0.2], [0.2, 0.5, 0.3], [0.2, 0.4, 0.4]])
# 马尔可夫状态概率分布链
chain = [init_probs]

# 检查chain变量是否已经平稳
def check_stable():
    if len(chain) < 3:
        return False
    for i in range(-2, -1):
        if not np.array_equal(np.around(chain[i], 2), np.around(chain[i-1], 2)):
            return False
    return True

for i in range(10000):
    chain.append(chain[-1].dot(transform_probs))  # 生成新的结点
    print("iter %s: %s" % (i, np.around(chain[-1], 2)))
    if check_stable():  # 如果进入平稳状态则退出
        print("stabel!")
        break
        
        
# 修改代码中的init_probs为任意其他分布，则仍然最后收敛于相同分布
# 修改代码中的transform_probs，则会收敛于一个不同的分布
```

### MCMC推理框架

用蒙特卡洛方法进行贝叶斯推理的基本想法是，在贝叶斯网络所表达的联合分布上进行若干次采样，然后用采样后的样本通过参数估计的方法解决推理问题。比如当需要求某离散型变量网络中概率$P(x=1,y=0)$时，只需采样若干样本，然后求其中取到$x=1,y=0$的样本所占采样总数的比例，就可得到$P(x=1,y=0)$的估计值。这样，蒙特卡洛推理的关键就转移到了"如何进行样本采样"上。

MCMC就是使用马尔可夫链进行采样的蒙特卡洛过程，该方法由M etropolis于1953年提出。如果能在马尔可夫链上构造一个转换概率矩阵，使它在进入平稳状态后收敛于采样的联合分布，则在该马尔可夫链上每个平稳状态结点都是一个取自目标联合分布的样本点。只要用转移矩阵产生新的结点就能不断地得到新的样本。与马氏链收敛定理的python代码不同的是，此时的马尔可夫链上状态通常是多元状态，因此转移概率分布也会是多元概率分布如多元高斯分布多项式分布等，用这些样本就可以进行贝叶斯推理了。

具体实现有集中不同的算法：Metropolis的经典算法基于细致平稳条件(Detailed Balance)、接受率(Acceptance Ratio)等；后来Hastings改进该算法使马氏链能更快收敛，称为Metropolis-Hastings算法；而Stuart和Donald Geman提出的Metropolis-Hastings的一种特殊形式Gibbs sampling是目前贝叶斯MCMC推理的主流采样算法。

### Gibbs采样

Gibbs采样的目标是，在不知道确切的联合分布的情况下，仅仅利用题哦啊见分布采样到符合目标联合分布的样本。它的本质是构造一个从快速收敛到平稳状态的马尔可夫链。

注意：在贝叶斯网络中，每个结点由条件概率分布CPD构成，因此在其中获得各种条件分布比获得联合分布容易。

例如有某个推理需求是求$P(x=1,y=1,z=0)$，则需要对联合分布$P(x,y,z)$进行采样。但是此时联合分布$P(x,y,z)$ 过于复杂难于计算，而条件分布$P(x|y=?,z=?),(y|x=?,z=?),p(z|y=?,x=?)$ 非常容易获得，则可利用如下步骤进行Gibbs采样：

1. 堆积定义初始样本$x_0,y_0,z_0$ (马尔可夫链的初始概率分布并不重要)。
2. 用条件分布$P(x|y=y_0,z=z_0)$ 随机采样一个新的$x$值，计为$x_1$；并用$P(y|x=x_1,z=z_0)$ 采样得$y_1$，用$p(z|x=x_1,y=y_1)$采样得$z_1$。因此得到了样本$x_1,y_1,z_1$(条件分布起到了马尔可夫链上转移概率的作用)。
3. 重复第二步的采样步骤可以一直产生新的样本(每个样本构成了马尔可夫链上的一个结点)。

上述过程可以构造出一个任意长度的马尔可夫链。只有平稳状态下的马尔可夫链才可以真正用于MCMC采样结果，因此Gibbs采样在获取结果时通常跳过最开始的 $n$ 个样本(如n=1000)，只将其后的样本作为真正的采样结果，这个过程被称为burn-in period.

可以将上述的三维特征空间的采样过程轻易地扩展到任意高的纬度，不同点只在于每个迭代中需要用到更多的条件分布逐个计算每个维度的采样值。

### 变分贝叶斯

变分贝叶斯(VB)是除MCMC外另一个重要的近似推理方法，理解VB需要较深的数学功底。泛函是一种描述"函数<->数值"映射关系的工具；变分(Variation)是对泛函的一种处理方法，相当于对函数的微积分处理；变分贝叶斯是用欧拉-拉格朗日方程、平均场定理等变分工具求解的方法。

- 变分贝叶斯的目标

所有的贝叶斯网络推理问题可以归结为某种条件概率或分布的问题，即$P(Z|D)$，其中D是已观测数据，Z是待求参数或无法观测的数据。

由于Z可以是任意多个事件的组合，所以按照概率公式分解$P(Z|D)$ 并求值非常复杂：
$$
P(Z|D) = P(Z_1,Z_2,\cdots,Z_n,|D)=P(Z_1|D)P(Z_2|D,Z_1)\cdots P(Z_n|D,Z_1,Z_n,\cdots)
$$
每个分解项都是一个复杂的条件分布。而利用平均场理论，可以找出另一个概率模型Q使得：
$$
p(Z|D)\approx q(Z)=q(Z_1,Z_2,\cdots,Z_n)=q(Z_1)q(Z_2)\cdots q(Z_n)
$$
这样就把原本求复杂条件分布的问题转化为了求独立事件的概率问题，因此寻找合适的Q分布就成为了VB的目标。

- 用Kullback-Leibler寻找Q分布

Kullback-Leibler是评估两个概率分布之间相似性的工具。而在VB中仍然用该公式衡量$P(Z|D),Q(Z)$ 的近似程度，根据Kullback-Leibler公式的定义，有
$$
KL(qp) = -\int{q(Z)\ln (\frac{p(Z|D)}{q(Z)})}\mathrm{d}Z=\ln(p(D))-\int{q(Z)\ln (\frac{p(Z,D)}{q(Z)})}\mathrm{d}Z
$$
如果设$\zeta {(q)}=\int{q(Z)\ln (\frac{p(Z,D)}{q(Z)})}\mathrm{d}Z$，则有
$$
\ln{(p(D))} = \zeta{(q)} - KL(qp)
$$
最合适的Q分布无疑是使得$KL(qp)$值最小的Q分布，因为$\ln(p(Q))$在给定观测数据的情况下固定，因此最小化$KL(qp)$的任务等同于最大化$\zeta{(q)}$。

对于解决这类优化目标，数学上使用拉格朗日乘子法，或者近似求解算法-EM算法、梯度上升等。

由于$\zeta{(q)}$中参数$q$ 是一个概率分布，在数学上$q$ 本身就是一个函数，则$\zeta{(q)}$ 就是一个泛函，而最大化$\zeta{(q)}$ 的过程就是一个变分过程，这就是变分贝叶斯名称的由来。

- VB与MCMC对比

对比VB和MCMC在推理效果上有如下论断：VB方法合适于数据量非常大、对推理时间要求高的额场景；而MCMC适合于数据规模较小、但对推理精度要求较高的场景。也就是说，VB推理速度更快，MCMC推理效果更好。

## 利用共轭建模

在贝叶斯网络中理论上事件的概率分布函数可以是任意形式的，但在实际建模中常用的是集中供暖经典的概率分布。原因是为什么呢？

### 共轭分布

共轭分布(Conjugate Distribution)的概念来源于对简化贝叶斯公式计算的需求。在$P(A|D)=\frac{P(D|A)P(A)}{P(D)}->P(D|A)P(A)$中，如果允许$P(A|D),P(A),P(D|A)$是任何形式的函数，用该公式计算概率分布时会充斥着分解、积分、求和等运算。

对于指数家族的概率函数来说则无须这样，它们有一个很好的性质，即在贝叶斯公式计算过程中后验$P(A|D)$和先验$P(A)$具有相同的函数形式，并且在计算过程中也不需要分解所有条件并积分。此时，称$P(A|D),P(A)$的分布函数是似然函数$P(D|A)$的共轭分布，特别地，称先验$P(A)$为共轭先验。

常用共轭分布

| 类型         | 似然函数分布          | 共轭分布              | 说明                   |
| ------------ | --------------------- | --------------------- | ---------------------- |
| 离散变量分布 | Bernoulli             | Beta                  | 单次二值事件实验       |
|              | Binomial              | Beta                  | 多次二值事件实验       |
|              | Poisson               | Gamma                 | 单位事件内计数事件实验 |
|              | Categorical           | Dirichlet             | 单次多值事件实验       |
|              | Multinomial           | Dirichlet             | 多次多值事件实验       |
| 连续变量分布 | Gaussian              | Gaussian              | 高斯分布               |
|              | Multivariate Gaussian | Multivariate Gaussian | 多元高斯分布           |
|              | Exponential           | Gamma                 | 时间间隔事件实验       |

### 隐含/显式变量

将共轭分布应用在贝叶斯网络中，就产生了隐含变量(Latent Variable)与显式变量(Manifest Variable)的概念。任何一个独立的不确定性事件可以在贝叶斯网络中用两个变量表示：隐含变量用于表达该事件的先验和后验概率，而显式变量用相对应的似然函数建模。

## 实战

### 诊断需求

<img src="../images/bayesian-network-sample.jpeg" alt="bayesian-network-sample" style="zoom:50%;" />

这是一个经典的贝叶斯网络应用场景，该网络丛上到下分为三层：

1. 第一层是两种生病的原因：最近去过亚洲(假设当时亚洲流行肺结核疾病)、有吸烟习惯。
2. 第二层是三种可能的疾病：肺结核、肺癌、支气管炎。
3. 第三层是病人的症状：X-ray检查是否有异样、呼吸困难。

通过网络中的边可知，是否去过亚洲会影响患肺结核的概率，吸烟会导致肺癌和支气管炎，只有肺结核和肺癌能通过X-ray检查到病灶，但三种疾病都会导致呼吸困难。

所有结点都有是、否两种结果，所以该网络中的所有结点均用Bernoulli建模。利用该网络希望获得的推理能力是给定任何病因或症状的组合，能够计算出患任意一种疾病的概率，比如：

1. 某个病人去过亚洲，且呼吸困难，则他/她患肺结核、肺癌的概率是多少？
2. 某个病人吸烟、X-Ray检查结果异常、呼吸困难，他/她患肺癌的可能性是多少？

### 工具包

BayesPy、PyMC3、Edward、Pomegranate

```shell
pip install pymc3 patsy pandas
```

### 建立模型

```python
import pymc3 as pm

# Model对象表示贝叶斯网络
basic_model = pm.Model()
# 用with语句引入该对象上下文，定义网络内结构
with basic_model:
    # 第一层，病因结点
    asia_p = pm.Beta('asia_p', 5, 95)  # 隐含变量，用于表达变量asia的共轭先验
    asia = pm.Bernoulli('asia', p=asia_p)
    smoking = pm.Bernoulli('smoking', p=0.3)  # 显式变量，没有使用隐含变量，使用固定概率值
    # 第二层，疾病结点
    # Deterministic对象定义隐含变量，该对象用于表示丛其他变量值通过确定性计算获得先验概率。实际描述了不同事件️之间的条件概率表
    tuberculosis_p = pm.Deterministic('tuberculosis_p', pm.math.switch(asia, 0.4, 0.1))  # 表示aisa为True时tuberculosis概率为0.4，aisa为False时tuberculosis概率为0.1
    tuberculosis = pm.Bernoulli('tuberculosis', p=tuberculosis_p)
    cancer_p = pm.Deterministic('cancer_p', pm.math.switch(smoking, 0.3, 0.1))
    cancer = pm.Bernoulli('cancer', p=cancer_p)
    bronchitis_p = pm.Deterministic('bronchitis_p', pm.math.switch(smoking, 0.3, 0.1))
    bronchitis = pm.Bernoulli('bronchitis', p=cancer_p)
    # 第三层，症状结点
    xray_p = pm.Deterministic('xray_p',
                              pm.math.switch(tuberculosis, pm.math.switch(cancer, 0.9, 0.7),
                                             pm.math.switch(cancer, 0.8, 0.1)))
    xray = pm.Bernoulli('xray', p=xray_p)
    dyspnea_p = pm.Deterministic('dyspnea_p',
                                 pm.math.switch(tuberculosis,
                                                pm.math.switch(cancer, pm.math.switch(bronchitis, 1.0, 0.9),
                                                               pm.math.switch(bronchitis, 0.8, 0.7)),
                                                pm.math.switch(cancer, pm.math.switch(bronchitis, 0.7, 0.5),
                                                               pm.math.switch(bronchitis, 0.6, 0.1))))
    dyspnea = pm.Bernoulli('dyspnea', p=dyspnea_p)
 
```

### 采样分析

PyMC3的推理主要通过采样、分析两步完成，其中采样默认使用MCMC方式，并提供若干文本、可视化工具进行分析。

- 采样

MCMC

```python
with basic_model:
    # 使用sample函数直接对模型进行采样，采样会自动根据网络中的结点分析分布类型选择合适的采样算法。
    trace = pm.sample(100)   
    # 变量trace是一个MultiTrace类型的对戏那个，可以通过它的points()方法获得轮询采样结果的迭代器
    for i, s in enumerate(trace.points()):
        print(i, s)
```

变分贝叶斯

```python
with basic_model:
	approx = pm.fit()
    trace = approx.sample(1000)
    
# 相对于MCMC，计算速度更快，适合网络较复杂的连续类型分布推理
```

- 分析

```python
with basic_model:
    # 使用summary函数获得采样总体的统计结果
    print(pm.summary(trace))
    # 变量分析
    # mean：均值，即预测值。如果没有任何观测值，该值与网络中的先验概率相近
    # sd：衡量变量数据值的集中程度
    # mc_error：蒙特卡洛统计的可信度，样本数越多该值越小(越好)
    # hdp：样本最集中值域的长度。hdp_2.5是最集中的2.5%样本，hdp_97.5是最集中的97.5%样本，该值一般与sd有反向关联
    # n_eff：有效样本数
```

- 可视化

```python
import matplotlib.pyplot as plt

with basic_model:
    # 绘制分析采样结果
    # 参数varnames是可选参数，用于指定需要绘制的变量，若不指定，则绘制网络中所有变量
    pm.traceplot(trace, varnames=['xray_p', 'xray'])
    plt.show()
```

### 近似推理

在pyMC3中，推理是输入已观测额到的数据并对模型进行采样和分析的过程。

配置已观测数据

```python
with basic_model:
    # 省略其他变量定义
    # 已观测数据通过结点显式变量的observed属性进行配置
    asia = pm.Bernoulli('asia', p=asia_p, observed=False)
    smoking = pm.Bernoulli('smoking', p=0.3, observed=True)
    xray = pm.Bernoulli('xray', p=xray_p, observed=True)
    dyspnea = pm.Bernoulli('dyspnea', p=dyspnea_p, observed=True)
```

完成推理

```python
with basic_model:
    # 通过采样与分析完成推理
    trace = pm.sample(1000)
    print(pm.summary(trace, varnames=['tuberculosis', 'cancer', 'bronchitis']))
```

