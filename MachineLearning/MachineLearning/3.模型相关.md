# 模型相关

## 数据集                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  

离散型数据：由于记录不同类别个体的数目所获得的数据，又称计数数据，不能再细分，也不能提高精度

连续型数据：变量可以在某个范围内取任一数，即变量的取值可以是连续的，这类数据通常是非整数，含有小数部分

### 常用数据集

> 流行的开发数据存储库

Kaggle网址：<https://www.kaggle.com/datasets>

UCI数据集网址：<http://archive.ics.uci.edu/ml/>

Amazon的AWS数据集：<http://aws.amazon.com/fr/datasets/>

scikit-learn网址：[http://scikit-learn.org/stable/datasets/index.html#datasets](http://scikit-learn.org/stable/datasets/index.html)

> 元门户网站

<http://dataportals.org/>

<http://opendatamonitor.eu/>

<http://quandl.com/>

> 其他页面

维基百科的机器学习数据集<https://goo.gl/SJHN2k>

Quora.com 问题<http:/goo.gl/zDR78y>

Datasets subreddit<https://www.reddit.com/datasets>

> 经典数据集

[MINIST](http://yann.lecun.com/exdb/mnist/)

[CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html?usg=alkjrhjqbhw2llxlo8emqns-tbk0at96jq)

下载数据集

```python
import os
import tarfile
from six.moves import urllib

DOWNLOAD_ROOT = "https://raw.githubusercontent.com/ageron/handson-ml/master/"
HOUSING_PATH = os.path.join("datasets", "housing")
HOUSING_URL = DOWNLOAD_ROOT + "datasets/housing/housing.tgz"

def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):
    os.makedirs(housing_path, exist_ok=True)
    tgz_path = os.path.join(housing_path, "housing.tgz")
    urllib.request.urlretrieve(housing_url, tgz_path)
    housing_tgz = tarfile.open(tgz_path)
    housing_tgz.extractall(path=housing_path)
    housing_tgz.close()
```

### 数据集划分

- 训练集与测试集

训练数据：用于训练，构建模型

测试数据：用于校验，测试模型是否有效

划分比例：`70:30, 80:20, 75:30`

作用：可以测试模型的泛化能力

```python
import numpy as np


# 保证同一数据集测试数据的一致性和灵活性：使用seed
def train_test_split(X, y, test_ratio=0.2, seed=None):
    """将数据 X 和 y 按照test_ratio分割成X_train, X_test, y_train, y_test"""
    assert X.shape[0] == y.shape[0], \
        "the size of X must be equal to the size of y"
    assert 0.0 <= test_ratio <= 1.0, \
        "test_ration must be valid"
    if seed:
        np.random.seed(seed)
    shuffled_indexes = np.random.permutation(len(X))
    test_size = int(len(X) * test_ratio)
    test_indexes = shuffled_indexes[:test_size]
    train_indexes = shuffled_indexes[test_size:]
    X_train, y_train = X[train_indexes], y[train_indexes]
    X_test, y_test= X[test_indexes], y[test_indexes]

    return X_train, X_test, y_train, y_test


# 保证获取更新后数据集测试数据的一致性：标识符
from zlib import crc32

def test_set_check(identifier, test_ratio):
    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32

def split_train_test_by_id(data, test_ratio, id_column):
    ids = data[id_column]
    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))
    return data.loc[~in_test_set], data.loc[in_test_set]

```

- 随机采样

一般来说，两个集合的划分需要加入随机因子，使得每个数据项有相等的机会被分到任一集合中。

- 分层采样

划分数据集时的一个常见陷阱是每种标签的数据没有均匀地被划分到训练集和测试集中。

分层采样就是一种在划分训练/测试集时保持标签数据比例的采样规则。

- 验证集

是在某个模型的学习过程中用来调试超参数的数据集。

如果有足够多数据，划分三个子集的数量保持如下不等式可以提高模型的泛化能力：训练集<验证集<测试集

## 模型类别

- 形式上

> 概率模型

利用训练样本数据，通过学习条件概率分布$ P(Y|X) $来进行推断决策

> 非概率模型

通过学习决策函数$Y=f(x)$来进行推断

- 算法上

联合概率分布：假设输入输出的随机变量$X$ 和 $Y$ 遵循联合概率分布 $P(X, Y)$

> 生成模型

模型学习联合概率分布 $P(X,Y)$，然后求出$P(Y|X)=\frac{P(X,Y)}{P(X)}$。

之所以称为生成模型，是因为模型不仅可以用来预测结果输出${argmax_y}(P(Y|X))$，还可以通过联合分布$P(X,Y)$来生成新的样本数据集$(x_i, y_i)$。

典型生成模型：朴素贝叶斯、隐马尔可夫

优缺点

```
1.生成模型可以还原联合概率，而判别模型不行
2.学习收敛速度快，当岩本容量增加时，学到的模型可以更快收敛
3.当存在隐变量时，可以使用生成模型，而判别模型不行
```

> 判别模型是：

直接求取条件概率分布$P(Y|X)$或决策函数$Y=f(X)$

判别模型并不需要关心X和Y之间的生成关系，它直接关心的是对于给定的输入X应该得到怎样的输出Y。

大部分的分类模型都属于判别模型，包括：k近邻、感知机、决策树、逻辑回归、SVM、条件随机场等

优缺点

```
1.直接学习决策函数或条件概率，学习的准确率更高
2.可以对数据进行抽象，定义特征和使用特征，可以简化学习问题
```

## 模型选择

- 理论支持

最大似然估计

奥卡姆剃刀定理

没有免费的午餐定理

模型是观察的简化，这个简化是丢弃了那些不大可能泛化至新实例上的多余细节。但是，要决定丢弃哪些数据以及保留哪些数据，必须要做出假设。如线性模型基于的假设为：数据基本上都是线性的，而实例与直线之间的距离都只是噪声，可以忽略它们。

没有免费午餐定理：如果你对数据绝对没有任何假设，那么你就没有理由会偏好于某个模型。

对不同的数据集，最佳模型可能是不同的。不存在一个先验模型能保证一定工作得更好。要想知道哪个模型最好的方法是对所有模型进行评估，但是实际上是不可能的，因此才会对数据做出一些合理的假设，然后只评估部分合理的模型。如：对于简单的任务，可能只会评估几个具有不同正则化水平的线性模型，而对于复杂问题，可能会评估多个神经网络模型。

![scikit-learn算法选择路径图](images/scikit-learn算法选择路径图.png)

## 拟合泛化

**欠拟合**：算法所训练的模型不能完整表述数据间的关系

**过拟合**：算法所训练的模型过多地表达了数据间的噪音关系

欠拟合也被称为模型具有高**偏差**，过拟合也被称为高**方差**

##  偏差方差均衡

Bias Variance Trade off

模型误差 = 偏差(Bias) + 方差(Variance) + 不可避免的误差

常见现象

```
偏差和方差通常是矛盾的，降低偏差，会提高方差；降低方差，会提高偏差

对于高偏差模型，模型在验证集的表现与在训练集上的表现类似；
对于高方差模型，模型在验证集的表现远远不如在训练集的表现。
```

偏差产生原因

```
对问题本身的假设不正确
如非线性回归使用线性回归，造成欠拟合
如特征选取错误
```

方差产生的原因

```
使用的模型太复杂
如高阶多项式回归，造成过拟合
```

算法原因

```
有一些算法天生是高方差的算法，如knn
非参数学习通常都是高方差算法，因为不对数据进行任何假设

有一些算法天生是高偏差的算法，如线性回归
参数学习通常都是高偏差算法，因为对数据具有极强的假设

大多数算法具有相应的参数，可以调整偏差和方差
如knn中的k,线性回归中使用多项式回归
```

机器学习算法的主要挑战，是方差

解决高方差的常用手段

```
1. 降低模型复杂度
2. 减少数据维度，降噪
3. 减少特征量
3. 增加样本数
4. 使用验证集
5. 模型正则化
6. 增大正则中的系数
```

解决高偏差的常用方法

```
1.增加特征量
2.增加模型复杂度
3.降低正则中的系数
```

## 损失函数

损失函数是机器学习中预测模型一次预测结果好坏的函数，它是一个非负实数值函数，用$L(Y, f(X))$ 来表示，常用的损失函数有

- 0-1损失函数

0-1损失函数比较的是预测值与真实值是否相同
$$
L(Y,f(X))=
\begin{cases}
1, & Y=f(X)\\
0, & Y\ne f(X)
\end{cases}
$$
0-1损失函数是一个非凸函数，在求解过程中，存在很多不足。常作为衡量指标，而不是最优化的目标函数。

- 平方损失函数

线性回归模型常用的最优化目标函数
$$
L(Y, f(X))=(Y-f(x))^2
$$

- 对数损失函数

常用于分类模型的最优化目标函数
$$
L(Y, f(X))= -\ln P(Y|X)
$$

- Hinge损失函数

也称为最大间隔目标函数，是SVM采用的最优化目标
$$
L(Y, f(X))= \max (0, 1-Y *f(X))
$$
对于任意给定的损失函数，可以求得平均一一下的期望损失函数，期望损失函数也称为期望风险函数
$$
R_{exp}(f)=E(L(Y, f(X)))=\int{L(Y, f(X))P(x,y)dxdy}
$$
机器学习的目标是使期望风险函数最小，但由于联合分布函数 $P(x,y)$ 是不知道的，因此在实际应用中，通常的优化目标是经验风险最小化。

假设现有训练数据集
$$
T = \{(x_1, y_1),(x_2, y_2),\cdots, (x_N, y_N)\}
$$
模型 $f(x)$ 关于训练数据集T的经验风险函数为
$$
R_{emp}(x)=\frac{1}{N}{\sum_{i=1}^{N}L(y_i, f(x_i))}
$$
事实上，由概率论的大数定理可知，当N无穷大时，有
$$
\lim_{N \to \infty}{R_{emp}(f)}=R_{exp}(f)
$$


## 模型正则化

Regularization，限制参数的大小，可以提高模型泛化

- 原理

在线性回归的损失函数
$$
\sum_{i=1}^m{(y^{(i)}-\theta_0-\theta_1X_1^{(i)}-\ldots-\theta_nX_n^{(i)})^2}
$$
也就是
$$
J(\theta) = MSE(y, \hat{y}; \theta)
$$
加入模型正则化
$$
J(\theta) = MSE(y, \hat{y}; \theta) + \alpha\frac{1}{2}\sum_{i=1}^n{\theta_i^2}
$$

- L1、L2、L0正则

$L_p$范数
$$
\Arrowvert{x}\Arrowvert_p = (\sum_{i=1}^n{\arrowvert{x_i}\arrowvert^p})^{\frac{1}{p}}
$$
Ridge添加正则化部分
$$
\sum_{i=1}^n{\theta_i^2}
$$
被称为L2正则项

LASSO添加正则化部分
$$
\sum_{i=1}^n{\arrowvert{\theta_i}\arrowvert}
$$
被称为L1正则项
$$
J(\theta) = MSE(y, \hat{y}; \theta) + min\{number-of-non-zero-\theta\}
$$
使$J(\theta)$中$\theta$个数尽可能少，即为L0正则项

对于L0正则的优化是一个NP难的问题，通常使用L1取代L0

- 弹性网(Elastic Net)

$$
J(\theta) = MSE(y, \hat{y}; \theta) + r\alpha\sum_{i=1}^n\arrowvert{\theta_i}\arrowvert + \frac{1-r}{2}\alpha\sum_{i=1}^n{\theta_i^2}
$$

- 实现

回归算法中使用模型正则化来提高泛化能力的有岭回归、拉索回归等

- 应用

通常来说，有正则化总是比没有更可取，大多数情况下，应该避免使用纯线性回归。岭回归是不错的默认选择。

如果实际用到的特征只有少数几个，更倾向于使用Lasso回归或弹性网络，因为他们会将无用的特征的权重降为0。

一般而言，弹性网络优于Lasso回归，因为当特征数量超过训练实例数量，或者几个特征强相关时，Lasso回归的表现可能非常不稳定。

- 早期停止法

对于梯度下降这类迭代学习的算法，又一个特殊的正则化方法，就是在验证误差达到最小值时停止训练，该方法叫做**早期停止法**。

经过一轮一轮的训练，算法不停地学习，训练集上的预测误差自然不断下贱，同样其在验证集上的预测误差也随之下降。到那时，一段时间之后，验证误差停止下降反而开始回升。这说明模型开始过度拟合训练数据。

通过早期停止法，一旦试验误差达到最小值就立刻停止训练。对于随机梯度下降和小批量梯度下降来说，曲线没有那么平滑，很难知道是否已经达到最小值，解决方法是等验证误差超过最小值一段时间之后再停止(此时模型不会变得更好了)，然后将模型参数回滚到验证误差最小时的位置。

## 验证曲线

不断调整模型的复杂度，可以得到训练得分和验证得分的图形，称为验证曲线。有如下特征

```
1.训练得分肯定高于验证得分，一般情况下，模型拟合自己接触过的数据，比拟合没接触过的数据效果要好
2.使用复杂度较低的模型(高偏差)时，训练数据往往欠拟合，说明模型对训练数据和新数据都缺乏预测能力
3.使用复杂度较高的模型(高方差)时，训练数据往往过拟合，说明模型对训练数据预测能力很强，但是对新数据的预测能力很差
4.当使用复杂度适中的模型时，验证曲线得分最高，说明在该模型复杂度条件下 ，偏差与方差达到均衡状态
```

## 学习曲线

随着训练样本的逐渐增多，算法训练出的模型的表现能力变化。反映训练集规模的训练得分/验证得分曲线被称为学习曲线。有如下特征

```
1.特定复杂度的模型对较小的数据集容易过拟合：此时训练得分较高，验证得分较低
2.特定复杂度的模型对较大的数据集容易欠拟合：随着数据的增大，训练得分会不断降低，而验证得分会不断升高
3.模型的验证集得分永远不会高于训练集得分：两条曲线一直在靠近，但永远不会交叉
```

示例

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler

np.random.seed(666)
x = np.random.uniform(-3.0, 3.0, size=100)
X = x.reshape(-1, 1)
y = 0.5 * x ** 2 + x * 2 + np.random.normal(0, 1, size=100)

# plt.scatter(x, y)
# plt.show()
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)
print(X_train.shape)

train_score = []
test_score = []
for i in range(1, 76):
    lin_reg = LinearRegression()
    lin_reg.fit(X_train[:i], y_train[:i])
    y_train_predict = lin_reg.predict(X_train[:i])
    train_score.append(mean_squared_error(y_train[:i], y_train_predict))
    y_test_predict = lin_reg.predict(X_test)
    test_score.append(mean_squared_error(y_test, y_test_predict))

# plt.plot([i for i in range(1, 76)], np.sqrt(train_score), label="train")
# plt.plot([i for i in range(1, 76)], np.sqrt(test_score), label="test")
# plt.legend()
# plt.show()


# 封装函数
def plot_learning_curve(algo, X_train, X_test, y_train, y_test):
    train_score = []
    test_score = []
    for i in range(1, 76):
        algo.fit(X_train[:i], y_train[:i])
        y_train_predict = algo.predict(X_train[:i])
        train_score.append(mean_squared_error(y_train[:i], y_train_predict))
        y_test_predict = algo.predict(X_test)
        test_score.append(mean_squared_error(y_test, y_test_predict))

    plt.plot([i for i in range(1, 76)], np.sqrt(train_score), label="train")
    plt.plot([i for i in range(1, 76)], np.sqrt(test_score), label="test")
    plt.legend()
    plt.axis([0, len(X_train) + 1, 0, 4])
    plt.show()

# 线性回归调用
plot_learning_curve(LinearRegression(), X_train, X_test, y_train, y_test)


# 多项式回归调用
def PolynomialRegression(degree):
    return Pipeline([
        ("poly", PolynomialFeatures(degree=degree)),
        ("std_scaler", StandardScaler()),
        ("lin_reg", LinearRegression())
    ])


poly2_reg = PolynomialRegression(degree=2)
plot_learning_curve(poly2_reg, X_train, X_test, y_train, y_test)
# 过拟合调用
poly20_reg = PolynomialRegression(degree=20)
plot_learning_curve(poly20_reg, X_train, X_test, y_train, y_test)
```

## 交叉验证

Cross Validation

训练数据：训练模型使用的数据集

验证数据：调整超参数使用的数据集

测试数据：作为衡量最终模型性能的数据集

如果对所有的数据进行模型训练，则可能造成过拟合，上线后无法进行模型调整，故需要测试数据集

如是仅仅用测试数据集对模型进行验证调整，则可能造成针对特定测试数据集过拟合，故在数据中随机使用部分数据作为验证数据集

有了验证数据，则可以在数据训练时采用验证数据进行验证来调整超参数，之后再用测试数据集进行测试，但是随机带来新的问题，验证数据可能存在极端情况，会造成对验证数据集的过拟合，故需要交叉验证

缺点

```
把训练集分成k份，称为k-folds cross validation，每次训练K个模型，整体性能慢了k倍
```

留一法

```
LOO-CV
有m个样本，把训练数据集分成m份， 称为留一法，Leave-One-Out Cross Validation

优点：
完全不受随机的影响，最接近模型真正的性能指标
缺点：
计算量大
```

示例

```python
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

digits = datasets.load_digits()
X = digits.data
y = digits.target

# 测试数据集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=666)

# 手动循环超参数验证
best_score, best_p, best_k = 0, 0, 0
for k in range(2, 11):
  	for p in range(1, 6):
      	knn_clf = KNeighborsClassifier(weights="distance", n_neighbors=k, p=p)
        knn_clf.fit(X_train, y_train)
        score = knn_clf.score(X_test, y_test)
        if score > best_score:
          	best_score = score
            best_p = p
            best_k = k
print("best_score", best_score)
print("best_p", best_p)
print("bset_k", best_k)

# 交叉验证
knn_clf = KNeighborsClassifier()
cross_val_score(knn_clf, X_train, y_train)
# cross_val_score(knn_clf, X_train, y_train, cv=5)  # 指定训练集分割份数
best_score, best_p, best_k = 0, 0, 0
for k in range(2, 11):
  	for p in range(1, 6):
      	knn_clf = KNeighborsClassifier(weights="distance", n_neighbors=k, p=p)
        scores = cross_val_score(knn_clf, X_train, y_train)
        score = np.mean(scores)
        if score > best_score:
          	best_score = score
            best_p = p
            best_k = k
print("best_score", best_score)
print("best_p", best_p)
print("bset_k", best_k)

best_knn_clf = KNeighborsClassifier(weights="distance", n_neighbors=2 p=2)
best_knn_clf.fit(X_train, y_train)
score = best_knn_clf.score(X_test, y_test)
print(score)

# 网格搜索
param_grid = [
  {
    'weights': ['distance'],
    'n_neighbors': [ i for i in range(2, 11)],
    'p': [i for i in range(1, 6)]
  }
]
grid_search = GridSearchCV(knn_clf, param_grid, verbose=1)
# GridSearchCV(knn_clf, param_grid, verbose=1, cv=5)  # 指定训练集分割份数
grid_search.fit(X_train, y_train)
print(grid_search.best_score_)
print(grid_search.best_params_)
best_knn_clf = grid_search.best_estimator_
best_knn_clf.score(X_test, y_test)
```

## 网格搜索

在实际工作中，模型通常有多个得分转折带你，因此验证曲线和学习曲线的图形会从二维曲线变成多维曲线。这种高纬可视化很难展现，因此从图中找出验证得分的最大值不是一件简单的事。

模型参数：算法过程中学习的参数

超参数：在算法运行前需要决定的参数

超参数选择方法：领域知识、经验数值、实验（网格）搜索

在网格搜索中每组超参数都采用交叉验证来进行评估。

自定义实现

```python
best_method = ""
best_score = 0.0
best_k = -1
for method in ["uniform", "distance"]:
		for k in range(1, 11):
  			knn_clf = KNeighborsClassifier(n_neighbors=k)
    		knn_clf.fit(X_train, y_train)
    		score = knn_clf.score(X_test, y_test)
    		if score > best_score:
      			best_k = k
      			best_score = score
            best_method = method
print("best_k = ", best_k)
print("best_score = ", best_score)
print("best_method = ", best_method)
```

## 评估指标

### 回归

- 平均绝对误差(Mean Absolute Error)

这是给定数据集的所有数据点的绝对误差平均值。优势是在于当误差较大时不会变得更陡峭，缺点是在目标值附近不平滑会导致不能很好地收敛。
$$
MAE = \frac{\sum_{i=1}^m y_{test}^{(i)}-\hat{y}_{test}^{(i)}\arrowvert}{m}
$$

计算绝对值的总和，对应 $l_1$范数，记作 $||\cdot||_{1}$。

- 均方误差(Mean Squared Error)

给定数据集的所有数据点的误差的平方的平均值。优势是在目标值附近有更好的曲度便于收敛。
$$
MSE = \frac{\sum_{i=1}^m{(y_{test}^{(i)}-\hat{y}_{test}^{(i)})^2}}{m}
$$



- 均方根误差(Root Mean Squared Error)

$$
RMSE = \sqrt{MSE}
$$

计算平方和的根，对应 $l_2$ 范数，记为 $||\cdot||_{2}$。

相对MSE，可降低量纲的影响。相对MAE，更关注大的价值，忽略小的价值，异常值稀少时，表现更优异。

- 中位数绝对误差(median absolute error)

给定数据集的所有数据点的误差的中位数。这个指标的主要优点是可以消除异常值的干扰。测试数据集中的单个坏点不会影响整个误差指标，均值误差指标会受到异常点的影响。

- 解释方差分(explained variance score)

这个分数用于衡量我们的模型对数据集波动的解释能力。如果得分1.0，表明模型完美。


- R方

也被称为**判定系数**，用于河梁模型与目标值均值的对比结果。

其值小于等于1，等于1表示模型与数据吻合·，等于0表示模型不比简单取均值好，小于0表示模型还不如基准模型，可能不存在任何线性关系。
$$
\begin{aligned}
R^2 
&=  1 - \frac{SS_{redidual}}{SS_{total}} \\
&=1 - \frac{\sum_i{(\hat{y}^{(i)}-y^{(i)})^2}}{\sum_i{(\bar{y}^{(i)}-y^{(i)})^2}}\\
&=1 - \frac{(\sum_{i=1}^m{(\hat{y}^{(i)}-y^{(i)})^2})/m}{(\sum_{i=1}^m{(\bar{y}^{(i)}-y^{(i)})^2})/m} \\
&= 1 - \frac{MSE(\hat{y}, y)}{Var(y)}
\end{aligned}
$$

自定义实现

```python
# metrics.py
import numpy as np
from math import sqrt


def accuracy_score(y_true, y_predict):
    """计算y_true和y_predict之间的准确率"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum(y_true == y_predict) / len(y_true)


def mean_squared_error(y_true, y_predict):
    """计算y_true和y_predict之间的MSE"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum((y_true - y_predict)**2) / len(y_true)


def root_mean_squared_error(y_true, y_predict):
    """计算y_true和y_predict之间的RMSE"""

    return sqrt(mean_squared_error(y_true, y_predict))


def mean_absolute_error(y_true, y_predict):
    """计算y_true和y_predict之间的RMSE"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum(np.absolute(y_true - y_predict)) / len(y_true)


def r2_score(y_true, y_predict):
    """计算y_true和y_predict之间的R Square"""

    return 1 - mean_squared_error(y_true, y_predict)/np.var(y_true)

```

sklearn实现

```python
# 均方误差
from sklearn.metrics import mean_squared_error


# 根均方误差
sqrt(mean_squared_error())

# 平均绝对误差
from sklearn.metrics import mean_absolute_error


# R方
from sklearn.metrics import r2_score
```

### 分类

- 准确度

$$
accuracy = \frac{\sum_{i=1}^m{(y_{test}^{(i)}==\hat{y}_{test}^{(i)})}}{m}
$$

对于极度偏斜(Skewed Data)的数据，分类准确度时不够的，这时可用精准率/召回率

- 精准率/召回率

1为关注的事件(Positive)，0为对立事件(Negative)

| 真实\预测 | 0    | 1    |
| --------- | ---- | ---- |
| 0         | TN   | FP   |
| 1         | FN   | TP   |

**精准率**：表示的是预测为正的样本中有多少是真正的正样本。有两种可能：把正类预测为正类(TP)，是把负类预测为正类(FP)。
$$
precision = \frac{TP}{TP+FP}
$$
**召回率**：表示的是样本中的正例有多少被预测正确了。有两种可能：把原来的正类预测成正类(TP)，把原来的正类预测为负类(FN)。
$$
recall = \frac{TP}{TP+FN}
$$
- F1 Score

反应了模型的稳健性，是precision和recall的调和平均值
$$
\frac{1}{F1} = \frac{1}{2}(\frac{1}{precision}+\frac{1}{recall}) 
$$
得到
$$
\\
F1 = \frac{2\cdot{precision}\cdot{recall}}{precision+recall}
$$

- Kappa

衡量两个评价者之间的一致性，考虑的是评价者在没有完全意识的情况下达成一致的可能性。计算方法如下
$$
k = 1- \frac{1-p_{观察}}{1-p_{偶然}}
$$
这个两个值分别表示评价者之间观察一致性和偶然一致性的概率。系数$k$ 在0（完全不一致）和1（完全一致）之间。事实上，$p_{观察}=1,p_{偶然}=0$ 则$k=1$，$p_{观察}=0,p_{偶然}=0$ 则$k=0$。所有中间值表示可能由特定选择或偶然性引起的不一致。因此，当需要评估随机选择对标准精度计算的可能影响时，该度量时有用的。

通常，当$k>0.8$时，一致性非常高，$0.4<k<0.8$ 时，表示具有一定不确定性的一致性。较低的结果显示几乎不一致，估计者不可信。

此度量值与二元混淆矩阵存在很强的联系
$$
p_{观察} = \frac{TP + TN}{TP+TN+FP+FN}\\
p_{偶然} = p_{正面}+p_{负面} \\
p_{正面} = \frac{TP + FN}{TP+TN+FP+FN} \cdot \frac{TP + FP}{TP+TN+FP+FN} \\
p_{负面} = \frac{TN + FP}{TP+TN+FP+FN} \cdot \frac{TN + FN}{TP+TN+FP+FN} \\
k = 1- \frac{1-p_{观察}}{1-p_{偶然}}
$$

- PR曲线

precision_recall_curve

随着阈值的变化，精准率和召回率呈现反向变化的情况，阈值越高，精准率越高，召回率越低，阈值越低，精准率越低，召回率越高

mAP是为结局P、R、F-measure的单点值局限性的

均衡：召回率（TPR）越高，精度越低。

比较：召回率*精准率的面积越大，则map越大，模型越好

- ROC/AUC曲线

Receiver Operation Characteristic Curve，受试者工作特征曲线。

描述TPR和FPR之间的关系， 可用于比较不同的模型好坏。

其中，TPR叫做 真正类率，TNR叫做 真负类率（特异度），FPR叫做假正类率


$$
TPR = Recall = \frac{TP}{TP+FN} \\
TNR = \frac{TN}{TN+FP}\\
FPR = 1-TNR = \frac{FP}{TN+FP}
$$

均衡：召回率（TPR）越高，分类器产生的假正类（FPR）就越多。

比较：分类器比较，测量曲线下面积（AUC）越接近1则分类器越好。

> PR/ROC选择
>
> 当正类非常少见或更关注假正例而不是假负例时，选择PR曲线，否则选择ROC曲线

- 实现

自实现

```python
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

digits = datasets.load_digits()
X = digitis.data
y = digitis.target.copy()
# 对数据手动偏斜
y[digits.target==9] = 1
y[digits.target!=9] = 0

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)

def TN(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 0)&(y_predict == 0))

def FP(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 0)&(y_predict == 1))
  
def FN(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 1)&(y_predict == 0))
  
def TP(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 1)&(y_predict == 1))
  
def confusion_matrix(y_true, y_predict):
		return np.array([
      	[TN(y_test, y_predict), FP(y_test, y_predict)],
      	[FN(y_test, y_predict), TP(y_test, y_predict)]
    ])

def precision_score(y_true, y_predict):
  	tp = TP(y_test, y_predict)
    fp = FP(y_test, y_log_predict)
    try:
      	return tp / (tp + fp)
    except:
      	retunr 0.0
  
def recall_score(y_true, y_predict):
  	tp = TP(y_test, y_predict)
    fn = FN(y_test, y_predict)
    try:
    		return tp / (tp + fn)
    except:
      	return 0.0
      
def f1_score(y_true, y_predict):
  	precision = precision_score(y_true, y_predict)
    recall = recall_score(y_true, y_predict)
  	try:
      	return 2 * precision*recall / (precision + recall)
    except:
      	return 0.0
      
def TPR(y_true, y_predict):
  	tp = TP(y_true, y_predict)
    fn = FN(y_true, y_predict)
    try:
      	return tp / (tp + fn)
    except:
      	return 0.

def FPR(y_true, y_predict):
  	fp = FP(y_true, y_predict)
    tn = TN(y_true, y_predict)
    try:
      	return fp / (fp + tn)
    except:
       	return 0.
  
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
log_reg.score(X_test, y_test)  # 准确度

y_log_predict = log_reg.predict(X_test)

TN(y_test, y_log_predict)
FP(y_test, y_log_predict)
FN(y_test, y_log_predict)
TP(y_test, y_log_predict)
confusion_matrix(y_test, y_log_predict)  # 混淆矩阵
precision = precision_score(y_test, y_log_predict)  # 精确度
print(precision)
recall = recall_score(y_test, y_log_predict)  # 召回率
print(recall)
f1_score = f1_score(y_test, y_log_predict)  # f1
print(f1_score)

# 决策函数返回score值，>0则预测为1，<0则预测为0
decision_scores = log_reg.decision_function(X_test)

# 使用5作为预测结果阈值
y_predict_2 = np.array(decision_scores >= 5, dtype='int')
confusion_matrix(y_test, y_predict_2)
precision = precision_score(y_test, y_predict_2)
recall = recall_score(y_test, y_predict_2)
f1_score = f1_score(y_test, y_predict_2)

# 自定义绘图precision-recall曲线
precisions = []
recalls = []
thresholds = np.arrange(np.min(decision_scores), np.max(decision_scores), 0.1)
for threshold in thresholds:
  	y_predict = np.array(decision_scores >= threshold, dtype='int')
    precisions.append(precision_score(y_test, y_predict))
    recalls.append(recall_score(y_test, y_predict))
    
plt.plot(thresholds, precisions)
plt.plot(thresholds, recalls)
plt.show()
plt.plot(precisions, recalls)
plt.show()

# ROC曲线
fprs = []
tprs = []
thresholds = np.arrange(np.min(decision_scores), np.max(decision_scores), 0.1)
for threshold in thresholds:
  	y_predict = np.array(decision_scores >= threshold, dtype='int')
    fprs.append(FPR(y_test, y_predict))
    tprs.append(TPR(y_test, y_predict))
    
plt.plot(fprs, tprs)
plt.show()
```

### 聚类

度量聚类算法的一个好方法是观察集群被分散的离散程度。这些集群是不是被分离得很合理？一个集群中所有的数据点是不是足够紧密？

- 轮廓系数

Silhouette Coefficient
$$
s_i = \frac{b_i-a_i}{max\{a_i,b_i\}}\\

s_i = \begin{cases}
			 1-\frac{a_i}{b_i},&a_i<b_i\\
			 0, & a_i=b_i\\
			 \frac{b_i}{a_i}-1, & a_i>b_i
			 \end{cases}
$$
计算样本i到同簇其他样本的平均距离$a_i$。$a_i$越小，说明样本i越应该被聚类到该簇。将$a_i$称为样本i的簇内不相似度。

计算样本i到其他某簇$C_j$的所有样本的平均距离$b_{ij}$，称为样本i与簇$C_j$的不相似度。定义为样本i的簇间不相似度：$b_i=min\{b_{i1},b_{i2},…,b_{ik}\}$

$s_i$接近1，则说明样本i聚类合理

$s_i$接近-1，则说明样本i更应该分类到另外的簇

$s_i$近似为0，则说明样本i在两个簇的边界上

- 基于样本标记的评价方法

因为聚类通常作为无监督方法应用，所以这种对于类的标记并不总是容易获得。然而，在某些情况下，训练集可能已经被标记，因而在预测新样本的类之前评估模型十分必要。

常用方法：同质性、完整性、修正兰德指数

## 模型保存与加载

svm模型

```python
# 保存模型
import pickle
with open("./svm.model", "wb") as f:
    pickle.dump(svc, f)

# 加载模型
with open("./svm.model", "rb") as f:
    svc = pickle.load(f)
```

## 向量化

有向量
$$
w = (w^{(1)}, w^{(2)}, ...,w^{(m)})
$$

$$
v = (v^{(1)}, v^{(2)},...,v^{(m)})^T
$$

可将如下求和公式
$$
\sum_{i=1}^m{w^{(i)}\cdot v^{(i)}}
$$
向量化
$$
w\cdot v
$$
向量化可以提高运算速度

```python
# 非向量化
sum = 0
for i in range(m):
    sum += w^i * v^i   
    
# 向量化
sum = np.dot(W.T, v)
```

## 最小二乘法

所谓最小二乘，其实也可以叫做最小平方和，其目的就是通过最小化误差的平方和，使得拟合对象无限接近目标对象。换句话说，最小二乘法可以用于对函数的拟合。
$$
\min e^2 = (y-\hat{y})^2
$$

## 梯度下降

梯度下降法(gradient descent)是一种常用的一阶(first-order)优化方法，是求解无约束优化问题最简单、最经典的方法之一。

考虑一个无约束优化问题$\min\limits_{x}f(x)$,  其中$f(x)$为连续可微函数，如果我们能够构造一个序列 $ x^0, x^1,\cdots$ ，并能够满足：
$$
f(x^{t+1}) < f(x^t), t=0,1,2,\cdots
$$
那么我们就能够不断执行该过程即可收敛到局部极小点。

如何找到下一个点 $x^{t+1}$，并保证$f(x^{t+1}<f(x^t))$ 呢？

假设当前的函数的形式是开口向上的抛物线形状，现在我们随机找了一个初始的点 $x_1$，对于一元函数来说，函数值只会随着$x$的变化而变化，那么我们就设计下一个 $x^{t+1}$ 是从上一个 $x^t$ 沿着某一方向走一小步 $\Delta x$ 得到的。

这一小步的方向是朝向哪里？

对于一元函数来说，$x$ 是会存在两个方向：要么是正方向（$\Delta x >0$），要么是负方向（$\Delta x < 0$），如何选择每一步的方向，就需要用到泰勒公式。

先看一下下面这个泰勒展式：
$$
f(x + \Delta x) \approx f(x)+\Delta x \nabla f(x)
$$
左边就是当前的 $x$  移动一小步 $\Delta x$ 之后的下一个点位，它近似等于右边。前面我们说了关键问题是找到一个方向，使得$f(x + \Delta x) < f(x)$，那么根据上面的泰勒展式，显然我们需要保证：
$$
\Delta x \nabla f(x) < 0
$$
可选择令：
$$
\Delta x = - \alpha \nabla f(x), (\alpha>0)
$$

其中步长 $\alpha$ 是一个较小的正数，从而： 
$$
\Delta x \nabla f(x) = - \alpha (\nabla f(x))^2
$$

由于任何不为0的数的平方均大于0，因此保证了

$$
\Delta x \nabla f(x) < 0
$$

从而，设定：
$$
f(x + \Delta x) = f(x- \alpha \nabla f(x))
$$

则可保证：
$$
f(x + \Delta x) < f(x)
$$

那么更新 $x$ 的计算方式就很简单了，可按如下公式更新 $x$
$$
x^{'} \leftarrow x - \alpha \nabla f(x)
$$

这就是所谓的**沿负梯度方向走一小步**。

到此为止，这就是梯度下降的全部原理。

实现

```python
import numpy as np
import matplotlib.pyplot as plt


def f(x):
    return np.power(x, 2)

def d_f_1(x):
    return 2.0 * x

def d_f_2(f, x, delta=1e-4):
    return (f(x+delta) - f(x-delta)) / (2 * delta)


# plot the function
xs = np.arange(-10, 11)
plt.plot(xs, f(xs))
plt.show()

learning_rate = 0.1
max_loop = 30

x_init = 10.0
x = x_init
lr = 0.1
for i in range(max_loop):
    # d_f_x = d_f_1(x)
    d_f_x = d_f_2(f, x)
    x = x - learning_rate * d_f_x
    print(x)

print('initial x =', x_init)
print('arg min f(x) of x =', x)
print('f(x) =', f(x))
```

## 距离度量

聚类是一个基于距离划分数据集的过程，令 $d(x,y)$ 表示向量 $x,y$ 之间的距离，则$d(x,y)$ 需满足下面四个条件

- 非负性：$d(x,y)\ge 0$
- 同一性：$d(x,x)=0$
- 对称性 ：$d(x, y)=d(y,x)$
- 三角不等式性：$d(x,z)\le d(x,y)+d(y,z)$

> 有序数据

有序数据常用的距离计算方法是Minkowski距离，假设当前有两个n维空间的点x和y，满足
$$
x = (x_1,x_2,\cdots, x_n)^T,y=(y_1,y_2,\cdots,y_n)^T
$$
则x和y的Minkowski距离
$$
d(x,y)=(\sum_{i=1}^m(x_i-y_i)^p)^{\frac{1}{p}}
$$
当 $p=2$ 时，是欧几里德距离；当 $p=1$ 时，是曼哈顿距离。

如果每一个特征的权重不一样，则可修如下
$$
d(x,y)=(\sum_{i=1}^m w_i(x_i-y_i)^p)^{\frac{1}{p}}
$$
其中，$w_i$ 是对应于第$i$ 个特征的权重大小

高斯距离也是一种常用的计算有序数据距离的方式
$$
d(x,y)= \exp (-\frac{||x-y||}{2\sigma^2})
$$

> 无序数据

无序数据不能直接使用Minkowski距离来衡量两者之间的距离，常用VDM距离来衡量

形式化定义为：设 $m_{ia}$ 表示在第i个特征中取值为a的样本数，$m_{iaj}$ 表示在第j个簇中，第i个特征取值为a的样本数，

设有k个簇，则特征取值为a和取值为b的距离为
$$
VDM(a,b)=\sum_{j=1}^{k}{(\frac{m_{iaj}}{m_{ia}}-\frac{m_{ibj}}{m_{ib}})}^p
$$

> 混合

当数据点中既含有有序特征，也含有无序特征时，可的混合的距离计算公式
$$
d(x,y)=(\sum_{i=1}^{s}{(x_i-y_i)^p}+\sum_{i=s+1}^{m}{VDM(x_i, y_i)})^{\frac{1}{p}}
$$

