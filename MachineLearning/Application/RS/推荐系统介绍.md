# 推荐系统

推荐系统中的基本概念是用户、产品和评级（或关于产品的隐含反馈）。每个模型都必须使用已知数据，以便能够推荐最合适的产品或预测产品的评级。

有两种常用方法：用户或内容为主，协同过滤

第一种方法基于已有的用户或产品信息，其目标是将新用户与现有的群组关联以推荐由其他用户评价的所有那品，或根据特征对产品进行聚类，提出一个相似产品的子集。第二种具有明确的评级，目的是为每个产品和每个用户预测评级。协同过滤需要更多的计算。

## 朴素的基于用户的系统

  假设有一组由$m$维特征向量表示的用户
$$
U = \{\bar{u}_1,\bar{u}_2,\cdots,\bar{u}_m\},其中\bar{u}_i \in R^m
$$
典型特征是年龄、性别、兴趣等。所有这些特征可以进行编码（如可以将它们二值化，在固定范围内进行归一化或转换为一个热编码）。但是通常来说，避免不同的方差，从而对相邻变量的距离的计算不产生负面影响。

假设有k个产品的数据集
$$
I = \{i_1,i_2,\cdots, i_k\}
$$
假设还有一个关系，它将每个用户与购买或积极评估的产品的一个子集相关联，特别是对那些有明确的操作或反馈的产品
$$
g(\bar{u})\to\{i_1,i_2,\cdots,i_p\},其中p\in(1,k)
$$
在基于用户的系统中，通常使用k最近邻方法对用户进行周期性地聚集，因此对于一个新用户$u$，可以立即确定与新用户相似的所有用户
$$
B_k(\bar{u})=\{\bar{u_i},d(\bar{u},\bar{u_i})\leq R\}
$$
可以使用之前介绍的关系创建一组推荐产品
$$
I_{推荐}（\bar{u}）=\{\cup_ig(\bar{u_i}),其中\bar{u_i}\in B_R(\bar{u})\}
$$


该集合包含所有相似用户积极评价或购买的产品。

```python
from __future__ import print_function

import numpy as np

from sklearn.neighbors import NearestNeighbors

# For reproducibility
np.random.seed(1000)

nb_users = 1000
nb_product = 20

if __name__ == '__main__':
    # Create the user dataset
    users = np.zeros(shape=(nb_users, 4))

    for i in range(nb_users):
        users[i, 0] = np.random.randint(0, 4)
        users[i, 1] = np.random.randint(0, 2)
        users[i, 2] = np.random.randint(0, 5)
        users[i, 2] = np.random.randint(0, 5)

    # Create user-product dataset
    user_products = np.random.randint(0, nb_product, size=(nb_users, 5))

    # Fit k-nearest neighbors
    nn = NearestNeighbors(n_neighbors=20, radius=2.0)
    nn.fit(users)

    # Create a test user
    test_user = np.array([2, 0, 3, 2])

    # Determine the neighbors
    d, neighbors = nn.kneighbors(test_user.reshape(1, -1))

    print('Neighbors:')
    print(neighbors)

    # Determine the suggested products
    suggested_products = []

    for n in neighbors:
        for products in user_products[n]:
            for product in products:
                if product != 0 and product not in suggested_products:
                    suggested_products.append(product)

    print('Suggested products:')
    print(suggested_products)

```

## 基于内容的系统

```python
from __future__ import print_function

import numpy as np

from sklearn.neighbors import NearestNeighbors

# For reproducibility
np.random.seed(1000)

nb_items = 1000

if __name__ == '__main__':
    # Create the item dataset
    items = np.zeros(shape=(nb_items, 4))

    for i in range(nb_items):
        items[i, 0] = np.random.randint(0, 100)
        items[i, 1] = np.random.randint(0, 100)
        items[i, 2] = np.random.randint(0, 100)
        items[i, 3] = np.random.randint(0, 100)

    metrics = ['euclidean', 'hamming', 'jaccard']

    for metric in metrics:
        print('Metric: %r' % metric)

        # Fit k-nearest neighbors
        nn = NearestNeighbors(n_neighbors=10, radius=5.0, metric=metric)
        nn.fit(items)

        # Create a test product
        test_product = np.array([15, 60, 28, 73])

        # Determine the neighbors with different radiuses
        d, suggestions = nn.radius_neighbors(test_product.reshape(1, -1), radius=20)

        print('Suggestions (radius=10):')
        print(suggestions)

        d, suggestions = nn.radius_neighbors(test_product.reshape(1, -1), radius=30)

        print('Suggestions (radius=15):')
        print(suggestions)
```

## 基于内存(无模式)的协同过滤

```python
from __future__ import print_function

import numpy as np
import warnings

from scikits.crab.models import MatrixPreferenceDataModel
from scikits.crab.similarities import UserSimilarity
from scikits.crab.metrics import euclidean_distances
from scikits.crab.recommenders.knn import UserBasedRecommender

# For reproducibility
np.random.seed(1000)

if __name__ == '__main__':
    # Define a user-item matrix
    user_item_matrix = {
        1: {1: 2, 2: 5, 3: 3},
        2: {1: 5, 4: 2},
        3: {2: 3, 4: 5, 3: 2},
        4: {3: 5, 5: 1},
        5: {1: 3, 2: 3, 4: 1, 5: 3}
    }

    # Build a matrix preference model
    model = MatrixPreferenceDataModel(user_item_matrix)

    # Build a similarity matrix
    similarity_matrix = UserSimilarity(model, euclidean_distances)

    # Create a recommender
    recommender = UserBasedRecommender(model, similarity_matrix, with_preference=True)

    # Test the recommender for user 2
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        print(recommender.recommend(2))

```

## 基于模型的协同过滤

奇异值分解策略

```python
from __future__ import print_function

import numpy as np

from scipy.linalg import svd

# For reproducibility
np.random.seed(1000)

if __name__ == '__main__':
    # Create a dummy user-item matrix
    M = np.random.randint(0, 6, size=(20, 10))

    print('User-Item matrix:')
    print(M)

    # Decompose M
    U, s, V = svd(M, full_matrices=True)
    S = np.diag(s)

    print('U -> %r' % str(U.shape))
    print('S -> %r' % str(S.shape))
    print('V -> %r' % str(V.shape))

    # Select the first 8 singular values
    Uk = U[:, 0:8]
    Sk = S[0:8, 0:8]
    Vk = V[0:8, :]

    # Compute the user and product vectors
    Su = Uk.dot(np.sqrt(Sk).T)
    Si = np.sqrt(Sk).dot(Vk).T

    # Compute the average rating per user
    Er = np.mean(M, axis=1)

    # Perform a prediction for the user 5 and item 2
    r5_2 = Er[5] + Su[5].dot(Si[2])
    print(r5_2)
```

Apache Spark MLlib实现交替最小二乘法策略

```python
import numpy as np

from pyspark import SparkContext, SparkConf
from pyspark.mllib.recommendation import Rating
from pyspark.mllib.recommendation import ALS

# For reproducibility
np.random.seed(1000)

nb_users = 200
nb_products = 100
ratings = []

if __name__ == '__main__':
    conf = SparkConf().setAppName('ALS').setMaster('local[*]')
    sc = SparkContext(conf=conf)

    for _ in range(10):
        for i in range(nb_users):
            rating = Rating(user=i, product=np.random.randint(1, nb_products), rating=np.random.randint(0, 5))
            ratings.append(rating)

    # Parallelize the ratings
    ratings = sc.parallelize(ratings)

    # Train the model
    model = ALS.train(ratings, rank=5, iterations=10)

    # Test the model
    test = ratings.map(lambda rating: (rating.user, rating.product))

    predictions = model.predictAll(test)
    full_predictions = predictions.map(lambda pred: ((pred.user, pred.product), pred.rating))

    # Compute MSE
    split_ratings = ratings.map(lambda rating: ((rating.user, rating.product), rating.rating))
    joined_predictions = split_ratings.join(full_predictions)
    mse = joined_predictions.map(lambda x: (x[1][0] - x[1][1]) ** 2).mean()

    print('MSE: %.3f' % mse)

    # Perform a single prediction
    prediction = model.predict(10, 20)
    print('Prediction: %.3f' % prediction)
```

