# 准备生产

## 连接到消息和语音通道

### 连接到一个通道

Learn how to make your assistant available on:

- [Your Own Website](https://rasa.com/docs/rasa/2.x/connectors/your-own-website)
- [Facebook Messenger](https://rasa.com/docs/rasa/2.x/connectors/facebook-messenger)
- [Slack](https://rasa.com/docs/rasa/2.x/connectors/slack)
- [Telegram](https://rasa.com/docs/rasa/2.x/connectors/telegram)
- [Twilio](https://rasa.com/docs/rasa/2.x/connectors/twilio)
- [Microsoft Bot Framework](https://rasa.com/docs/rasa/2.x/connectors/microsoft-bot-framework)
- [Cisco Webex Teams](https://rasa.com/docs/rasa/2.x/connectors/cisco-webex-teams)
- [RocketChat](https://rasa.com/docs/rasa/2.x/connectors/rocketchat)
- [Mattermost](https://rasa.com/docs/rasa/2.x/connectors/mattermost)
- [Google Hangouts Chat](https://rasa.com/docs/rasa/2.x/connectors/hangouts)
- [Custom Connectors](https://rasa.com/docs/rasa/2.x/connectors/custom-connectors)

### 在本地机器上测试频道

如果您在 localhost 上运行 Rasa X 本地模式或 Rasa 开源服务器，大多数外部通道将无法找到您的服务器 URL，因为 localhost 未对互联网开放。

要在本地计算机上公开端口网上有，可以使用ngrok。安装ngrok后，运行：

```shell
ngrok http 5005; rasa run
```

当您按照说明使您的助手在频道上可用时，请使用 ngrok URL。具体来说，只要说明使用 `https://<host>:<port>/webhooks/<CHANNEL>/webhook`，请使用 `<ngrok_url>/<CHANNEL>/webhook`，将 `<ngrok_url>` 替换为你的 ngrok 终端窗口显示的随机生成的 URL。例如，如果将您的机器人连接到 Slack，您的 URL 应类似于` https://26e7e7744191.ngrok.io/webhooks/slack/webhook`。

> 使用 ngrok 的免费层，您可能会遇到每分钟可以建立的连接数的限制。在撰写本文时，它设置为 40 个连接/分钟。

## 调整NLU模型

Rasa Open Source 将在项目初始化时为您提供建议的 NLU 配置，但随着项目的增长，您可能需要调整配置以适应您的训练数据。

### 如何选择管道

在 Rasa Open Source 中，传入的消息由一系列组件处理。这些组件在 `config.yml` 中定义的所谓处理管道中一个接一个地执行。选择 NLU 管道允许您自定义模型并在数据集上对其进行微调。

要开始使用，您可以让建议配置功能为您选择默认管道。只需在 `config.yml` 文件中提供您的机器人的语言，并将管道的`key`留空。

```yml
language: fr  # your 2-letter language code

pipeline:
# intentionally left empty
```

#### 明智的启动管道

如果您是从头开始，从预训练的词嵌入开始通常会很有帮助。预训练的词嵌入很有帮助，因为它们已经编码了某种语言知识。例如，如果你的训练数据中有“我想买苹果”这样的句子，并且要求 Rasa 预测“get pears”的意图，那么你的模型已经知道“apples”和“pears”这两个词是非常相似。如果您没有足够的训练数据，这将特别有用。

如果您开始使用 spaCy 支持的一种语言，我们建议您使用以下管道：

```yml
language: "fr"  # your two-letter language code

pipeline:
  - name: SpacyNLP
  - name: SpacyTokenizer
  - name: SpacyFeaturizer
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CountVectorsFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: "char_wb"
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 100
  - name: EntitySynonymMapper
  - name: ResponseSelector
    epochs: 100

```

它使用 `SpacyFeaturizer`，提供预训练的词嵌入（请参阅语言模型）。

如果您在管道中不使用任何预训练的词嵌入，则您不会绑定到特定语言，并且可以将模型训练为更多领域特定。

如果您的语言没有词嵌入，或者您有非常特定于领域的术语，我们建议使用以下管道：

```yml
language: "fr"  # your two-letter language code

pipeline:
  - name: WhitespaceTokenizer
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CountVectorsFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: "char_wb"
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 100
  - name: EntitySynonymMapper
  - name: ResponseSelector
    epochs: 100
```

此管道使用 `CountVectorsFeaturizer` 仅对您提供的训练数据进行训练。该管道可以处理任何用空格分隔单词的语言。如果您的语言不是这种情况，请查看 `WhitespaceTokenizer` 的替代方案。

#### 组件的生命周期

每个组件处理输入`and/or`创建输出。组件的顺序由它们在 `config.yml` 中列出的顺序决定；组件的输出可以被管道中的任何其他组件使用。某些组件仅生成管道中其他组件使用的信息。其他组件产生在处理完成后返回的输出属性。

例如，对于“我在找中国菜”这句话，输出是：

```yml
{
    "text": "I am looking for Chinese food",
    "entities": [
        {
            "start": 8,
            "end": 15,
            "value": "chinese",
            "entity": "cuisine",
            "extractor": "DIETClassifier",
            "confidence": 0.864
        }
    ],
    "intent": {"confidence": 0.6485910906220309, "name": "restaurant_search"},
    "intent_ranking": [
        {"confidence": 0.6485910906220309, "name": "restaurant_search"},
        {"confidence": 0.1416153159565678, "name": "affirm"}
    ]
}
```

这是作为以下管道中不同组件的结果的组合创建的：

```yml
pipeline:
  - name: WhitespaceTokenizer
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CountVectorsFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: "char_wb"
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
  - name: EntitySynonymMapper
  - name: ResponseSelector
```

例如这里的`entities` 属性是由`DIETClassifier` 组件创建的。

每个组件都可以从`Component` 基类中实现多个方法；在管道中，这些不同的方法将按特定顺序调用。假设我们在 `config.yml` 中添加了以下管道：

```yml
pipeline:
  - name: "Component A"
  - name: "Component B"
  - name: "Last Component"
```

下图显示了此管道训练期间的调用顺序：

<img src="/Users/henry/Markup/MachineLearning/Application/NLP/RASA/images/component-lifecycle-img.0111328.1202.png" alt="component-lifecycle-img.0111328.1202" style="zoom:50%;" />

在使用 `create` 函数创建第一个组件之前，会创建一个所谓的上下文（只不过是一个 python 字典）。此上下文用于在组件之间传递信息。例如，一个组件可以计算训练数据的特征向量，将其存储在上下文中，另一个组件可以从上下文中检索这些特征向量并进行意图分类。最初，上下文填充有所有配置值。图像中的箭头显示调用顺序并可视化传递上下文的路径。在所有组件都被训练和持久化之后，最终的上下文字典用于持久化模型的元数据。

#### 处理多意图分类

您可以使用多意图分类来预测多个意图（例如 `check_balances transfer_money`），或者对分层意图结构进行建模（例如，`feedback+positive` 比`chitchat`更类似于`feadback+negative`）。

要进行多意图分类，您需要使用 `DIETClassifier`在您的管道中。您还需要在使用的任何标记器中定义这些标志：

```python
intent_tokenization_flag  # 将其设置为True，以便对意图标签进行标记。
intent_split_symbol	# 将其设置为分割意图标签的分隔符字符串。在这种情况+下，默认_。
```

这是一个示例配置：

```yml
language: "en"

pipeline:
- name: "WhitespaceTokenizer"
  intent_tokenization_flag: True
  intent_split_symbol: "+"
- name: "CountVectorsFeaturizer"
- name: "DIETClassifier"
```

- 何时使用多意图

假设您有一个金融服务机器人，并且您有意图 `check_balances` 和 `transfer_money` 的示例：

```yml
nlu:
- intent: check_balances
  examples: |
    - How much money do I have?
    - what's my account balance?

- intent: transfer_money
  examples: |
    - I want to transfer money to my savings account
    - transfer money
```

但是，您的机器人会收到类似这样的传入消息，它结合了两种意图：

```
How much money do I have?I want to transfer some to my savings
```

如果您看到足够多的这些示例，您可以创建一个新的意图多意图 `check_balances+transfer_money` 并将传入的示例添加到其中，例如：

```yml
nlu:
- intent: check_balances+transfer_money
  examples: |
    - How much money do I have? I want to transfer some to savings.
    - What's the balance on my account? I need to transfer some so I want to know how much I have
```

- 如何使用多意图进行对话管理

多意图分类旨在帮助在多意图之后进行动作预测的下游任务。在对话训练数据中使用多意图有两种互补的方式：

1) 为多意图添加常规故事或规则。例如，给定每个单独意图的以下两条规则：

```yml
rules:
- rule: check account balance
  steps:
  - intent: check_balances
  - action: action_check_balances
- rule: transfer money
  steps:
  - intent: transfer_money
  - action: action_transfer_money
```

您可以为多意图添加另一条规则，指定一系列操作来解决这两个意图：

```yml
rules:
- rule: check balances and transfer money
  steps:
  - intent: check_balances+transfer_money
  - action: action_check_balances
  - action: action_transfer_money
```

2) 允许机器学习策略从单意图故事泛化到多意图场景。

当使用多意图时，意图针对使用多热编码的机器学习策略进行特征化。这意味着 `check_balances+transfer_money` 的特征化将与每个单独意图的特征化重叠。机器学习策略（如 TEDPolicy）然后可以基于多意图做出预测，即使它没有明确出现在任何故事中。然而，它通常会表现得好像只有一个单独的意图存在，所以写一个特定的故事或规则来处理多意图的情况总是一个好主意。

#### 对比管道

Rasa 为您提供了直接比较数据上多个管道的性能的工具。有关更多信息，请参阅[比较 NLU 管道](https://rasa.com/docs/rasa/2.x/testing-your-assistant#comparing-nlu-pipelines)。

### 选择合适的组件

有用于实体提取、意图分类、响应选择、预处理等的组件。如果您想添加自己的组件，例如运行拼写检查或进行情绪分析，请查看自定义 NLU 组件。管道通常由三个主要部分组成：

- 分词

您可以使用 `WhitespaceTokenizer` 处理空格标记（即单词由空格分隔）语言。如果您的语言未使用空格标记，则应使用不同的标记器。我们支持多种不同的分词器，或者您可以创建自己的自定义分词器。

> 管道中的某些组件可能需要特定的标记器。您可以在各个组件的 requires 参数中找到这些要求。如果管道中缺少必需的组件，则会引发错误。

- 特征化

您需要决定是否使用提供预训练词嵌入的组件。我们建议在少量训练数据的情况下从预训练的词嵌入开始。一旦您拥有大量数据并确保最相关的单词将出现在您的数据中并因此将具有单词嵌入，监督嵌入（直接从您的训练数据中学习单词含义）可以使您的模型更加具体到您的领域。如果您找不到适合您的语言的预训练模型，则应使用监督嵌入。

**1.预训练嵌入**

在管道中使用预训练词嵌入的优势在于，如果您有一个训练示例，例如：“我想买苹果”，并且要求 Rasa 预测“get pears”的意图，那么您的模型已经知道“apples”和“pears”这两个词非常相似。如果您没有足够的训练数据，这将特别有用。我们支持一些提供预训练词嵌入的组件：

1. [MitieFeaturizer](https://rasa.com/docs/rasa/2.x/components#mitiefeaturizer)
2. [SpacyFeaturizer](https://rasa.com/docs/rasa/2.x/components#spacyfeaturizer)
3. [ConveRTFeaturizer](https://rasa.com/docs/rasa/2.x/components#convertfeaturizer)
4. [LanguageModelFeaturizer](https://rasa.com/docs/rasa/2.x/components#languagemodelfeaturizer)

如果您的训练数据是英文的，我们建议使用 `ConveRTFeaturizer`。 `ConveRTFeaturizer` 的优点是它不会独立处理用户消息的每个单词，而是为完整的句子创建上下文向量表示。例如，如果您有一个训练示例，例如：“我可以预订汽车吗？”，并且要求 Rasa 预测“我需要从我的地方搭车”的意图，因为这两个示例的上下文向量表示已经非常相似，为两者分类的意图很可能是相同的。如果您没有足够的训练数据，这也很有用。 

`ConveRTFeaturizer` 的替代方法是 `LanguageModelFeaturizer`，它使用预训练的语言模型（例如 BERT、GPT-2 等）来提取完整句子的相似上下文向量表示。有关支持的语言模型的完整列表，请参阅 `HFTransformersNLP`。

如果您的训练数据不是英语，您还可以使用不同的语言模型变体，其已使用特定于您的训练数据的语言进行预训练。例如，BERT 模型有中文（bert-base-chinese）和日文（bert-base-japanese）变体。 Transformers 库的官方文档中提供了这些语言模型的不同变体的完整列表。

spacynlp 还提供许多不同语言的词嵌入，因此您可以将其用作另一种选择，具体取决于训练数据的语言。 

**2.监督嵌入**

如果您在管道中不使用任何预训练的词嵌入，则您不会被绑定到特定的语言，并且可以将您的模型训练为更特定于领域。例如，在一般英语中，“平衡”一词与“对称”密切相关，但与“现金”一词却截然不同。在银行领域，“余额”和“现金”密切相关，您希望您的模型能够捕捉到这一点。如果您不想使用预训练的词嵌入，则应仅使用稀疏特征化器类别中的特征化器，例如 `CountVectorsFeaturizer,RegexFeaturizer,LexicalSyntacticFeaturizer`。

- 意图分类/响应选择

根据您的数据，您可能只想执行意图分类、实体识别或响应选择。或者您可能想要组合多个这些任务。我们为每个任务支持多个组件。我们建议使用 `DIETClassifier` 进行意图分类和实体识别，使用 `ResponseSelector` 进行响应选择。

默认情况下，所有这些组件都会消耗管道中生成的所有可用功能。但是，有时限制特定组件使用的功能是有意义的。例如，如果没有使用 `RegexFeaturizer` 或 `LexicalSyntacticFeaturizer` 中的特征，则 `ResponseSelector` 可能会执行得更好。为此，您可以执行以下操作： 通过选项`alias`为管道中的每个特征化器设置一个别名。默认情况下，别名设置为完整的特征化器类名称，例如 `RegexFeaturizer`。然后，例如，您可以通过选项`featurizers`在 `ResponseSelector `上指定哪些特征应该被使用。如果您不设置选项`featurizers`，则将使用所有可用功能。

这是一个示例配置文件，其中 DIETClassifier 使用所有可用功能，而 ResponseSelector 仅使用来自 ConveRTFeaturizer 和 CountVectorsFeaturizer 的功能。 

```yml
language: "en"

pipeline:
  - name: ConveRTTokenizer
  - name: ConveRTFeaturizer
    alias: "convert"
  - name: RegexFeaturizer
    alias: "regex"
  - name: LexicalSyntacticFeaturizer
    alias: "lexical-syntactic"
  - name: CountVectorsFeaturizer
    alias: "cvf-word"
  - name: CountVectorsFeaturizer
    alias: "cvf-char"
    analyzer: "char_wb"
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 100
  - name: EntitySynonymMapper
  - name: ResponseSelector
    featurizers: ["convert", "cvf-word"]
    epochs: 100
```

- 实体抽取

实体提取涉及解析用户消息以获取所需的信息。 Rasa Open Source 为自定义实体以及日期和位置等预训练实体提供实体提取器。以下是可用提取器的摘要以及它们最适合的用途：

| Component                 | Requires          | Model                                            | Notes              |
| ------------------------- | ----------------- | ------------------------------------------------ | ------------------ |
| `DIETClassifier`          | N/A               | conditional random field on top of a transformer | 适合训练自定义实体 |
| `CRFEntityExtractor`      | sklearn-crfsuite  | conditional random field                         | 适合训练自定义实体 |
| `SpacyEntityExtractor`    | spaCy             | averaged perceptron                              | 提供预训练实体     |
| `DucklingEntityExtractor` | running duckling  | context-free grammar                             | 提供预训练实体     |
| `MitieEntityExtractor`    | MITIE             | structured SVM                                   | 适合训练自定义实体 |
| `EntitySynonymMapper`     | existing entities | N/A                                              | 映射已知同义词     |

### 提高性能

- 处理类不平衡

如果存在较大的类不平衡，分类算法通常表现不佳，例如，如果您有很多针对某些意图的训练数据而针对其他意图的训练数据很少。为了缓解这个问题，您可以使用`balanced`的批处理策略。该算法确保所有类都在每个批次中表示，或者至少在尽可能多的后续批次中表示，仍然模仿某些类比其他类更频繁的事实。默认情况下使用平衡批处理。为了关闭它并使用经典的批处理策略，请在您的配置文件中包含 `batch_strategy: sequence`。

```yml
language: "en"

pipeline:
# - ... other components
- name: "DIETClassifier"
  batch_strategy: sequence
```

- 访问诊断数据

为了更好地了解模型的作用，您可以访问预测过程的中间结果。为此，您需要访问` Message` 和 `Prediction` 对象的 `diagnostic_data `字段，其中包含有关注意力权重和推理计算的其他中间结果的信息。您可以使用此信息进行调试和微调，例如使用 `RasaLit`。

训练模型后，您可以访问 DIET 的诊断数据，给定一条已处理的消息，如下所示：

```python
nlu_diagnostic_data = message.as_dict()[DIAGNOSTIC_DATA]

for component_name, diagnostic_data in nlu_diagnostic_data.items():
    attention_weights = diagnostic_data["attention_weights"]
    print(f"attention_weights for {component_name}:")
    print(attention_weights)

    text_transformed = diagnostic_data["text_transformed"]
    print(f"\ntext_transformed for {component_name}:")
    print(text_transformed)
```

你可以像这样访问 TED 的诊断数据

```python
prediction = policy.predict_action_probabilities(
    GREET_RULE, domain, RegexInterpreter()
)
print(f"{prediction.diagnostic_data.get('attention_weights')}")
```

### 配置Tensorflow

TensorFlow 允许通过 TF Config 子模块在运行时环境中配置选项。 Rasa Open Source 支持这些配置选项的一小部分，并对 tf.config 子模块进行适当的调用。这个较小的子集包含开发人员经常与 Rasa Open Source 一起使用的配置。所有配置选项都使用环境变量指定，如后续部分所示。

- 确定性操作

如果您使用 GPU 并且在您的管道中有一个或多个稀疏特征化器，`and/or`使用任何 `TEDPolicy,UnexpecTEDIntentPolicy,DIETClassifier,ResponseSelector`，如果您设置环境变量 `TF_DETERMINISTIC_OPS=1`，训练和测试将失败，因为底层 tensorflow 操作 `tf.sparse.sparse_dense_matmul、tf.nn.sparse_softmax_cross_entropy_with_logits 和 tf.math.unsorted_segment `操作没有确定性的 GPU 实现。有关更多信息，请参见[此处](https://github.com/tensorflow/community/blob/master/rfcs/20210119-determinism.md)

通过检查特征化器的“类型”，您可以在此处查看哪些特征化器是稀疏的。

- 优化CPU性能

> 我们建议您仅在您是高级 TensorFlow 用户并了解管道中机器学习组件的实现时才配置这些选项。这些选项会影响在 Tensorflow 中如何进行操作。将它们保留为默认值很好。

根据 NLU 组件或核心策略使用的 TensorFlow 操作，您可以通过调整这些选项来利用多核 CPU 并行性。

**并行一个操作**

将 `TF_INTRA_OP_PARALLELISM_THREADS` 设置为环境变量，以指定可用于并行执行一个操作的最大线程数。例如，像 `tf.matmul(),tf.reduce_sum` 这样的操作可以在并行运行的多个线程上执行。此变量的默认值为 0，这意味着 TensorFlow 将为每个 CPU 内核分配一个线程。

**并行多个操作**

将 `TF_INTER_OP_PARALLELISM_THREADS` 设置为环境变量，以指定可用于并行执行多个非阻塞操作的最大线程数。这些将包括在 TensorFlow 图中它们之间没有定向路径的操作。换句话说，一个操作的计算不会影响另一个操作的计算。此变量的默认值为 0，这意味着 TensorFlow 将为每个 CPU 内核分配一个线程。

要了解有关这两个选项之间有何不同的更多信息，请参阅此 stackoverflow 线程。

- 优化GPU性能

**限制GPU内存增长**

默认情况下，TensorFlow 会为正在运行的进程阻塞所有可用的 GPU 内存。如果您正在运行多个 TensorFlow 进程并希望在它们之间分配内存，这可能会受到限制。为防止 Rasa Open Source 阻塞所有可用的 GPU 内存，请将环境变量 `TF_FORCE_GPU_ALLOW_GROWTH` 设置为 True。

**限制可用的绝对 GPU 内存**

您可能希望限制 Rasa 开源进程可以使用的 GPU 内存的绝对数量。例如，假设您有两个可见的 GPU（GPU:0 和 GPU:1）并且您希望从第一个分配 1024 MB GPU 和第二个 GPU 的 2048 MB。您可以通过将环境变量 `TF_GPU_MEMORY_ALLOC` 设置为“0:1024, 1:2048”来做到这一点。

## 测试助手

Rasa Open Source 允许您通过运行测试故事来端到端地验证和测试对话。此外，您还可以分别测试对话管理和消息处理（NLU）。

### 验证数据和故事

数据验证验证您的域、NLU 数据或故事数据中没有出现错误或重大不一致。要验证您的数据，请让您的 CI 运行以下命令：

```shell
rasa data validate
```

如果您将 max_history 值传递给 config.yml 文件中的一个或多个策略，请将这些值中的最小值提供为

```
rasa data validate --max-history <max_history>
```

如果数据验证导致错误，训练模型也可能失败或产生不良性能，因此在训练模型之前运行此检查总是好的。通过包含 --fail-on-warnings 标志，此步骤将在指示更多小问题的警告上失败。

> 注意
>
> 运行 rasa data validate 不会测试您的规则是否与您的故事一致。但是，在训练期间，RulePolicy 会检查规则和故事之间的冲突。任何此类冲突都会中止培训

要阅读有关验证器和所有可用选项的更多信息，请参阅 rasa 数据验证文档。

### 写测试故事

在测试故事上测试您训练有素的模型是对您的助手在某些情况下的行为方式充满信心的最佳方式。以修改后的故事格式编写，测试故事允许您提供整个对话并测试，给定某些用户输入，您的模型将以预期的方式运行。当您开始从用户对话中引入更复杂的故事时，这一点尤其重要。

测试故事就像您的训练数据中的故事，但也包括用户信息。

基础故事

`tests/test_stories.yml`

```yml
stories:
- story: A basic story test
  steps:
  - user: |
      hello
    intent: greet
  - action: utter_ask_howcanhelp
  - user: |
     show me [chinese]{"entity": "cuisine"} restaurants
    intent: inform
  - action: utter_ask_location
  - user: |
      in [Paris]{"entity": "location"}
    intent: inform
  - action: utter_ask_price
```

自定义动作

```yml
stories:
- story: A test where a custom action returns events
  steps:
  - user: |
      hey
    intent: greet
  - action: my_custom_action
  - slot_was_set:
    - my_slot: "value added by custom action"
  - action: utter_ask_age
  - user: |
      thanks
    intent: thankyou
  - action: utter_no_worries
```

表单happy路径

```yml
stories:
- story: A test story with a form
  steps:
  - user: |
      hi
    intent: greet
  - action: utter_greet
  - user: |
      im looking for a restaurant
    intent: request_restaurant
  - action: restaurant_form
  - active_loop: restaurant_form
  - user: |
      [afghan](cuisine) food
    intent: inform
  - action: restaurant_form
  - active_loop: null
  - action: utter_slots_values
  - user: |
      thanks
    intent: thankyou
  - action: utter_no_worries
```

表单unhappy路径

```yml
stories:
- story: A test story with unexpected input during a form
  steps:
  - user: |
      hi
    intent: greet
  - action: utter_greet
  - user: |
      im looking for a restaurant
    intent: request_restaurant
  - action: restaurant_form
  - active_loop: restaurant_form
  - user: |
      How's the weather?
    intent: chitchat
  - action: utter_chitchat
  - action: restaurant_form
  - active_loop: null
  - action: utter_slots_values
  - user: |
      thanks
    intent: thankyou
  - action: utter_no_worries
```

默认情况下，该命令将对来自名称以 `test_ `开头的任何文件的故事运行测试。您还可以使用 `--stories` 参数提供特定的测试故事文件或目录。您可以通过运行以下命令来测试您的助手：

```
rasa test
```

对话测试仅与您包含的测试用例一样彻底和准确，因此您应该在改进您的助手时继续增加您的测试故事集。一个很好的经验法则是，你的目标应该是让你的测试故事能够代表真实对话的真实分布。 Rasa X 可以轻松添加基于真实对话的测试对话。

有关更多配置选项，请参阅有关 rasa test 的 CLI 文档。

### 评估NLU模型

除了测试故事，您还可以单独测试自然语言理解 (NLU) 模型。在现实世界中部署您的助手后，它将处理未在训练数据中看到的消息。为了模拟这一点，您应该始终留出一部分数据进行测试。您可以使用以下方法将 NLU 数据拆分为训练集和测试集：

```
rasa data split nlu
```

接下来，您可以使用以下方法查看经过训练的 NLU 模型从您生成的测试集中预测数据的能力：

```
rasa test nlu
    --nlu train_test_split/test_data.yml
```

要更广泛地测试您的模型，请使用交叉验证，它会自动创建多个训练/测试拆分：

```
rasa test nlu
    --nlu data/nlu.yml
    --cross-validation
```

- 比较NLU性能

如果您对 NLU 训练数据进行了重大更改（例如，将一个意图分成两个意图或添加大量训练示例），您应该运行完整的 NLU 评估。您需要将未更改 NLU 模型的 NLU 模型的性能与您的更改进行比较。您可以通过在交叉验证模式下运行 NLU 测试来做到这一点：

```
rasa test nlu --cross-validation
```

您还可以在训练集上训练模型并在测试集上对其进行测试。如果您使用训练-测试集方法，最好使用 rasa 数据拆分作为此 CI 步骤的一部分来打乱和拆分您的数据，而不是使用静态 NLU 测试集，后者很容易过时。

您可以找到CLI 文档中有关 rasa 测试的完整选项列表。

- 比较NLU管道

为了充分利用您的训练数据，您应该在不同的管道和不同数量的训练数据上训练和评估您的模型。为此，请将多个配置文件传递给 rasa test 命令：

```
rasa test nlu --nlu data/nlu.yml
   --config config_1.yml config_2.yml
```

这将执行几个步骤：

1.从 `data/nlu.yml`中创建80%数据训练20%数据测试

2.从全局训练拆分中排除一定百分比的数据。

3.在剩余的训练数据上为每个配置训练模型.

4.在全局测试拆分上评估每个模型。

在步骤 2 中使用不同百分比的训练数据重复上述过程，让您了解如果增加训练数据量，每个管道将如何表现。由于训练不是完全确定的，整个过程对每个指定的配置重复 3 次。

绘制了所有运行中 f1 分数的均值和标准差的图表。 f1 分数图以及所有训练/测试集、训练模型、分类和错误报告将保存到名为 `nlu_comparison_results` 的文件夹中。

检查 f1 分数图可以帮助您了解是否有足够的数据用于 NLU模型。如果图表显示在所有训练结束时 f1-score 仍在提高 数据被使用，它可能会随着更多的数据而进一步改进。但是，如果在使用所有训练数据时 f1-score 已趋于平稳，则添加更多数据可能无济于事。

如果要更改运行次数或排除百分比，您可以： 

```
rasa test nlu --nlu data/nlu.yml
  --config config_1.yml config_2.yml
  --runs 4 --percentages 0 25 50 70 90
```

- 解释输出

**意图分类**

`rasa test`脚本将为您的意图分类模型生成报告 (intent_report.json)、混淆矩阵 (intent_confusion_matrix.png) 和置信度直方图 (intent_histogram.png)。

该报告记录每个意图的精度、召回率和 f1 分数，并提供总体平均值。您可以使用 `--report `参数将这些报告保存为 JSON 文件。

混淆矩阵显示哪些意图被误认为是其他意图。任何被错误预测的样本都会被记录并保存到一个名为 errors.json 的文件中，以便于调试。

直方图允许您可视化所有预测的置信度，正确和不正确的预测分别由蓝色和红色条显示。提高训练数据的质量将使蓝色柱状图向上移动，红色柱状图向下移动。它还应该有助于减少红色直方图条本身的数量。

**响应选择**

`rasa test`以与评估意图分类器相同的方式评估响应选择器，生成报告 (response_selection_report.json)、混淆矩阵 (response_selection_confusion_matrix.png)、置信度直方图 (response_selection_histogram.png) 和错误 (response_selection_errors.json)。如果您的管道包含多个响应选择器，它们会在单个报告中进行评估。

该报告记录检索意图的每个子意图的精度、召回率和 f1 度量，并提供总体平均值。您可以使用 `--report` 参数将这些报告保存为 JSON 文件。

**实体提取**

`rasa test`报告您的可训练实体提取器经过训练以识别的每种实体类型的召回率、精度和 f1 分数。

`rasa test`仅评估可训练实体提取器，例如 `DIETClassifier,CRFEntityExtractor`。不评估像 `DucklingHTTPExtractor` 这样的预训练提取器。

**实体评分**

为了评估实体提取，我们应用了一种简单的基于标签的方法。我们不完全考虑 BILOU 标签，而只考虑基于每个令牌的实体类型标签。对于像“near Alexanderplatz”这样的位置实体，我们期望标签 `LOC LOC` 而不是基于 BILOU 的 `B-LOC L-LOC`。

我们的方法在评估方面更加宽松，因为它奖励部分提取并且不惩罚分割实体。例如，给定上述实体“near Alexanderplatz”和提取“Alexanderplatz”的系统，我们的方法奖励“Alexanderplatz”的提取并惩罚遗漏的单词“near”。

然而，基于 BILOU 的方法会将其标记为完全失败，因为它希望 Alexanderplatz 被标记为实体 (L-LOC) 中的最后一个标记，而不是单个标记实体 (U-LOC)。另请注意，“near”和“Alexanderplatz”的拆分提取将在我们的方法中获得满分，在基于 BILOU 的方法中获得零分。

这是两种评分机制之间的比较 对于“今晚在亚历山大广场附近”这句话： 

| extracted                                           | Simple tags (score) | BILOU tags (score)     |
| --------------------------------------------------- | ------------------- | ---------------------- |
| `[near Alexanderplatz](loc) [tonight](time)`        | loc loc time (3)    | B-loc L-loc U-time (3) |
| `[near](loc) [Alexanderplatz](loc) [tonight](time)` | loc loc time (3)    | U-loc U-loc U-time (1) |
| `near [Alexanderplatz](loc) [tonight](time)`        | O loc time (2)      | O U-loc U-time (1)     |
| `[near](loc) Alexanderplatz [tonight](time)`        | loc O time (2)      | U-loc O U-time (1)     |
| `[near Alexanderplatz tonight](loc)`                | loc loc loc (2)     | B-loc I-loc L-loc (1)  |

### 评估对话模型

您可以使用测试脚本在一组测试故事上评估您训练有素的对话模型：

```shell
rasa test core --stories test_stories.yml --out results
```

这会将任何失败的故事打印到 `results/failed_test_stories.yml`。如果至少有一个动作预测不正确，则故事失败。

测试脚本还将混淆矩阵保存到名为 `results/story_confmat.pdf` 的文件中。对于您域中的每个操作，混淆矩阵显示正确预测该操作的频率以及预测错误操作的频率。

- 解释生成的警告

测试脚本还将生成一个名为 `results/stories_with_warnings.yml` 的警告文件。该文件包含所有测试故事，在任何对话轮次中都预测了 `action_unlikely_intent` 但原始故事中的所有动作都被正确预测。但是，如果一个测试故事最初包含一个 `action_unlikely_intent`，例如为了确保一个规则被设计为在一个 `action_unlikely_intent` 之后触发对话路径，但策略集合未能这样做，那么相应的故事将最终出现在 `results/failed_test_stories.yml`作为一个失败的故事。

故事按`action_unlikely_intent `预测的严重性排序。此严重性由 `UnexpectTEDIntentPolicy` 本身在预测时计算。严重性越高，意图越不可能，因此审查特定对话路径变得更加关键。

注意，`action_unlikely_intent` 由 `UnexpectTEDIntentPolicy` 预测，该策略采用基于机器学习的模型 引擎盖，因此也可能导致错误警告。如果这些故事中的对话路径已经存在于训练故事中，您可以选择忽略此类警告。 

- 比较策略配置

要为您的对话模型选择配置，或为特定策略选择超参数，您需要衡量您的对话模型对以前从未见过的对话的泛化程度。特别是在项目开始时，当您没有很多真实的对话来训练您的机器人时，您可能不想排除一些用作测试集。

Rasa Open Source 有一些脚本可以帮助您选择和微调您的策略配置。一旦你对它感到满意，你就可以在你的完整数据集上训练你的最终配置。

为此，你首先必须为你的不同配置训练模型。创建两个（或更多）配置文件，包括您要比较的策略，然后将它们提供给训练脚本以训练您的模型：

```shell
rasa train core -c config_1.yml config_2.yml \
  --out comparison_models --runs 3 --percentages 0 5 25 50 70 95
```

与评估 NLU 模型的方式类似，上述命令在多种配置和不同数量的训练数据上训练对话模型。对于提供的每个配置文件，Rasa Open Source 将训练对话模型，其中 0、5、25、50、70 和 95% 的训练故事从训练数据中排除。重复 3 次以确保结果一致。

此脚本完成后，您可以将多个模型传递给测试脚本，以比较您刚刚训练的模型：

```shell
rasa test core -m comparison_models --stories stories_folder
  --out comparison_results --evaluate-model-directory
```

这将评估 `stories_folder` 中故事的每个模型（可以是训练集或测试集），并绘制一些图表来向您展示哪个策略执行得最好。由于之前的 train 命令排除了一些训练数据来训练每个模型，因此上面的测试命令可以测量您的模型对保留故事的预测程度。要比较单个策略，请创建每个仅包含一个策略的配置文件。

> 此训练过程可能需要很长时间，因此我们建议让它在后台某个不能被中断的地方运行。

- 测试行动代码

用于测试您的操作代码的方法将取决于它是如何实现的。例如，如果您连接到外部 API，您应该编写集成测试以确保这些 API 按预期响应公共输入。无论您如何测试您的操作代码，都应该将这些测试包含在您的 CI 管道中，以便在您每次进行更改时运行它们。

如果您有任何疑问或问题，请在我们论坛的专用测试部分与我们分享！

## 创建CI/CD

即使开发上下文助手与开发传统软件不同，您仍应遵循软件开发最佳实践。设置持续集成 (CI) 和持续部署 (CD) 管道可确保对机器人的增量更新正在改进它，而不是损害它

- 概览

持续集成 (CI) 是频繁合并代码更改并在提交更改时自动测试更改的做法。持续部署 (CD) 意味着将集成更改自动部署到登台或生产环境。它们一起使您可以更频繁地改进您的助手，并有效地测试和部署这些更改。

本指南将涵盖特定于 Rasa 项目的 CI/CD 管道中应该包含的内容。如何实施该管道取决于您。有许多 CI/CD 工具，例如 GitHub Actions、GitLab CI/CD、Jenkins 和 CircleCI。我们建议选择与您使用的任何 Git 存储库集成的工具。

- CI

改进助手的最佳方法是频繁地进行增量更新。无论更改多么小，您都希望确保它不会引入新问题或对助手的性能产生负面影响。

通常最好在合并/拉取请求或提交时运行 CI 检查。大多数测试都足够快，可以在每次更改时运行。但是，您可以选择仅在某些文件已更改或存在其他指示符时才运行资源密集型测试。例如，如果您的代码托管在 Github 上，则只有在拉取请求具有特定标签（例如“需要 NLU 测试”）时才能进行测试运行。

**CI 管道概述**

您的 CI 管道应包括模型训练和测试，作为简化部署过程的步骤。保存新训练数据后的第一步是启动管道。这可以手动启动，也可以在您创建或更新拉取请求时启动。

接下来，您需要运行各种测试集以查看更改的影响。这包括运行数据验证测试、NLU 交叉验证和故事测试。有关测试的更多信息，请参阅测试您的助手。

最后一步是查看测试结果并在测试成功时推送更改。一旦新模型经过训练和测试，就可以使用持续部署管道自动部署。

**GitHub Actions CI 管道**

您可以在 CI 管道中使用 `Rasa Train-Test Github Action` 来自动执行数据验证、训练和测试。使用 `Github Action` 的示例 CI 管道如下所示：

```yml
jobs:
  training-testing:
    name: Training and Testing
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v1
      - name: Rasa Train and Test GitHub Action
        uses: RasaHQ/rasa-train-test-gha@main
        with:
          requirements_file: requirements.txt
          data_validate: true
          rasa_train: true
          cross_validation: true
          rasa_test: true
          test_type: all
          publish_summary: true
          github_token: ${{ secrets.GITHUB_TOKEN }}
      - name: Upload model
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@master
        with:
          name: model
          path: models
```

在这个管道中，Rasa Train-Test Github Action 在第一步中执行数据验证、模型训练和故事测试，在第二步中将模型文件作为工件上传。Rasa Train 可配置参数的完整列表-Test Github Action 在存储库的 README 中可用。

当 `publish_summary` 设置为 `true` 时，此操作将自动将模型的测试结果作为注释发布到关联的 Pull Request 中

可以根据评估结果批准或拒绝拉取请求，并且在许多情况下，如果所有 CI 检查都通过，您将希望自动部署模型。您可以继续阅读下一部分以了解有关持续部署的更多信息。

- CD

为了经常向您的用户提供改进，您将希望尽可能多地自动化部署过程。一旦 CI 检查成功，CD 步骤通常在推送或合并到某个分支时运行。

**部署你的Rasa模型**

如果您在 CI 管道中运行测试故事，您将拥有一个经过训练的模型。如果 CI 结果令人满意，您可以设置您的 CD 管道以将经过训练的模型上传到您的 Rasa 服务器。例如，要将模型上传到 Rasa X：

```shell
curl -k -F "model=@models/my_model.tar.gz" "https://example.rasa.com/api/projects/default/models?api_token={your_api_token}"
```

如果您使用的是 Rasa X，您还可以将上传的模型标记为生产（或者如果使用多个部署环境，则可以标记任何您想要标记的部署）：

```shell
curl -X PUT "https://example.rasa.com/api/projects/default/models/my_model/tags/production"
```

**部署你的动作服务**

您可以为您的操作服务器自动构建新图像并将其上传到图像存储库，以便对您的操作代码进行每次更新。如上所述，如果操作服务器与当前的生产模型不兼容，请小心自动将新的图像标签部署到生产中。

- 示例 CI/CD 管道

例如，请参阅 Sara 的 CI/CD 管道、您可以在 Rasa Docs 中与之交谈的 Rasa 助手和 Carbon Bot。两者都使用 Github Actions 作为 CI/CD 工具。

这些示例只是众多可能性中的两种。如果您有自己喜欢的 CI/CD 设置，请在论坛上与 Rasa 社区分享。

## 部署助手

本页解释了何时以及如何部署使用 Rasa 构建的助手。它将允许您向用户提供您的助手，并为您设置一个生产就绪的环境。

### 何时部署

部署您的助手并将其提供给测试用户的最佳时间是它可以处理最重要的快乐路径，或者我们称之为最小可行助手。

下面描述的推荐部署方法可以轻松与测试用户共享您的助手通过 Rasa X 中的共享您的助手功能。然后，当您准备好通过一个或多个消息传递和语音通道使您的助手可用时，您可以轻松地将它们添加到您现有的部署设置中。

### 部署方法

部署助手的推荐方法是使用我们支持的服务器快速安装或 Helm Chart 选项。两者都部署 Rasa X 和你的助手。它们是部署助手的最简单方法，允许您使用 Rasa X 查看对话并将其转化为训练数据，并且可以投入生产。有关部署方法的更多详细信息，请参阅 Rasa X 安装指南。

- 服务快速安装

服务器快速安装脚本是部署 Rasa X 和您的助手的最简单方法。它会在您的机器上安装一个具有合理默认值的 Kubernetes 集群，让您在一个命令中启动并运行。

默认：确保满足[操作系统要求](https://rasa.com/docs/rasa-x/installation-and-setup/install/quick-install-script/#hardware-os-requirements)，然后运行：

```
curl -s get-rasa-x.rasa.com | sudo bash
```

自定义： [Customizing the Script](https://rasa.com/docs/rasa-x/installation-and-setup/customize/#server-quick-install) and the [Server Quick-Install docs](https://rasa.com/docs/rasa-x/installation-and-setup/install/quick-install-script).

- Helm Chart

对于将接收大量用户流量的助手，通过我们的 Helm 图表设置 Kubernetes 或 Openshift 部署是最佳选择。这提供了一个易于部署的可扩展架构。但是，如果您有特定要求，您也可以自定义 Helm 图表。

默认：[Helm Chart Installation](https://rasa.com/docs/rasa-x/installation-and-setup/install/helm-chart-installation/introduction) 

自定义：阅读以上内容以及[高级配置文档](https://rasa.com/docs/rasa-x/installation-and-setup/customize/#helm-chart)，并根据您的需要自定义[开源 Helm 图表](https://github.com/RasaHQ/rasa-x-helm).

- docker compose

您还可以在 Docker Compose 设置中运行 Rasa X，而无需集群环境。我们有一个安装脚本，以及任何自定义设置的手动说明。

默认：阅读 [Docker Compose 安装脚本文档](https://rasa.com/docs/rasa-x/installation-and-setup/install/docker-compose/#docker-compose-install-script)或观看有关部署 Rasa X 的[大师班视频](https://www.youtube.com/watch?v=IUYdwy8HPVc)。

自定义：阅读 [Docker Compose 手动安装文档](https://rasa.com/docs/rasa-x/installation-and-setup/install/docker-compose/#docker-compose-manual-install) 以获取完整的自定义选项。

- 开源部署

也可以使用 Docker Compose 在没有 Rasa X 的情况下部署 Rasa 助手。为此，您可以在本地或在 Docker 中构建您的 Rasa Assistant。然后您可以在 Docker Compose 中部署您的模型。

[Building a Rasa Assistant Locally](https://rasa.com/docs/rasa/2.x/playground)

[Building a Rasa Assistant in Docker](https://rasa.com/docs/rasa/2.x/docker/building-in-docker)

[Deploying a Rasa Open Source Assistant in Docker Compose](https://rasa.com/docs/rasa/2.x/docker/deploying-in-docker-compose)

### 部署动作服务

- 构建动作服务器映像

如果您构建包含操作代码的映像并将其存储在容器注册表中，则可以将其作为部署的一部分运行，而无需在服务器之间移动代码。此外，您可以添加系统或 Python 库的任何其他依赖项，这些依赖项是您的操作代码的一部分，但未包含在基本 `rasa/rasa-sdk` 映像中。

**自动化动作服务器映像构建**

除了手动创建新的 Action Server 镜像之外，您还可以使用 `Rasa Action Server GitHub Action` 来自动构建镜像。如果您不熟悉 GitHub Actions，那么熟悉 GitHub Actions 文档可能会有所帮助。

以下步骤假设您已经创建了一个 GitHub 存储库并且您有一个 DockerHub 帐户。创建用于构建和推送 Docker 映像的工作流一个 DockerHub 注册表：

1. 使用您的 DockerHub 登录名和密码添加 GitHub Secrets。您可以在 Github 文档中找到有关如何为存储库创建加密机密的详细信息

该示例使用以下机密：

```shell
DOCKER_HUB_LOGIN 	# DockerHub的登录名
DOCKER_HUB_PASSWORD # DockerHub的密码
```

2. 在您的 GitHub 存储库中创建文件 `.github/workflows /action_server.yml`。

每当 `actions/` 目录中的文件发生更改并将更改推送到主分支时，下面的 GitHub Action 工作流程都会构建一个新的 docker 映像。

```yml
on:
  push:
    branches:
      - main
    paths:
    - 'actions/**'

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest
    name: Build Action Server image and upgrade Rasa X deployment
    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - id: action_server
      name: Build an action server with a custom actions
      uses: RasaHQ/action-server-gha@master
      # Full list of parameters: https://github.com/RasaHQ/action-server-gha/tree/master#input-arguments
      with:
        docker_image_name: 'account_username/repository_name'
        docker_registry_login: ${{ secrets.DOCKER_HUB_LOGIN }}
        docker_registry_password: ${{ secrets.DOCKER_HUB_PASSWORD }}
        # More details about github context:
        # https://docs.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions#github-context
        #
        # github.sha - The commit SHA that triggered the workflow run
        docker_image_tag: ${{ github.sha }}
```

1. 将您的更改推送到主分支。推送更改后，工作流将构建并将新镜像推送到 DockerHub 注册表中。
2. 现在，您可以使用您的新品牌 docker 镜像。
3. 您还可以扩展您的工作流程，这样您就不必手动更新你的 Rasa X 部署。下面的示例显示了如何通过更新 Rasa X Helm Chart 部署的附加步骤来扩展您的工作流程。

```yml
on:
  push:
    branches:
      - main

jobs:
  build_and_deploy:
    runs-on: ubuntu-latest
    name: Build Action Server image and upgrade Rasa X deployment
    steps:
    [..]

    # This step shows only the example of output parameter usage
    # and it's not focused on deployment itself.
    - name: "Upgrade a Rasa X deployment"
      run: |
        helm upgrade --install --reuse-values \
          --set app.name=${{ steps.action_server.outputs.docker_image_name }} \
          --set app.tag=${{ steps.action_server.outputs.docker_image_tag }} rasa rasa-x/rasa-x
```

如您所见，可以使用 `action_server` 步骤中的输出变量。 `steps.action_server.outputs.docker_image_name` 变量返回一个 docker 镜像名称，`steps.action_server.outputs.docker_image_tag` 变量返回一个 docker 镜像标签。有关如何使用和自定义 Rasa GitHub Actions 的更多示例，您可以在 Rasa GitHub Actions 存储库中找到.

**手动构建动作服务器**

创建你的镜像：

1. 确保你的动作在`actions/actions.py`中定义。`rasa/rasa-sdk` 映像将自动在此文件中查找操作。
2. 如果您的操作有任何额外的依赖项，请在文件`actions/requirements-actions.txt`中创建它们的列表，
3. 创建一个名为`Dockerfile` 在您的项目目录中，您将在其中扩展官方 SDK 映像，复制您的代码，并添加任何自定义依赖项（如有必要）。例如：

```dockerfile
# Extend the official Rasa SDK image
FROM rasa/rasa-sdk:2.8.4

# Use subdirectory as working directory
WORKDIR /app

# Copy any additional custom requirements, if necessary (uncomment next line)
# COPY actions/requirements-actions.txt ./

# Change back to root user to install dependencies
USER root

# Install extra requirements for actions code, if necessary (uncomment next line)
# RUN pip install -r requirements-actions.txt

# Copy actions folder to working directory
COPY ./actions /app/actions

# By best practices, don't run the code with root user
USER 1001
```

然后，您可以通过以下命令构建镜像：

```shell
docker build . -t <account_username>/<repository_name>:<custom_image_tag>
```

`<custom_image_tag>` 应该引用此图像与其他图像的不同之处。例如，您可以对标签进行版本化或日期化，以及为生产和开发服务器创建具有不同代码的不同标签。每当您更新代码并想要重新部署它时，您都应该创建一个新标签。

- 使用你的自定义动作服务镜像

如果您正在构建此镜像以使其可从其他服务器使用，例如 Rasa X 或 Rasa Enterprise 部署，您应该将映像推送到云存储库。

本文档假设您将映像推送到 DockerHub。 DockerHub 将允许您免费托管多个公共存储库和一个私有存储库。请务必先创建一个帐户并创建一个存储库来存储您的图像。您还可以将映像推送到不同的 Docker 注册表，例如 Google Container Registry、Amazon Elastic Container Registry 或 Azure Container Registry。

您可以通过以下方式将映像推送到 DockerHub：

```shell
docker login --username <account_username> --password <account_password>
docker push <account_username>/<repository_name>:<custom_image_tag>
```

要对图像进行身份验证并将图像推送到不同的容器注册表，请参阅您选择的容器注册表的文档。

如何引用自定义操作图像取决于您的部署。为您的部署选择相关文档：

[Server Quick-Install](https://rasa.com/docs/rasa-x/installation-and-setup/customize/#quick-install-script-customizing)

[Helm Chart](https://rasa.com/docs/rasa-x/installation-and-setup/customize/#adding-a-custom-action-server)

[Docker Compose](https://rasa.com/docs/rasa-x/installation-and-setup/customize/#connecting-a-custom-action-server)

[Rasa Open Source Only](https://rasa.com/docs/rasa/2.x/docker/deploying-in-docker-compose#using-docker-compose-to-run-multiple-services)