# 对话模式

## 闲聊和问答

FAQ 助手是最容易构建的助手，通常是任何人构建的第一种助手。此页面是处理常见问题和闲聊等非上下文问题所需的概念和培训数据的指南。

常见问题解答和闲聊是两种情况，其中对话助手使用一组固定的消息进行响应，并且无论对话之前发生了什么，助手都应始终以相同的方式回答。例如，在接下来的对话中，每个问题都可以在对话中的任何时候提出，答案与用户之前所说的任何内容无关。

### 分步指南

要处理常见问题解答和闲聊，您需要基于规则的对话管理策略（RulePolicy）和返回问题适当响应的简单方法（ResponseSelector）。

- 更新配置

对于常见问题解答和闲聊，您总是希望助手在每次提出相同类型的问题时都以相同的方式做出回应。规则允许你做到这一点。要使用规则，您需要将 RulePolicy 添加到配置文件中的策略中：

`config.yml`

```yaml
policies:
# other policies
- name: RulePolicy
```

接下来，将 ResponseSelector 包含在配置文件中的 NLU 管道中。 ResponseSelector 需要特征化器和意图分类器才能工作，因此它应该位于管道中的这些组件之后，例如：

```yml
pipeline:
  - name: WhitespaceTokenizer
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CountVectorsFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: char_wb
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 100
  - name: EntitySynonymMapper
  - name: ResponseSelector
    epochs: 100
```

默认情况下，ResponseSelector 将为所有检索意图构建一个检索模型。要分别检索常见问题解答和闲聊的响应，请使用多个 ResponseSelector 组件并指定检索意图键

```yml
pipeline:
# Other components
- name: ResponseSelector
  epochs: 100
  retrieval_intent: faq
- name: ResponseSelector
  epochs: 100
  retrieval_intent: chitchat
```

- 定义检索意图和 `ResponseSelector`

考虑一个示例，您有 20 个不同的常见问题解答。尽管每个问题都表示为一个单独的意图，但所有常见问题解答意图在对话中都以相同的方式处理。对于每个常见问题解答意图，助手会根据提出的问题检索正确的响应。

您可以使用单个操作而不是编写 20 条规则，例如`utter_faq` 使用单个规则处理所有常见问题解答，方法是将它们组合在一个名为例如`faq`的检索意图下。

单个操作使用 `ResponseSelector` 的输出来返回用户询问的特定常见问题解答的正确响应。

- 创建规则

您只需为每个检索意图编写一个规则。然后将按相同方式处理分组在该检索意图下的所有意图。动作名称以 `utter_` 开头，以检索意图的名称结尾。编写回答常见问题和闲聊的规则：

`rules.yml`

```yaml
rules:
  - rule: respond to FAQs
    steps:
    - intent: faq
    - action: utter_faq
  - rule: respond to chitchat
    steps:
    - intent: chitchat
    - action: utter_chitchat
```

`utter_faq` 和 `utter_chitchat` 动作将使用 `ResponseSelector` 的预测来返回实际的响应消息。

- 更新nlu训练数据

`ResponseSelector` 的 NLU 训练示例看起来与常规训练示例相同，只是它们的名称必须指代它们分组的检索意图：

`nlu.yml`

```yaml
nlu:
  - intent: chitchat/ask_name
    examples: |
      - What is your name?
      - May I know your name?
      - What do people call you?
      - Do you have a name for yourself?
  - intent: chitchat/ask_weather
    examples: |
      - What's the weather like today?
      - Does it look sunny outside today?
      - Oh, do you mind checking the weather for me please?
      - I like sunny days in Berlin.
```

请务必更新您的域文件以包含添加的闲聊意图：

`domain.yml`

```yaml
intents:
# other intents
- chitchat
```

- 定义响应内容

`ResponseSelector` 的响应遵循与检索意图相同的命名约定。除此之外，它们还可以具有正常机器人响应的所有特征。对于上面列出的闲聊意图，我们的响应可能如下所示：

`domain.yml`

```yaml
responses:
  utter_chitchat/ask_name:
  - image: "https://i.imgur.com/zTvA58i.jpeg"
    text: Hello, my name is Retrieval Bot.
  - text: I am called Retrieval Bot!
  utter_chitchat/ask_weather:
  - text: Oh, it does look sunny right now in Berlin.
    image: "https://i.imgur.com/vwv7aHN.png"
  - text: I am not sure of the whole week but I can see the sun is out today.
```

### 总结

```
将 RulePolicy 添加到您的策略中，并将 ResponseSelector 添加到您在 config.yml 中的管道
添加至少一项规则以响应常见问题/闲聊
添加常见问题解答/闲聊意图的示例
添加常见问题解答/闲聊意图的响应
更新您的意图领域
```

现在，您的助手应该能够正确且一致地响应常见问题解答或闲聊，即使这些感叹词发生在您的助手正在帮助用户完成另一项任务时。

## 处理业务逻辑

会话助手通常需要向用户询问信息以帮助他们。您可以使用表单来收集所需的用户信息并完成请求。

会话助手通常支持用户目标，这些目标涉及在为用户做某事之前从用户那里收集所需的信息

此页面是处理收集用户信息以完成请求的业务逻辑的指南。

### 分步指南

表单通过提示用户输入信息来工作，直到它收集了所有必需的信息。信息存储在插槽中。一旦所有必需的插槽都被填满，机器人就会满足用户的原始请求。

- 定义表单

要定义表单，您需要定义：1.槽映射：收集所需的信息，2.响应：您的机器人应如何询问每条信息

**槽映射**

对于餐厅搜索示例，我们希望从用户那里收集以下信息：

```
cuisine
number of people
whether they want to sit outside or not
```

您可以通过为每条所需信息指定槽映射来定义域中的表单。插槽映射定义了需要哪些插槽，以及如何填充每个插槽：

`domain.yml`

```yaml
forms:  # 表单
  restaurant_form:
    required_slots:
        cuisine:
          - type: from_entity
            entity: cuisine
        num_people:
          - type: from_entity
            entity: number
        outdoor_seating:
          - type: from_intent
            intent: affirm
            value: true
          - type: from_intent
            intent: deny
            value: false
```
对于从实体填充的任何插槽，都需要将实体添加到域中。
`domain.yml`
```yml
entities:  # 需要填充的实体插槽
  - cuisine
  - number   
```

DucklingEntityExtractor 可以提取像数字这样的实体。要使用它，请将 DucklingEntityExtractor 添加到您的 NLU 管道中：
`config.yml`

```yaml
language: en
pipeline:
# other components
- DucklingEntityExtractor:  # numbert提取器
  dimensions: ["number"]
```
根据用户的意图填充outdoor_seating槽：如果是`affirm`，那就是`true`，如果是`deny`，那就是`false`。

由于表单依赖于某些可用的槽，你需要将这些槽添加到域。填满表格的空位通常不会影响对话。将`influence_conversation` 设置为 `false` 以在对话期间忽略它们的值：

`domain.yml`

```yml
slots: # 插槽
  cuisine:
    type: text
    auto_fill: false
    influence_conversation: false
  num_people:
    type: float
    auto_fill: false
    influence_conversation: false
  outdoor_seating:
    type: text
    auto_fill: false
    influence_conversation: false
```
**验证槽**

通常，您需要在接受用户输入之前对其进行验证，例如通过检查给定`cuisine`是否在您的助手的可用美食数据库中。有关验证操作的更多信息，请参阅验证表单输入的文档。

**请求槽**

要指定机器人应如何询问所需信息，您可以在域中定义名为 `utter_ask_{slotname}` 的响应：

`domain.yml`

```yml
responses:  # 响应插槽
  utter_ask_cuisine:
    - text: "What cuisine?"
  utter_ask_num_people:
    - text: "How many people?"
  utter_ask_outdoor_seating:
    - text: "Do you want to sit outside?"
```

- 更新配置

表单的快乐路径应定义为规则，这意味着您需要将 RulePolicy 添加到您的策略中：

`config.yml`

```yml
policies:
  - name: RulePolicy
```

- 创建规则

表单本身负责向用户询问所有必需信息的逻辑，因此您只需要两条规则来实现表单的快乐路径：一条定义何时开始，另一条定义填写完成后会发生什么。对于餐厅搜索示例，在现实生活中，助手会根据用户的偏好查找餐厅。在这种情况下，机器人会发出响应，其中包含将用于搜索的详细信息。

`rules.yml`

```yaml
rules:
  - rule: activate restaurant form
    steps:
      - intent: request_restaurant   # intent that triggers form activation
      - action: restaurant_form      # run the form
      - active_loop: restaurant_form # this form is active

  - rule: submit form
    condition:
    - active_loop: restaurant_form   # this form must be active
    steps:
      - action: restaurant_form      # run the form
      - active_loop: null            # the form is no longer active because it has been filled
      - action: utter_submit         # action to take after the form is complete
      - action: utter_slots_values   # action to take after the form is complete
```
通过拆分表单的激活和提交，如果用户提供意外输入或通过闲聊打断表单，规则仍然适用。

- 更新训练数据

您需要为应该激活表单的意图添加示例，以及用户将如何提供所需信息的示例。

**表单激活意图**

您需要为应该激活表单的意图提供训练示例。为意图 `request_restaurant` 添加示例：

`nlu.yml`

```yaml
nlu:
- intent: request_restaurant
  examples: |
    - im looking for a restaurant
    - can i get [swedish](cuisine) food in any area
    - a restaurant that serves [caribbean](cuisine) food
    - id like a restaurant
    - im looking for a restaurant that serves [mediterranean](cuisine) food
    - can i find a restaurant that serves [chinese](cuisine)
```
默认情况下，使用 `from_entity` 填充的槽可以由任何用户话语填充，无论其意图如何，只要提取了正确的实体即可。这意味着如果用户在他们的第一条消息中提供`cuisine`实体，则该位置将在表单的开头填充，并且机器人不会再次向他们询问美食。

**表单填充意图**

当表单在填充槽时，它不会关注预测的是哪个意图，除非槽映射明确需要或排除一个意图。

对于餐厅搜索示例，`outdoor_seating` 槽映射到两个意图，因此您需要添加训练数据对于这些意图。

对于`cuisine, number`槽，没有指定意图，因此您可以将示例添加到通用`inform`意图。您需要注释`cuisine`实体，以便 `DIETClassifier` 可以学习提取它。您不需要注释`number`实体，因为 `DucklingEntityExtractor` 是一个基于规则的提取器，未根据您的训练数据进行训练。每个意图仅显示几个示例；为了让您的机器人正常工作，您应该添加比此处显示的更多的训练数据：

`nlu.yml`
```yml
nlu:
- intent: affirm
  examples: |
    - Yes
    - yes, please
    - yup
    
- intent: deny
  examples: |
    - no don't
    - no
    - no I don't want that

- intent: inform
  examples: |
    - [afghan](cuisine) food
    - how bout [asian oriental](cuisine)
    - what about [indian](cuisine) food
    - uh how about [turkish](cuisine) type of food
    - um [english](cuisine)
    - im looking for [tuscan](cuisine) food
    - id like [moroccan](cuisine) food
    - for ten people
    - 2 people
    - for three people
    - just one person
    - book for seven people
    - 2 please
    - nine people
```
更新您的域以包含以下意图：
`domain.yml`

```yaml
intents:
  - request_restaurant
  - affirm
  - deny
  - inform
```

- 定义响应

添加表单提交后发送的响应：

`domain.yml`

```yaml
responses:
  utter_submit:
  - text: "All done!"
  utter_slots_values:
  - text: "I am going to run a restaurant search using the following parameters:\n
            - cuisine: {cuisine}\n
            - num_people: {num_people}\n
            - outdoor_seating: {outdoor_seating}"
```

### 总结

```
将 RulePolicy 添加到 config.yml
用域中的槽映射定义表单
将所有必需的槽添加到域
添加用于激活和提交表单的规则
添加用于激活表单的意图的示例
添加示例用于填充所需槽的意图
定义表单完成后机器人要采取的操作或响应
使用您定义的新意图和操作更新您的域
```

要尝试新定义的表单，请通过运行 `rasa train` 重新训练机器人模型并启动 `rasa shell`。因为 `DucklingEntityExtractor` 用于提取实体，所以您还需要在后台启动 Duckling（请参阅运行 Duckling 的说明）。

## 回退和介入

这是有关如何处理助手的各种故障的指南。

即使你完美地设计了你的机器人，用户也不可避免地会向你的助手说出你没有预料到的话。在这些情况下，你的助手会失败，重要的是你要确保它优雅地完成。

### 控制超出的意图

为避免用户沮丧，您可以处理您知道用户可能会问的问题，但您尚未实现用户目标。

- 创建超出的意图

您需要在 NLU 训练数据中定义 `out_of_scope` 意图，并将任何已知的超出范围的请求添加为训练示例，例如：

`nlu.yml`

```yaml
nlu:
- intent: out_of_scope
  examples: |
    - I want to order food
    - What is 2 + 2?
    - Who's the US President?
```

与每一个意图一样，您应该从真实对话中获取大部分示例。

- 定义响应内容

您需要在域文件中定义一个超出范围的响应。使用话语 `utter_out_of_scope` 作为默认响应，如下所示：

`domain.yml`

```yaml
responses:
  utter_out_of_scope:
  - text: Sorry, I can't handle that request.
```

- 创建超出的规则

最后，您需要为超出范围的请求编写一个规则

`rules.yml`

```yaml
rules:
- rule: out-of-scope
  steps:
  - intent: out_of_scope
  - action: utter_out_of_scope
```

- 处理特定的超出范围的消息

如果您观察到您的用户询问您将来希望将其转化为用户目标的某些事情，您可以将这些作为单独的意图来处理，让用户知道您已经理解了他们的信息，但目前还没有解决方案。例如，如果用户问“我想申请 Rasa 的工作”，我们可以回复“我知道你在找工作，但我担心我还不能掌握那个技能”。

与 `out_of_scope` 意图示例类似，您需要使用训练示例创建新意图、定义响应消息并创建规则。

### 回退

尽管 Rasa 会泛化到看不见的消息，但某些消息可能会收到较低的分类置信度。使用 Fallbacks 将有助于确保这些低置信度消息得到妥善处理，让您的助手可以选择使用默认消息进行响应或尝试消除用户输入的歧义。

#### NLU fallback

要处理 NLU 置信度较低的传入消息，请使用 `FallbackClassifier`。使用此配置，当所有其他意图预测低于配置的置信度阈值时，将预测意图 `nlu_fallback`。然后，您可以为预测 `nlu_fallback` 时机器人应该做什么编写规则。

- 更新配置

要使用 `FallbackClassifier`，请将其添加到您的 NLU 管道中：

`config.yml`

```yaml
pipeline:
# other components
- name: FallbackClassifier  # 使用分类器
  threshold: 0.7
```

- 定义响应信息

通过添加响应来定义当消息被分类为低置信度时机器人应发送的消息：

`domain.yml`

```yaml
responses:
  utter_please_rephrase:
  - text: I'm sorry, I didn't quite understand that. Could you rephrase?
```

- 创建一个NLU fallback规则

以下规则将要求用户在发送分类为低置信度的消息时重新措辞：

`rules.yml`

```yaml
rules:
- rule: Ask the user to rephrase whenever they send a message with low NLU confidence
  steps:
  - intent: nlu_fallback
  - action: utter_please_rephrase
```

#### 处理低置信度

由于用户可能会发送意外消息，因此他们的行为可能会导致他们走上未知的对话路径。 Rasa 的机器学习策略（例如 TED Policy）针对处理这些未知路径进行了优化。

要处理机器学习策略无法以高置信度预测下一个动作的情况，您可以配置 Rule Policy 以在没有 Policy 的情况下预测默认动作具有高于可配置阈值的置信度的下一个动作预测。

您可以使用以下步骤配置在动作置信度低的情况下运行的动作以及相应的置信度阈值：

- 更新配置

您需要将 RulePolicy 添加到 `config.yml` 中的策略中。默认情况下，规则策略带有以下设置：

`config.yml`

```yaml
policies:
- name: RulePolicy
  # Confidence threshold for the `core_fallback_action_name` to apply.
  # The action will apply if no other action was predicted with
  # a confidence >= core_fallback_threshold
  core_fallback_threshold: 0.4
  core_fallback_action_name: "action_default_fallback"
  enable_fallback_prediction: True
```

- 定义默认响应消息

要定义当动作置信度低于阈值时您的机器人会说什么，请定义响应 `utter_default`

`domain.yml`

```yaml
responses:
  utter_default:
  - text: Sorry I didn't get that. Can you rephrase?
```

当动作置信度低于阈值时，Rasa 将运行动作 `action_default_fallback`。这将发送响应 `utter_default` 并恢复到导致回退的用户消息之前的对话状态，因此不会影响对未来动作的预测。

- 自定义默认行为

`action_default_fallback` 是 Rasa Open Source 中的默认操作，它将 `utter_default` 响应发送给用户。您可以创建自己的自定义操作以用作后备（有关自定义操作的更多信息，请参阅自定义操作）。以下代码片段是一个自定义操作的实现，它与 `action_default_fallback` 执行相同但调度不同的模板 `utter_fallback_template`：

`actions.py`

```python
from typing import Any, Text, Dict, List

from rasa_sdk import Action, Tracker
from rasa_sdk.events import UserUtteranceReverted
from rasa_sdk.executor import CollectingDispatcher

class ActionDefaultFallback(Action):
    """Executes the fallback action and goes back to the previous state
    of the dialogue"""

    def name(self) -> Text:
        return ACTION_DEFAULT_FALLBACK_NAME

    async def run(
        self,
        dispatcher: CollectingDispatcher,
        tracker: Tracker,
        domain: Dict[Text, Any],
    ) -> List[Dict[Text, Any]]:
        dispatcher.utter_message(template="my_custom_fallback_template")

        # Revert user message which led to fallback.
        return [UserUtteranceReverted()]
```

#### 两级fallback

为了让机器人有机会弄清楚用户想要什么，您通常希望它通过提出澄清问题来尝试消除用户信息的歧义。

两阶段后备是使用以下序列处理多个阶段中的低 NLU 置信度：

```
1.用户消息被分类为低置信度
	要求用户确认意图
2.用户确认或否认意图
	如果他们确认，对话将继续进行，就好像从一开始就对意图进行了高置信度分类一样。不采取进一步的后备步骤。
	如果他们拒绝，则要求用户重新表述他们的消息。
3.用户重新表述他们的意图
	如果消息被高度信任地分类，则对话继续进行，就好像用户从开始。
	如果改写的用户消息仍然具有低置信度，则要求用户确认意图。
4.用户确认或拒绝改写的意图
	如果他们确认，则对话继续进行，就好像用户从一开始就具有此意图.
	如果他们否认，则触发最终的后备动作（例如，移交给人类）。默认的最终回退操作是调用 action_default_fallback。此操作会导致机器人发出 utter_default 响应并重置对话状态 就好像两阶段回退期间发生的转折没有发生一样。 
```

可以使用以下步骤启用两阶段回退：

- 更新配置

将 FallbackClassifier 添加到您的管道，并将 RulePolicy 添加到您的策略配置中：

`config.yml`

```yaml
pipeline:
# other components
- name: FallbackClassifier
  threshold: 0.7

policies:
# other policies
- RulePolicy
```

- 定义回退响应

要定义您的机器人如何要求用户重新表述他们的消息，请定义响应 `utter_ask_rephrase`：

`domain.yml`

```yaml
responses:
  utter_ask_rephrase:
  - text: I'm sorry, I didn't quite understand that. Could you rephrase?
```

Rasa 提供了默认实现来询问用户的意图以及要求用户重新措辞。要自定义这些操作的行为，请参阅有关默认操作的文档。

- 定义两级回退规则

将以下规则添加到您的训练数据中。此规则将确保在收到分类置信度较低的消息时激活两阶段回退：

`rules.yml`

```yaml
rules:
- rule: Implementation of the Two-Stage-Fallback
  steps:
  - intent: nlu_fallback
  - action: action_two_stage_fallback
  - active_loop: action_two_stage_fallback
```

- 定义最终回退操作

要在用户拒绝重新表述的意图时定义机器人的响应，请定义响应 `utter_default`：

`domain.yml`

```yaml
responses:
  utter_default:
  - text: I'm sorry, I can't help you.
```

或者，您可以通过编写自定义操作来自定义 `action_default_fallback` 以获得更复杂的行为。例如，如果您希望机器人呼叫人类并停止与用户交互：

`actions.py`

```python
from typing import Any, Dict, List, Text

from rasa_sdk import Action, Tracker
from rasa_sdk.events import UserUtteranceReverted
from rasa_sdk.executor import CollectingDispatcher

class ActionDefaultFallback(Action):
    def name(self) -> Text:
        return "action_default_fallback"

    def run(
        self,
        dispatcher: CollectingDispatcher,
        tracker: Tracker,
        domain: Dict[Text, Any],
    ) -> List[Dict[Text, Any]]:

        # tell the user they are being passed to a customer service agent
        dispatcher.utter_message(text="I am passing you to a human...")
        
        # assume there's a function to call customer service
        # pass the tracker so that the agent has a record of the conversation between the user
        # and the bot for context
        call_customer_service(tracker)
     
        # pause the tracker so that the bot stops responding to user input
        return [ConversationPaused(), UserUtteranceReverted()]
```

### 人工介入

作为回退操作的一部分，您可能希望机器人移交给人工代理，例如作为两阶段回退中的最终操作，或者当用户明确要求人工时。实现人工切换的一种直接方法是配置您的消息或语音通道，以根据特定的机器人或用户消息切换它所听的主机。

例如，作为两阶段回退的最终操作，机器人可以询问用户，“你想被转移到人工助理吗？”如果他们说是，机器人会发送一条带有特定有效负载的消息，例如“handoff_to_human”到频道。当频道看到此消息时，它会停止收听 Rasa 服务器，并向人工频道发送一条消息，其中包含该点之前的聊天对话记录。

从前端移交给人工的实现将取决于您正在使用哪个频道。您可以在 `Financial Demo` 和 `Helpdesk-Assistant` 中看到使用聊天室频道改编的示例实现 入门包。 

### 总结

为了让您的助手优雅地处理故障，您应该处理已知的超出范围的消息并添加一种回退行为形式。如果您想添加人工切换，您可以添加它或者作为您的回退设置中的最后一步。以下是您需要对每种方法进行的更改的摘要：

对于范围外意图

```
将每个范围外意图的训练示例添加到您的 NLU 数据
定义范围外响应或操作
为每个范围外意图定义规则
添加 RulePolicy到 config.yml
```

对于单阶段 NLU 回退

```
在 config.yml 中将 FallbackClassifier 添加到您的管道
定义回退响应或操作
为 nlu_fallback 意图定义规则
将 RulePolicy 添加到 config.yml
```

用于处理低核心置信度：

```
配置config.yml 中核心回退的规则策略
可选择自定义您配置的回退操作
定义 utter_default 
```

响应对于两阶段回退

```
在 config.yml 中将 FallbackClassifier 添加到您的管道
为触发 action_two_stage_fallback 操作的 nlu_fallback 意图定义规则
在您的域中定义范围外意图
将 RulePolicy 添加到 config.yml
```

用于移交给人类

```
配置您的前端以切换主机
编写自定义操作（可能是您的后备操作）以发送移交有效负载
添加触发切换的规则（如果不是回退的一部分）
将 RulePolicy 添加到 config.yml
```

## 处理意外输入

在构建会话助手时，您可以依靠的一件事是用户会说出意想不到的话。此页面是处理意外输入的指南。

意外输入是与您定义的快乐路径的偏差。例如：
```
- 用户在谈论他们的订阅时走开了，然后回来说“嗨！”

- 用户问“为什么你需要知道这个？”当机器人询问他们的电子邮件地址时。
```
此页面是有关处理仍在您的机器人域内的意外输入的方法的指南。根据您尝试处理的意外输入类型，所描述的部分或全部方法可能适用于您。本指南不是关于消除用户输入的歧义或处理超出范围的问题；对于这些情况，请参阅回退和介入指南。

### 用户打断

有两种意外输入：一般打断和上下文打断。通用打断是中断，无论对话上下文如何，都应该始终得到相同的响应。如果您已经有定义对意图的响应的规则，则无需执行任何其他操作即可将其视为中断。常见问题和闲聊是常见的通用打断。上下文打断是其响应取决于对话上下文。例如，如果用户问“你为什么需要那个？”，答案将取决于机器人刚刚要求的内容。

### 上下文打断

处理上下文打断似于处理上下文对话。

上下文打断的一个常见情况是在填写表格时，用户会问“你为什么需要知道这个？”或“你能解释一下吗？”。每个插槽的响应应该不同。

由于我们希望 `requests_slot` 影响对话，我们需要将 `slot requested_slot` 的属性 `influence_conversation` 设置为 `true`，并为其分配分类类型：

`domain.yml`

```yml
slots:
  requested_slot:
    type: categorical
    values:
      - cuisine
      - num_people
      - outdoor_seating
      - preferences
      - feedback
    influence_conversation: true
```

这意味着对话模型在进行预测时会关注 `slot` 的值（阅读更多关于 slot 如何影响助手的行为）。然后，您可以根据 `requested_slot` 的值来编写针对打断的特定响应的故事，例如

`stories.yml`

```yml
stories:
- story: cuisine interjection
  steps:
  - intent: request_restaurant
  - action: restaurant_form
  - active_loop: restaurant_form
  - slot_was_set:
    - requested_slot: cuisine
  - intent: explain
  - action: utter_explain_cuisine
  - action: restaurant_form

- story: number of people interjection
  steps:
  - intent: request_restaurant
  - action: restaurant_form
  - active_loop: restaurant_form
  - slot_was_set:
    - requested_slot: num_people
  - intent: explain
  - action: utter_explain_num_people
  - action: restaurant_form
```

### 总结

您如何处理意外输入取决于响应是否应该是上下文相关的。

对于一般感叹词：

- 定义单轮交互规则
- 使用 ResponseSelector 处理常见问题和闲聊中断

对于上下文感叹词：

- 使请求槽成为分类槽（用于表单)
- 为针对感叹词的特定上下文响应编写故事，在适用的情况下使用槽值

## 上下文对话

考虑上下文通常是提供良好用户体验的关键。此页面是创建上下文对话模式的指南。

在上下文对话中，对话中上一步之外的内容在接下来应该发生的事情中发挥作用。例如，如果用户问“有多少？”，仅从消息中并不清楚用户在问什么。在助手说“你有邮件！”的上下文中，响应可能是“你的邮箱里有五封信”。在关于未付账单的对话中，响应可能是“您有三张逾期账单”。助手需要知道上一个操作才能选择下一个操作。

要创建上下文感知对话助手，您需要定义对话历史记录如何影响下一个响应。

### 分步指南

- 定义槽

插槽是您助手的记忆。插槽存储您的助手稍后需要参考的信息片段，并且可以根据 `slot_was_set` 事件指导对话流。有不同类型的槽，每一种都以自己的方式影响对话流。

在 Concert bot 示例中，`likes_music` 槽是一个布尔槽。如果是真的，机器人会发送一条介绍消息。如果为假，机器人会发送不同的消息。您在域中定义一个插槽及其类型：

`domain.yml`

```yaml
slots:
  likes_music:
    type: bool
```

- 创建stories

故事是对话应该如何进行的例子。在上面的示例中，音乐会机器人对喜欢音乐的用户和不喜欢音乐的用户的响应不同，因为这两个故事：

`stories.yml`

```yml
stories:
  - story: User likes music
    steps:
    - intent: how_to_get_started
    - action: utter_get_started
    - intent: affirm
    - action: action_set_music_preference
    - slot_was_set:
      - likes_music: True
    - action: utter_awesome

  - story: User doesn't like music
    steps:
    - intent: how_to_get_started
    - action: utter_get_started
    - intent: deny
    - action: action_set_music_preference
    - slot_was_set:
      - likes_music: False
    - action: utter_goodbye
```

这些故事根据用户的意图（`affirm`或`deny`）而有所不同。根据用户的意图，自定义操作设置进一步引导对话的槽。

- 配置 TEDPolicy

除了添加故事以考虑上下文之外，机器学习策略还可以帮助您的模型泛化到看不见的对话路径。重要的是要了解使用机器学习策略并不意味着放弃对助手的控制。如果基于规则的策略能够做出预测，则该预测将始终具有更高的策略优先级，并将预测下一个动作。

TEDPolicy 用于处理意外的用户行为。例如，在下面的对话中（摘自 Rasa X 上的对话）：

```yml
stories:
- story: Story from conversation with a2baab6c83054bfaa8d598459c659d2a on November 28th 2019
  steps:
  - checkpoint: STORY_START
  - intent: greet
  - action: action_greet_user
  - slot_was_set:
    - shown_privacy: true
  - intent: ask_whoisit
  - action: action_chitchat
  - intent: ask_whatspossible
  - action: action_chitchat
  - intent: telljoke
  - action: action_chitchat
  - intent: how_to_get_started
    entities:
    - product: x
  - slot_was_set:
    - product: x
  - action: utter_explain_x
  - action: utter_also_explain_nlucore
  - intent: affirm
  - action: utter_explain_nlu
  - action: utter_explain_core
  - action: utter_direct_to_step2
```

在这里我们可以看到用户先完成了一些闲聊任务，然后最终询问他们如何开始使用 Rasa X。TEDPolicy 正确预测应该向用户解释 Rasa X，然后也将他们记下入门路径，而不是先问所有符合条件的问题。

由于机器学习策略已推广到这种情况，您应该将此故事添加到您的训练数据中，以不断改进您的机器人并帮助模型在未来更好地泛化。 Rasa X 是一种工具，可以帮助您改进您的机器人并使其更具情境性。

**设置max_history**

通常，只有一定数量的上下文与您的助手相关。 `max_history` 是 Rasa 对话管理策略的超参数，它控制模型查看对话中的多少步以决定下一步要采取的行动。

在下面的故事中，用户连续三次寻求帮助。前两次，机器人发送相同的消息，但第三次，它把它们交给人类

`stories.yml`

```yml
stories:
  - story: user persists in asking for help
    steps:
    - intent: help
    - action: utter_help
    - intent: help
    - action: utter_help
    - intent: help
    - action: action_human_handoff
```

为了让模型学习这种模式，它至少需要知道前四个步骤，即` max_history` 为四个。如果` max_history` 为 3，模型将没有足够的上下文来查看用户已经发送了两个帮助请求，并且永远不会预测人工切换操作。您可以通过将 `max_history` 传递给配置文件中的策略设置来设置它，例如

`config.yml`

```
policies:
  - name: "TEDPolicy"
    max_history: 5
```

您希望确保将 `max_history` 设置得足够高，以考虑您的助手需要对下一步做什么做出准确预测所需的最多上下文。有关更多详细信息，请参阅有关特征化器的文档。

### 总结

以下是您可以应用的概念摘要，以使您的助手能够进行上下文对话：

- 为上下文对话编写故事
- 使用插槽存储上下文信息以供以后使用
- 根据机器人所需的上下文量适当设置策略的 `max_history` 
- 使用 TEDPolicy 泛化到看不见的对话路径

## 接触用户

有时您希望您的助手在没有用户提示的情况下与用户联系。例如，您可能希望助手在用户打开聊天窗口时发送消息，或者您可能希望在用户有一段时间没有发送消息时提示用户。此页面是使您的助手能够主动与用户联系的指南。

### 接触第一步

在大多数用例中，当用户打开与您的助手的聊天窗口时，您会希望助手发送第一条消息。这样做可以让用户了解机器人能做什么或不能做什么，并让他们进行更成功的对话。某些消息或语音通道具有现有配置选项，可在用户首次开始对话时向助手发送有效负载，但您也可以将此选项添加到您自己的自定义通道。

一旦您将通道配置为发送有效负载，您将需要指定助手应如何反应和问候用户。您可以为此重新使用现有意图的行为，也可以为此指定新的意图和规则。以下是有关如何指定欢迎规则的指南。

- 更新配置信息

由于您为此行为使用规则，因此需要将 RulePolicy 添加到配置文件中：

`config.yml`

```yml
policies:
  # other policies
  - name: RulePolicy
```

- 添加规则

要让助手仅在对话开始时使用欢迎消息响应意图`greet`，请添加以下规则：

`rules.yml`

```yml
rules:
  - rule: welcome user
    conversation_start: true  # this rule only applies at the beginning of a conversation
    steps:
      - intent: greet
      - action: utter_welcome
```

- 添加响应

最后，将 `utter_welcome utter` 操作的响应添加到您的域：

`domain.yml`

```yml
responses:
  utter_welcome:
  - text: Hi there! What can I help you with today?
```

### 外部事件

有时，您希望使用外部设备来改变正在进行的对话过程。例如，如果您在 Raspberry Pi 上连接了湿度传感器，您可以使用它通过您的助手在植物需要浇水时通知您。以下示例来自提醒示例机器人，其中包括提醒和外部事件。

- 触发意图

要让来自外部设备的事件更改正在进行的对话的过程，您可以让设备发布到对话的 `trigger_intent` 端点。 `trigger_intent` 端点将用户意图（可能带有实体）注入到您的对话中。对于 Rasa，就好像您输入了一条按特定意图和实体分类的消息。然后助手会像往常一样预测并执行下一个动作。

例如，以下发布请求会将意图 `EXTERNAL_dry_plant` 和 `plant` 实体注入到 ID 为 `user123` 的对话中：

```shell
curl -H "Content-Type: application/json" -X POST \
  -d '{"name": "EXTERNAL_dry_plant", "entities": {"plant": "Orchid"}}' \
  "http://localhost:5005/conversations/user123/trigger_intent?output_channel=latest"
```

- 获取对话id

在现实生活中，您的外部设备会从 API 或数据库中获取对话 ID。在干植物示例中，您可能有一个植物数据库、给植物浇水的用户以及用户的对话 ID。您的 Raspberry Pi 将直接从数据库中获取对话 ID。要在本地试用提醒机器人示例，您需要手动获取对话 ID。有关更多信息，请参阅提醒机器人自述文件。

- 添加NLU训练数据

在干植物示例中，您的 Raspberry Pi 需要将带有意图 `EXTERNAL_dry_plant` 的消息发送到 `trigger_intent` 端点。此意图将保留给 Raspberry Pi 使用，因此不会有任何 NLU 训练示例。

`domain.yml`

```yml
intents:
  - EXTERNAL_dry_plant
```

- 更新域

要告诉助手哪种植物需要浇水，您可以定义一个实体，将其与意图一起发布。为了能够直接在响应中使用实体值，请使用相同的名称定义一个插槽：

`domain.yml`

```yml
entities:
  - plant

slots:
  plant:
    type: text
    influence_conversation: false
```

- 添加一个规则

您需要一个规则来告诉您的助手在收到来自 Raspberry Pi 的消息时如何响应。

`rules.yml`

```yml
rules:
  - rule: warn about dry plant
    steps:
    - intent: EXTERNAL_dry_plant
    - action: utter_warn_dry
```

- 添加一个响应

您需要为 utter_warn_dry 定义响应文本：

`domain.yml`

```yml
responses:
  utter_warn_dry:
  - text: "Your {plant} needs some water!"
```

响应将使用来自槽植物的值来警告需要浇水的特定植物。

- 试一下

要试用干植物通知示例，您需要启动 Rasa X 或 CallbackChannel。

使用您的对话 ID 运行此 POST 请求以模拟外部事件：

```shell
curl -H "Content-Type: application/json" -X POST -d \
'{"name": "EXTERNAL_dry_plant", "entities": {"plant": "Orchid"}}' \
"http://localhost:5005/conversations/user1234/trigger_intent?output_channel=latest"
```

### 提醒

您可以使用提醒让您的助手在设定的时间后与用户联系。以下示例来自提醒示例机器人。您可以克隆它并按照 README 中的说明试用完整版。

- 设定提醒

**1.定义一个提醒者**

要安排提醒，您需要定义一个返回 `ReminderScheduled` 事件的自定义操作。例如，以下自定义操作将提醒时间从现在开始 5 秒

`actions.py`

```python
import datetime
from rasa_sdk.events import ReminderScheduled
from rasa_sdk import Action

class ActionSetReminder(Action):
    """Schedules a reminder, supplied with the last message's entities."""

    def name(self) -> Text:
        return "action_set_reminder"

    async def run(
        self,
        dispatcher: CollectingDispatcher,
        tracker: Tracker,
        domain: Dict[Text, Any],
    ) -> List[Dict[Text, Any]]:

        dispatcher.utter_message("I will remind you in 5 seconds.")

        date = datetime.datetime.now() + datetime.timedelta(seconds=5)
        entities = tracker.latest_message.get("entities")

        reminder = ReminderScheduled(
            "EXTERNAL_reminder",
            trigger_date_time=date,
            entities=entities,
            name="my_reminder",
            kill_on_user_message=False,
        )

        return [reminder]
```

`ReminderScheduled` 事件的第一个参数是提醒的名称，在本例中为 `EXTERNAL_reminder`。提醒名称稍后将用作触发对提醒的反应的意图。使用 `EXTERNAL_` 前缀命名提醒名称，以便更轻松地查看训练数据中发生的情况。

您可以看到最后消息的实体也传递给提醒。这允许对提醒做出反应的操作使用用户日程安排消息中的实体。

例如，如果您希望助手提醒您给朋友打电话，您可以向它发送一条消息，例如“提醒我给保罗打电话”。如果“Paul”被提取为 PERSON 实体，则对提醒做出反应的动作可以使用它说“记得给 Paul 打电话！”

**2.添加一个规则**

`rules.yml`

```yml
rules:
- rule: Schedule a reminder
  steps:
  - intent: ask_remind_call
    entities:
    - PERSON
  - action: action_schedule_reminder
```

**3.添加训练数据**

`nlu.yml`

```yml
nlu:
- intent: ask_remind_call
  examples: |
    - remind me to call John
    - later I have to call Alan
    - Please, remind me to call Vova
    - please remind me to call Tanja
    - I must not forget to call Juste
```

`domain.yml`

```yml
intents:
  - ask_remind_call
```

**4.更新流程管道**

通过在 config.yml 中将 `SpacyNLP,SpacyEntityExtractor` 添加到您的管道中，您无需在训练数据中注释任何名称，因为 Spacy 具有 `PERSON` 维度：

`config.yml`

```yml
pipeline:
# other components
- name: SpacyNLP
  model: "en_core_web_md"
- name: SpacyEntityExtractor
  dimensions: ["PERSON"]
```

- 响应提醒

**1.定义一个响应**

在收到对 `trigger_intent` 端点的 POST 请求后，机器人会联系用户。但是，提醒会在一定时间后使用您在 `ReminderScheduled` 事件中定义的名称自动将请求发送到正确的对话 ID。

要定义对提醒的反应，您只需要编写一个规则来告诉机器人什么收到提醒意图时要采取的操作。

在呼叫提醒示例中，您希望使用提醒附带的实体来提醒特定人员，因此您需要编写一个自定义操作来执行此操作：

`actions.py`

```python
class ActionReactToReminder(Action):
    """Reminds the user to call someone."""

    def name(self) -> Text:
        return "action_react_to_reminder"

    async def run(
        self,
        dispatcher: CollectingDispatcher,
        tracker: Tracker,
        domain: Dict[Text, Any],
    ) -> List[Dict[Text, Any]]:

        name = next(tracker.get_slot("PERSON"), "someone")
        dispatcher.utter_message(f"Remember to call {name}!")

        return []
```

**2.添加一个规则**

要告诉您的机器人在触发提醒时要运行什么操作，请添加一条规则。

`rules.yml`

```yml
rules:
- rule: Trigger `action_react_to_reminder` for `EXTERNAL_reminder`
  steps:
  - intent: EXTERNAL_reminder
  - action: action_react_to_reminder
```

**3.添加训练数据**

您需要定义触发对提醒做出反应的意图。您不需要添加任何训练示例，因为意图是为提醒保留的。

`domain.yml`

```yml
intents:
- intent: EXTERNAL_reminder
```

- 取消提醒

**1.定义一个取消提醒的动作**

要取消您已安排的提醒，您需要一个返回 `ReminderCancelled()` 事件的自定义操作。

返回 `ReminderCancelled()` 会取消当前安排的所有提醒。如果您只想取消某些提醒，您可以指定一些参数来缩小计划提醒的范围：•

```python
ReminderCancelled(intent="EXTERNAL_greet") # 取消所有带有意图的提醒 EXTERNAL_greet
ReminderCancelled(entities={}) # 取消所有提醒给定实体
ReminderCancelled("...")  #  取消您在创建期间提供的具有给定名称“...”的唯一提醒
```

对于呼叫提醒示例，您可以定义一个自定义操作 `action_forget_reminders` 来取消所有提醒：

`actions.py`

```python
class ForgetReminders(Action):
    """Cancels all reminders."""

    def name(self) -> Text:
        return "action_forget_reminders"

    async def run(
        self, dispatcher, tracker: Tracker, domain: Dict[Text, Any]
    ) -> List[Dict[Text, Any]]:

        dispatcher.utter_message(f"Okay, I'll cancel all your reminders.")

        # Cancel all reminders
        return [ReminderCancelled()]
```

**2.添加一个规则**

`rules.yml`

```yml
rules:
- rule: Cancel a reminder
  steps:
  - intent: ask_forget_reminders
  - action: action_forget_reminders
```

**3.添加训练数据**

您需要定义一个触发取消提醒的意图。

`nlu.yml`

```yml
nlu:
- intent: ask_forget_reminders
  examples: |
    - Forget about the reminder
    - do not remind me
    - cancel the reminder
    - cancel all reminders please
```

您还应该将其添加到 domain.yml：

`domain.yml`

```yml
intents:
- intent: ask_forget_reminders
```

- 试一下

要试用提醒，您需要启动 Rasa X 或 CallbackChannel。您还需要启动操作服务器来安排、响应和取消您的提醒。有关详细信息，请参阅提醒机器人自述文件。

然后，如果您向机器人发送消息，例如提醒我给 Paul Pots 打电话，您应该在五秒钟后收到一条提醒，上面写着“记得给 Paul Pots 打电话！”。
