# 配置

## 概览

配置文件定义了模型将用于根据用户输入进行预测的组件和策略。

语言和管道键指定模型用于进行 NLU 预测的组件。 policy 键定义模型用于预测下一步操作的策略。如果您不知道要选择哪些组件或策略，可以使用 Suggested Config 功能，该功能将推荐合理的默认值。

- 推荐配置

您可以将管道`and/or`策略密钥保留在配置文件之外。当您运行 `rasa train` 时，建议配置功能将为缺少的键选择默认配置来训练模型。

确保在 `config.yml` 文件中使用 2 字母 ISO 语言代码指定语言键。

示例`config.yml `文件：

```yml
language: en

pipeline:
# will be selected by the Suggested Config feature

policies:
- name: MemoizationPolicy
- name: TEDPolicy
  max_history: 5
  epochs: 10
```

选择的配置也将作为注释写入 config.yml 文件，因此您可以查看使用了哪个配置。对于上面的示例，生成的文件可能看起来例如像这样：

```yml
language: en

pipeline:
# # No configuration for the NLU pipeline was provided. The following default pipeline was used to train your model.
# # If you'd like to customize it, uncomment and adjust the pipeline.
# # See https://rasa.com/docs/rasa/tuning-your-model for more information.
#   - name: WhitespaceTokenizer
#   - name: RegexFeaturizer
#   - name: LexicalSyntacticFeaturizer
#   - name: CountVectorsFeaturizer
#   - name: CountVectorsFeaturizer
#     analyzer: char_wb
#     min_ngram: 1
#     max_ngram: 4
#   - name: DIETClassifier
#     epochs: 100
#   - name: EntitySynonymMapper
#   - name: ResponseSelector
#     epochs: 100
#   - name: FallbackClassifier
#     threshold: 0.3
#     ambiguity_threshold: 0.1

policies:
- name: MemoizationPolicy
- name: TEDPolicy
  max_history: 5
  epochs: 10

```

如果您愿意，您可以取消注释其中一个或两个键的建议配置并进行修改。请注意，这将在再次训练时禁用此键的自动建议。只要您将配置注释掉并且自己不为密钥指定任何配置，那么每当您训练新模型时都会建议使用默认配置。

## 管道组件

组件构成您的 NLU 管道并按顺序工作以将用户输入处理为结构化输出。有用于实体提取、意图分类、响应选择、预处理等的组件。

### 语言模型

如果您想在管道中使用预训练的词向量，以下组件会加载所需的预训练模型。

- MitieNLP

摘要：`MITIE `初始化

输出:`Nothing`

依赖: `Nothing`

描述

初始化 MITIE 结构。每个 MITIE 组件都依赖于此，因此应将其放在使用任何 MITIE 组件的每个管道的开头。

配置

MITIE 库需要一个语言模型文件，必须在配置中指定：

```yml
pipeline:
- name: "MitieNLP"
  # language model to load
  model: "data/total_word_feature_extractor.dat"
```

有关从何处获取该文件的更多信息，请转到安装 MITIE。

您还可以使用 MITIE 从语言语料库中预训练您自己的词向量。要做到这一点：

1. 获取一个干净的语言语料库（维基百科转储工作）作为一组文本文件。
2. 在您的语料库上构建并运行 MITIE Wordrep 工具。这可能需要几个小时/几天，具体取决于您的数据集和工作站。您需要 128GB 的 RAM 才能运行 wordrep – 是的，这很多：尝试扩展您的 swap.
3. 将新的 `total_word_feature_extractor.dat` 的路径设置为配置文件中 `MitieNLP `组件的模型参数。有关如何训练 MITIE 词向量的完整示例，请查看 [用Rasa NLU构建自己的中文NLU系统](http://www.crownpku.com/2017/07/27/用Rasa_NLU构建自己的中文NLU系统.html),，这是一篇博客文章，它通过从中文 Wikipedia 转储创建 MITIE 模型。

- SpacyNLP

摘要:`spaCy`语言初始化

输出：Nothing

依赖：Nothing

描述

初始化 spaCy 结构。每个 spaCy 组件都依赖于此，因此应该将其放在使用任何 spaCy 组件的每个管道的开头。

配置

您需要指定要使用的语言模型。该名称将传递给 spacy.load(name)。您可以在 spaCy 文档中找到有关可用模型的更多信息。

```yml
pipeline:
- name: "SpacyNLP"
  # language model to load
  model: "en_core_web_md"

  # when retrieving word vectors, this will decide if the casing
  # of the word is relevant. E.g. `hello` and `Hello` will
  # retrieve the same vector, if set to `False`. For some
  # applications and models it makes sense to differentiate
  # between these two words, therefore setting this to `True`.
  case_sensitive: False
```

有关如何下载 spaCy 模型的更多信息，请前往安装 SpaCy。

除了 SpaCy 的预训练语言模型外，您还可以使用此组件附加您自己训练的 spaCy 模型。

### 分词

标记器将文本拆分为标记。如果您想将意图拆分为多个标签，例如对于预测多个意图或对分层意图结构建模，将以下标志与任何标记器一起使用：

```python
intent_tokenization_flag # 指示是否对意图标签进行标记。将其设置为 True，以便对意图标签进行标记。
intent_split_symbol # 设置分隔符字符串以分割意图标签，默认为下划线 (_)。
```

- 空格

摘要：使用空格作为分隔符的分词器

输出: `tokens` 用于用户消息、响应（如果存在）和意图（如果指定）

依赖: `Nothing`

描述

为每个空格分隔的字符序列创建一个标记。

如果字符满足以下任何条件，则不在：`a-zA-Z0-9_#@&` 中的任何字符都将被替换为空格，然后再在空格上进行分割：

```
字符跟在空格后面: " !word" → "word"
字符前面有一个空格："word!" → "word"
字符在字符串的开头："!word" → "word"
字符在结尾字符串："world!" → "word"
```

注意

```
"wo!rd" → "wo!rd"
```

另外，任何不在`a-zA-Z0-9_#@&.~:\/?[]()!$*+,;=-` ，如果字符不在数字之间将在拆分之前用空格替换

```
"twenty{one" → "twenty", "one" ("{"` is not between numbers)
"20{1" → "20{1" ("{"` is between numbers)
```

注意

```
"name@example.com" → "name@example.com"
"10,000.1" → "10,000.1"
"1 - 2" → "1","2"
```

配置

```yml
pipeline:
- name: "WhitespaceTokenizer"
  # Flag to check whether to split intents
  "intent_tokenization_flag": False
  # Symbol on which intent should be split
  "intent_split_symbol": "_"
  # Regular expression to detect tokens
  "token_pattern": None
```

- 结巴

摘要：中文分词器

输出: `tokens` 用于用户消息、响应（如果存在）和意图（如果指定）

依赖: `Nothing`

描述：使用专门针对中文的 Jieba 标记器创建标记。它只适用于中文。

> 注意
>
> 要使用 JiebaTokenizer，您需要使用 pip3 install jieba。

配置

用户的自定义字典文件可以通过`dictionary_path`指定文件的目录路径来自动加载。如果 `dictionary_path `为 `None`（默认值），则不会使用自定义字典。

```yml
pipeline:
- name: "JiebaTokenizer"
  dictionary_path: "path/to/custom/dictionary/dir"
  # Flag to check whether to split intents
  "intent_tokenization_flag": False
  # Symbol on which intent should be split
  "intent_split_symbol": "_"
  # Regular expression to detect tokens
  "token_pattern": None
```

- Mitie

摘要：使用MITIE分词

输出: `tokens` 用于用户消息、响应（如果存在）和意图（如果指定）

依赖: `MitieNLP`

描述：使用MITIE分词器创建分词

配置

```yml
pipeline:
- name: "MitieTokenizer"
  # Flag to check whether to split intents
  "intent_tokenization_flag": False
  # Symbol on which intent should be split
  "intent_split_symbol": "_"
  # Regular expression to detect tokens
  "token_pattern": None
```

- Spacy

摘要：使用Spacy进行分词

输出: `tokens` 用于用户消息、响应（如果存在）和意图（如果指定）

依赖: `SpacyNLP`

描述：使用Spacy进行分词

配置

```yml
pipeline:
- name: "SpacyTokenizer"
  # Flag to check whether to split intents
  "intent_tokenization_flag": False
  # Symbol on which intent should be split
  "intent_split_symbol": "_"
  # Regular expression to detect tokens
  "token_pattern": None
```

### 特征化

文本特征化器分为两类：稀疏特征化器和密集特征化器。稀疏特征化器是返回具有大量缺失值的特征向量的特征化器，例如零。由于这些特征向量通常会占用大量内存，因此我们将它们存储为稀疏特征。稀疏特征仅存储非零值及其在向量中的位置。因此，我们节省了大量内存，并且能够在更大的数据集上进行训练。

所有特征化器都可以返回两种不同的特征：序列特征和句子特征。序列特征是一个大小矩阵（`numbr-of-tokens x feature-dimension`）。该矩阵包含序列中每个标记的特征向量。这使我们能够训练序列模型。句子特征由大小矩阵（`1 x feature-dimension`）表示。它包含完整话语的特征向量。句子特征可以用于任何词袋模型。因此相应的分类器可以 决定使用什么样的功能。注意：序列和句子特征的`feature-dimension`不必相同。 

- Mitie

摘要：使用 MITIE 特征化器创建用户消息和响应（如果指定）的矢量表示。

输出: 用户消息和响应的`dense_features`

依赖: `MitieNLP`

类型：`Dense featurizer`

描述：使用 MITIE 特征化器为实体提取、意图分类和响应分类创建特征。

> 注意
>
> MitieIntentClassifier 组件不使用。但是可以由管道中稍后使用dense_features的任何组件使用。

配置

句子向量，即完整话语的向量，可以通过两种不同的方式计算，通过均值或通过最大池化。您可以使用选项 pooling 在配置文件中指定池化方法。默认池化方法设置为均值。

```yml
pipeline:
- name: "MitieFeaturizer"
  # Specify what pooling operation should be used to calculate the vector of
  # the complete utterance. Available options: 'mean' and 'max'.
  "pooling": "mean"
```

- Spacy

摘要：使用 spaCy 特征化器创建用户消息和响应（如果指定）的矢量表示。

输出: 用户消息和响应的`dense_features`

依赖: `SpacyNLP`

类型：`Dense featurizer`

描述：使用 spaCy 特征化器为实体提取、意图分类和响应分类创建特征。

配置

句子向量，即完整话语的向量，可以通过两种不同的方式计算，通过均值或通过最大池化。您可以使用选项 pooling 在配置文件中指定池化方法。默认池化方法设置为均值。

```yml
pipeline:
- name: "SpacyFeaturizer"
  # Specify what pooling operation should be used to calculate the vector of
  # the complete utterance. Available options: 'mean' and 'max'.
  "pooling": "mean"
```

- ConveRT

摘要：使用ConveRT模型创建用户消息和响应（如果指定）的矢量表示。

输出: 用户消息和响应的`dense_features`

依赖: `tokens`

类型：`Dense featurizer`

描述：为实体提取、意图分类和响应选择创建特征。它使用默认签名来计算输入文本的向量表示。

> 注意
>
> 由于 ConveRT 模型仅在英语对话语料库上进行训练，因此仅当您的训练数据为英语时才应使用此特征化器。
>
> 要使用 ConveRTFeaturizer，安装 Rasa Open Source时请使用 pip3 install rasa[convert] 。

配置

```yml
pipeline:
- name: "ConveRTFeaturizer"
# Remote URL/Local directory of model files(Required)
"model_url": None
```

- 语言模型

摘要：使用预训练的语言模型创建用户消息和响应（如果指定）的矢量表示。

输出: 用户消息和响应的`dense_features`

依赖: `tokens`

类型：`Dense featurizer`

描述：为实体提取、意图分类和响应选择创建特征。使用预训练的语言模型来计算输入文本的向量表示。

**配置**

在此组件之前包含一个 Tokenizer 组件。您应该通过参数 model_name 指定要加载的语言模型。有关可用的语言模型，请参见下表。此外，您还可以通过指定参数 model_weights 来指定所选语言模型的架构变体。支持架构的完整列表可以在 HuggingFace 文档中找到。如果留空，它将使用原始 Transformers 库加载的默认模型架构（见下表）。

```
+----------------+--------------+-------------------------+
| Language Model | Parameter    | Default value for       |
|                | "model_name" | "model_weights"         |
+----------------+--------------+-------------------------+
| BERT           | bert         | rasa/LaBSE              |
+----------------+--------------+-------------------------+
| GPT            | gpt          | openai-gpt              |
+----------------+--------------+-------------------------+
| GPT-2          | gpt2         | gpt2                    |
+----------------+--------------+-------------------------+
| XLNet          | xlnet        | xlnet-base-cased        |
+----------------+--------------+-------------------------+
| DistilBERT     | distilbert   | distilbert-base-uncased |
+----------------+--------------+-------------------------+
| RoBERTa        | roberta      | roberta-base            |
+----------------+--------------+-------------------------+
```

以下配置加载语言模型 BERT：

```yml
pipeline:
  - name: LanguageModelFeaturizer
    # Name of the language model to use
    model_name: "bert"
    # Pre-Trained weights to be loaded
    model_weights: "rasa/LaBSE"

    # An optional path to a specific directory to download and cache the pre-trained model weights.
    # The `default` cache_dir is the same as https://huggingface.co/transformers/serialization.html#cache-directory .
    cache_dir: null
```

- 正则

摘要：使用正则表达式创建用户消息和响应（如果指定）的矢量表示。

输出: `sparse_features` 用于用户消息和`tokens.pattern`

依赖: `tokens`

类型：`Sparse featurizer`

**描述**

为实体提取和意图分类创建特征。在训练期间，RegexFeaturizer 创建以训练数据格式定义的正则表达式列表。对于每个正则表达式，将设置一个特征，标记该表达式是否在用户消息中找到。所有特征稍后将被送入意图分类器/实体提取器以简化分类（假设分类器在训练阶段已经学会，该集合特征表示某个意图/实体）。目前仅 `CRFEntityExtractor `和 `DIETClassifier` 组件支持用于实体提取的正则表达式功能！

**配置**

通过添加 `case_sensitive: False` 选项使特征化器不区分大小写，默认为 `case_sensitive: True`。

要正确处理中文等不使用空格进行分词的语言，用户需要添加 `use_word_boundaries: False` 选项，默认`use_word_boundaries:True`。

```yml
pipeline:
- name: "RegexFeaturizer"
  # Text will be processed with case sensitive as default
  "case_sensitive": True
  # use match word boundaries for lookup table
  "use_word_boundaries": True
```

**配置增量训练**

为了确保 `sparse_features` 在增量训练期间具有固定大小，应配置组件以考虑将来可能添加到训练数据中的其他模式。为此，请在从头开始训练基本模型时配置 `number_additional_patterns` 参数：

```yml
pipeline:
- name: RegexFeaturizer
  number_additional_patterns: 10
```

如果用户未配置，该组件将使用训练数据中当前存在的模式数量的两倍（包括查找表和正则表达式模式）作为 `number_additional_patterns` 的默认值。这个数字至少保持在 10，以避免在增量训练期间过于频繁地用完新模式的额外插槽。一旦组件用完额外的模式槽，新模式就会被丢弃，并且在特征化过程中不会考虑。此时，建议从头开始重新训练新模型。

- 计数向量

摘要：创建用户消息、意图和响应的词袋表示。

输出: 用户消息、意图、响应的`sparse_features`

依赖: `tokens`

类型：`Sparse featurizer`

**描述**

为意图分类和响应选择创建特征。使用 sklearn 的 `CountVectorizer` 创建用户消息、意图和响应的词袋表示。所有仅由数字组成的标记（例如 123 和 99 但不包括 a123d）将分配给相同的功能。

**配置**

有关配置参数的详细说明，请参阅 sklearn 的 CountVectorizer 文档。

可以使用`analyzer`配置参数将此特征化器配置为使用单词或字符 n-gram。默认情况下，`analyzer`设置为`word`，因此单词标记计数用作特征。如果要使用字符 n-gram，请将`analyzer`设置为 `char,char_wb`。 n-gram 的下边界和上边界可以通过参数 `min_ngram` 和 `max_ngram` 进行配置。默认情况下，它们都设置为 1。默认情况下，特征化器采用单词的引理，而不是直接使用可用的单词。词的引理目前仅由 SpacyTokenizer 设置。您可以通过将 `use_lemma` 设置为 `False` 来禁用此行为。

> 注意
>
> 选项 `char_wb` 仅从单词边界内的文本创建字符 n-gram；单词边缘的 n-gram 用空格填充。此选项可用于创建子词语义散列。
>
> 对于字符 n-gram，不要忘记增加 min_ngram 和 max_ngram 参数。否则，词汇表将只包含单个字母。

处理词汇外 (OOV) 词：

> 注意
>
> analyzer是word时生效

由于训练是在有限的词汇数据上进行的，因此不能保证在预测过程中算法不会遇到未知单词（训练期间未见过的单词）。为了教算法如何处理未知词，训练数据中的一些词可以用通用词 OOV_token 代替。在这种情况下，在预测过程中，所有未知词都将被视为这个通用词 OOV_token。

例如，可能会在训练数据中创建单独的意图超出范围，其中包含不同数量的 OOV_token 的消息，可能还有一些额外的通用词。然后算法可能会将带有未知单词的消息分类为此意图超出范围。

您可以设置 OOV_token 或单词列表 OOV_words：

```
OOV_token 为看不见的单词设置关键字；如果训练数据在某些消息中包含 OOV_token 作为单词，则在预测期间，训练期间未看到的单词将替换为提供的 OOV_token；如果 OOV_token=None（默认行为） 在训练期间没有看到的单词将在预测时间被忽略；

OOV_words 设置在训练期间被视为 OOV_token 的单词列表；如果已知应被视为词汇表外的单词列表，则可以将其设置为 OOV_words 而不是在训练数据中手动更改它或使用自定义预处理器。
```

> 注意
>
> 该特征化器通过计算单词来创建词袋表示，因此句子中 OOV_token 的数量可能很重要。
>
> 提供 OOV_words 是可选的，训练数据可以包含手动输入的 OOV_token 或自定义附加预处理器。仅当训练数据中存在此标记或提供了 OOV_words 列表时，才会用 OOV_token 替换未见过的单词。

 如果要在用户消息和意图之间共享词汇表，则需要将选项 use_shared_vocab 设置为 True。在这种情况下，在意图中的标记和用户消息之间建立一个通用词汇集。

```yml
pipeline:
- name: "CountVectorsFeaturizer"
  # Analyzer to use, either 'word', 'char', or 'char_wb'
  "analyzer": "word"
  # Set the lower and upper boundaries for the n-grams
  "min_ngram": 1
  "max_ngram": 1
  # Set the out-of-vocabulary token
  "OOV_token": "_oov_"
  # Whether to use a shared vocab
  "use_shared_vocab": False
```

**配置增量训练**

为确保 sparse_features 在增量训练期间具有固定大小，应将组件配置为考虑将来可能作为新训练示例的一部分添加的其他词汇标记。为此，请在从头开始训练基本模型时配置 additional_vocabulary_size 参数：

```yml
pipeline:
- name: CountVectorsFeaturizer
  additional_vocabulary_size:
    text: 1000
    response: 1000
    action_text: 1000
```

如上例所示，您可以为每个`text`（用户消息）、`response`（ResponseSelector 使用的机器人响应）和 `action_text`（ResponseSelector 不使用的机器人响应）定义额外的词汇量。如果您正在构建一个共享词汇表（`use_shared_vocab=True`），您只需要为 `text` 属性定义一个值。如果用户未配置任何属性，则该组件将当前词汇大小的一半作为该属性的`additional_vocabulary_sizee`的默认值。这个数字至少保持在 1000，以避免在增量训练期间过于频繁地用完额外的词汇槽。一旦组件用完额外的词汇槽，新的词汇标记就会被丢弃并且在特征化过程中不会被考虑。此时，建议从头开始重新训练新模型。

上述配置参数是您应该配置的参数，以使您的模型适合您的数据。但是，存在可以调整的附加参数。

- 词法句法

摘要：为用户消息创建词汇和句法特征以支持实体提取。

输出: 用户消息的`sparse_features`

依赖: `tokens`

类型：`sparse featurizer`

**描述**

为实体提取创建特征。在用户消息中的每个令牌上移动一个滑动窗口，并根据配置创建功能（见下文）。由于存在默认配置，因此您无需指定配置。

**配置**

您可以配置特征化器应该提取的词汇和句法特征。提供以下功能

```
==============  ==========================================================================================
Feature Name    Description
==============  ==========================================================================================
BOS             Checks if the token is at the beginning of the sentence.
EOS             Checks if the token is at the end of the sentence.
low             Checks if the token is lower case.
upper           Checks if the token is upper case.
title           Checks if the token starts with an uppercase character and all remaining characters are
                lowercased.
digit           Checks if the token contains just digits.
prefix5         Take the first five characters of the token.
prefix2         Take the first two characters of the token.
suffix5         Take the last five characters of the token.
suffix3         Take the last three characters of the token.
suffix2         Take the last two characters of the token.
suffix1         Take the last character of the token.
pos             Take the Part-of-Speech tag of the token (``SpacyTokenizer`` required).
pos2            Take the first two characters of the Part-of-Speech tag of the token
                (``SpacyTokenizer`` required).
==============  ==========================================================================================
```

当特征化器在带有滑动窗口的用户消息中的标记上移动时，您可以在滑动窗口中定义先前标记、当前标记和下一个标记的特征。您将特征定义为 [before, token, after] 数组。如果您想为之前的令牌、当前令牌和之后的令牌定义功能，您的功能配置将如下所示：

```yml
pipeline:
- name: LexicalSyntacticFeaturizer
  "features": [
    ["low", "title", "upper"],
    ["BOS", "EOS", "low", "upper", "title", "digit"],
    ["low", "title", "upper"],
  ]
```

这个配置也是默认配置

> 如果你想使用 pos 或 pos2 你需要将 SpacyTokenizer 添加到你的管道中。

### 意图分类

意图分类器将域文件中定义的意图之一分配给传入的用户消息。

- Mitie

摘要：MITIE 意图分类器（使用文本分类器）

输出: `intent`

依赖: `tokens`和`MitieNLP`

输出实例

```json
{
    "intent": {"name": "greet", "confidence": 0.98343}
}
```

**描述**

该分类器使用 MITIE 来执行意图分类。底层分类器使用具有稀疏线性内核的多类线性 SVM（请参阅 MITIE 训练器代码中的 `train_text_categorizer_classifier` 函数）。

> 注意
>
> 该分类器不依赖任何特征化器，因为它自己提取特征。

配置

```yml
pipeline:
- name: "MitieIntentClassifier"
```

- Sklearn

摘要：sklearn意图分类

输出: `intent`和`intent_ranking`

依赖: `dese_features`用于用户信息

输出实例

```json
{
    "intent": {"name": "greet", "confidence": 0.78343},
    "intent_ranking": [
        {
            "confidence": 0.1485910906220309,
            "name": "goodbye"
        },
        {
            "confidence": 0.08161531595656784,
            "name": "restaurant_search"
        }
    ]
}
```

**描述**

sklearn 意图分类器训练一个线性 SVM，该 SVM 使用网格搜索进行优化。它还提供了没有“获胜”的标签的排名。 `SklearnIntentClassifier` 之前需要在管道中使用密集的特征化器。这个密集的特征化器创建了用于分类的特征。有关算法本身的更多信息，请查看 GridSearchCV 文档。

**配置**

在 SVM 的训练期间，运行超参数搜索以找到最佳参数集。在配置中，您可以指定将要尝试的参数。

```yml
pipeline:
- name: "SklearnIntentClassifier"
  # Specifies the list of regularization values to
  # cross-validate over for C-SVM.
  # This is used with the ``kernel`` hyperparameter in GridSearchCV.
  C: [1, 2, 5, 10, 20, 100]
  # Specifies the kernel to use with C-SVM.
  # This is used with the ``C`` hyperparameter in GridSearchCV.
  kernels: ["linear"]
  # Gamma parameter of the C-SVM.
  "gamma": [0.1]
  # We try to find a good number of cross folds to use during
  # intent training, this specifies the max number of folds.
  "max_cross_validation_folds": 5
  # Scoring function used for evaluating the hyper parameters.
  # This can be a name or a function.
  "scoring_function": "f1_weighted"
```

- 关键词

摘要：简单的关键字匹配意图分类器，适用于小型短期项目。

输出: `intent`

依赖: Nothing

输出实例

```json
{
    "intent": {"name": "greet", "confidence": 1.0}
}
```

**描述**

该分类器通过在消息中搜索关键字来工作。默认情况下，匹配区分大小写，仅搜索用户消息中关键字字符串的完全匹配。意图的关键字是 NLU 训练数据中该意图的示例。这意味着整个示例都是关键字，而不是示例中的单个单词。

> 注意
>
> 此分类器仅适用于小型项目或入门。如果您的 NLU 训练数据很少，可以查看 Tuning Your Model 中推荐的管道。

配置

```yml
pipeline:
- name: "KeywordIntentClassifier"
  case_sensitive: True
```

- DIET

摘要：Dual Intent Entity Transformer (DIET) 用于意图分类和实体提取

输出: `entities,intent,intent_ranking`

依赖: 用于用户消息的`dense_features` 和/或`sparse_features` 以及可选的意图

输出实例

```json
{
    "intent": {"name": "greet", "confidence": 0.8343},
    "intent_ranking": [
        {
            "confidence": 0.385910906220309,
            "name": "goodbye"
        },
        {
            "confidence": 0.28161531595656784,
            "name": "restaurant_search"
        }
    ],
    "entities": [{
        "end": 53,
        "entity": "time",
        "start": 48,
        "value": "2017-04-10T00:00:00.000+02:00",
        "confidence": 1.0,
        "extractor": "DIETClassifier"
    }]
}
```

**描述**

DIET（Dual Intent and Entity Transformer）是一种用于意图分类和实体识别的多任务架构。该架构基于两个任务共享的转换器。实体标签序列通过与输入标记序列相对应的转换器输出序列顶部的条件随机场 (CRF) 标记层进行预测。对于意图标签，完整话语和意图标签的转换器输出被嵌入到单个语义向量空间中。我们使用点积损失来最大化与目标标签的相似性并最小化与负样本的相似性。

如果您想了解有关该模型的更多信息，请查看 YouTube 上的算法白板系列，其中我们详细解释了模型架构。

> 注意
>
> 如果在预测期间，消息仅包含训练期间未见过的单词，并且没有使用 Out-Of-Vocabulary 预处理器，则以 0.0 的置信度预测空意图 None。如果您仅将 CountVectorsFeaturizer 与单词分析器一起用作特征化器，则可能会发生这种情况。如果您使用 char_wb 分析器，您应该始终获得置信度值 > 0.0 的意图。

**配置**

如果您只想将 DIETClassifier 用于意图分类，请将 entity_recognition 设置为 False。如果您只想进行实体识别，请将 intent_classification 设置为 False。默认情况下 DIETClassifier 两者都做，即 entity_recognition 和 intent_classification 设置为 True。

您可以定义许多超参数来适应模型。如果要调整模型，请先修改以下参数：

```python
epochs
# 此参数设置算法将看到训练数据的次数（默认值：300）。一个 epoch 等于所有训练示例的一次前向传递和一次反向传递。有时模型需要更多的 epoch 才能正确学习。有时更多的时期不会影响性能。时期数越少，模型训练得越快。
hidden_layers_sizes
# 此参数允许您定义用户消息和意图的前馈层数及其输出维度（默认值：text：[]，label：[]）。列表中的每个条目都对应一个前馈层。比如你设置text：[256, 128]，我们会在transformer前面添加两个前馈层。输入标记的向量（来自用户消息）将被传递到这些层。第一层的输出维度为 256，第二层的输出维度为 128。如果使用空列表（默认行为），则没有前馈层 被添加。确保仅使用正整数值。通常，使用 2 的幂数。此外，通常的做法是在列表中具有递减值：下一个值小于或等于之前的值。
embedding_dimension
# 此参数定义模型内部使用的嵌入层的输出维度（默认值：20）。我们在模型架构中使用了多个嵌入层。例如，完整话语和意图的向量在比较之前传递到嵌入层并计算损失。
number_of_transformer_layers
# 此参数设置要使用的转换器层数（默认值：2）。变换器层数对应于模型使用的变换器块。
transformer_size
# 此参数设置变换器中的单元数（默认值：256）。来自转换器的向量将具有给定的转换器大小。
weight_sparsity
# 此参数定义内核的分数 模型中所有前馈层的权重设置为 0（默认值：0.8）。该值应介于 0 和 1 之间。如果将 weight_sparsity 设置为 0，则不会将内核权重设置为 0，该层充当标准前馈层。您不应将 weight_sparsity 设置为 1，因为这将导致所有内核权重为 0，即模型无法学习。
constrain_similarities
# 此参数设置为 True 时会在所有相似项上应用 sigmoid 交叉熵损失。这有助于将输入标签和负标签之间的相似性保持为较小的值。这应该有助于更好地将模型推广到真实世界的测试集。
model_confidence
# 此参数允许用户配置在推理过程中如何计算置信度。它可以取两个值：
# 1. softmax：置信度在 [0, 1] 范围内（旧行为和当前默认值）。计算出的相似性使用 softmax 激活函数进行归一化。
# 2.linear_norm：置信度在 [0, 1] 范围内。计算 点积相似度使用线性函数进行归一化。
# 请尝试使用 linear_norm 作为 model_confidence 的值。这应该更容易调整 FallbackClassifier 的回退阈值。 
```

上述配置参数是您应该配置的参数，以使您的模型适合您的数据。但是，存在可以调整的附加参数。

- 回退

摘要：如果 NLU 意图分类分数不明确，则使用意图 `nlu_fallback` 对消息进行分类。置信度设置为与`fallback threshold`相同。

输出: `entities,intent,intent_ranking`

依赖: 来自先前意图分类器的输出`inteent,intent_ranking`

输出实例

```json

    {
        "intent": {"name": "nlu_fallback", "confidence": 0.7183846840434321},
        "intent_ranking": [
            {
                "confidence": 0.7183846840434321,
                "name": "nlu_fallback"
            },
            {
                "confidence": 0.28161531595656784,
                "name": "restaurant_search"
            }
        ],
        "entities": [{
            "end": 53,
            "entity": "time",
            "start": 48,
            "value": "2017-04-10T00:00:00.000+02:00",
            "confidence": 1.0,
            "extractor": "DIETClassifier"
        }]
    }
```

**描述**

FallbackClassifier 使用意图 nlu_fallback 对用户消息进行分类，以防先前的意图分类器无法对置信度大于或等于 FallbackClassifier 阈值的意图进行分类。它还可以在排名靠前的两个意图的置信度分数接近于 ambiguity_threshold 的情况下预测回退意图。

您可以使用 FallbackClassifier 来实现处理具有不确定 NLU 预测的消息的 Fallback Action。

```yml
rules:

- rule: Ask the user to rephrase in case of low NLU confidence
  steps:
  - intent: nlu_fallback
  - action: utter_please_rephrase
```

**配置**

FallbackClassifier 将仅添加其对 `nlu_fallback` 意图的预测，以防没有其他意图被预测为置信度大于或等于阈值。

```python
threshold
# 此参数设置用于预测 nlu_fallback 意图的阈值。如果先前的意图分类器预测的意图没有大于或等于阈值的置信度，则 FallbackClassifier 将添加置信度为 1.0 的 nlu_fallback 意图的预测。
ambiguity_threshold
# 如果您配置了 ambiguity_threshold，则 FallbackClassifier 还将预测 nlu_fallback 意图如果两个排名最高的意图的置信度分数的差异小于 ambiguity_threshold。
```

### 实体提取

实体提取器从用户消息中提取实体，例如人名或位置。

> 注意
>
> 如果您使用多个实体提取器，我们建议每个提取器都针对一组专有的实体类型。例如，使用 Duckling 提取日期和时间，使用 DIETClassifier 提取人名。否则，如果多个提取器针对相同的实体类型，很可能会多次提取实体。
>
> 例如，如果您使用两个或多个通用提取器，如 MitieEntityExtractor、DIETClassifier 或 CRFEntityExtractor，则训练数据中的实体类型将被所有人找到并提取。如果您使用实体类型填充的插槽是文本类型，则管道中的最后一个提取器将获胜。如果插槽是列表类型，则所有结果都将添加到列表中，包括重复项。
>
> 即使提取器专注于不同的实体类型，也可能发生重复/重叠提取的另一个不太明显的情况。想象一个送餐机器人和一条用户消息，比如我想订购周一特价菜。假设， 如果你的时间提取器的性能不是很好，它可能会在这里提取星期一作为订单的时间，而你的另一个提取器可能会提取星期一的特价作为餐点。如果您遇到此类重叠的实体，添加额外的训练数据以改进您的提取器可能是有意义的。如果这还不够，您可以添加一个自定义组件，根据您自己的逻辑解决实体提取中的冲突。 

- Mitie

摘要：MITIE 实体提取（使用 MITIE NER 训练器）

输出: `entities`

依赖: `MitieNLP`和`tokens`

输出实例

```json
{
    "entities": [{
        "value": "New York City",
        "start": 20,
        "end": 33,
        "confidence": null,
        "entity": "city",
        "extractor": "MitieEntityExtractor"
    }]
}
```

**描述**

MitieEntityExtractor 使用 MITIE 实体提取来查找消息中的实体。底层分类器使用具有稀疏线性内核和自定义特征的多类线性 SVM。 MITIE 组件不提供实体置信度值。

> 注意
>
> 该实体提取器不依赖任何特征化器，因为它自己提取特征。

**配置**

```yml
pipeline:
- name: "MitieEntityExtractor"
```

- Spacy

摘要：spaCy实体抽取

输出: `entities`

依赖: `SpacyNLP`

输出实例

```json
{
    "entities": [{
        "value": "New York City",
        "start": 20,
        "end": 33,
        "confidence": null,
        "entity": "city",
        "extractor": "SpacyEntityExtractor"
    }]
}
```

**描述**

该组件使用 spaCy 预测消息的实体。 spaCy 使用统计 BILOU 转换模型。截至目前，该组件只能使用 spaCy 内置的实体提取模型，不能重新训练。此提取器不提供任何置信度分数。您可以在此交互式演示中测试 spaCy 的实体提取模型。请注意，某些 spaCy 模型高度区分大小写。

> 注意
>
> SpacyEntityExtractor 提取器不提供置信度并且将始终返回 null。

**配置**

配置 spaCy 组件应该提取的维度，即实体类型。可以在 spaCy 文档中找到可用维度的完整列表。未指定维度选项将提取所有可用维度。

```yml
pipeline:
- name: "SpacyEntityExtractor"
  # dimensions to extract
  dimensions: ["PERSON", "LOC", "ORG", "PRODUCT"]
```

- CRF

摘要：条件随机场 (CRF) 实体提取

输出: `entities`

依赖: `tokens` 和`dense_features` (可选)

输出实例

```json
{
    "entities": [{
        "value": "New York City",
        "start": 20,
        "end": 33,
        "entity": "city",
        "confidence": 0.874,
        "extractor": "CRFEntityExtractor"
    }]
}
```

**描述**

该组件实现了一个条件随机字段 (CRF) 来进行命名实体识别。 CRF 可以被认为是一个无向马尔可夫链，其中时间步长是单词，状态是实体类。单词的特征（大写、POS 标记等）给出了某些实体类的概率，相邻实体标签之间的转换也是如此：然后计算并返回最可能的标签集。

如果您想将自定义特征（例如预训练的词嵌入）传递给 CRFEntityExtractor，您可以在 CRFEntityExtractor 之前将任何密集特征化器添加到管道中。 CRFEntityExtractor 自动查找额外的密集特征并检查密集特征是否是 len(tokens) 的可迭代项，其中每个条目都是一个向量。如果检查失败，将显示警告。但是，CRFEntityExtractor 将继续训练，而无需额外的自定义功能。如果存在密集特征，CRFEntityExtractor 会将密集特征传递给 sklearn_crfsuite 并使用它们进行训练。

**配置**

CRFEntityExtractor 有一个要使用的默认功能列表。但是，您可以覆盖默认配置。可以使用以下功能：

```
==============  ==========================================================================================
Feature Name    Description
==============  ==========================================================================================
low             Checks if the token is lower case.
upper           Checks if the token is upper case.
title           Checks if the token starts with an uppercase character and all remaining characters are
                lowercased.
digit           Checks if the token contains just digits.
prefix5         Take the first five characters of the token.
prefix2         Take the first two characters of the token.
suffix5         Take the last five characters of the token.
suffix3         Take the last three characters of the token.
suffix2         Take the last two characters of the token.
suffix1         Take the last character of the token.
pos             Take the Part-of-Speech tag of the token (``SpacyTokenizer`` required).
pos2            Take the first two characters of the Part-of-Speech tag of the token
                (``SpacyTokenizer`` required).
pattern         Take the patterns defined by ``RegexFeaturizer``.
bias            Add an additional "bias" feature to the list of features.
==============  ==========================================================================================
```

当特征化器在带有滑动窗口的用户消息中的标记上移动时，您可以在滑动窗口中定义先前标记、当前标记和下一个标记的特征。您将特征定义为 [before, token, after] 数组。另外，您可以设置一个标志来确定是否使用 BILOU 标记模式。

BILOU_flag 决定是否使用 BILOU 标记。默认`true`。

```yml
pipeline:
- name: "CRFEntityExtractor"
  # BILOU_flag determines whether to use BILOU tagging or not.
  "BILOU_flag": True
  # features to extract in the sliding window
  "features": [
    ["low", "title", "upper"],
    [
      "bias",
      "low",
      "prefix5",
      "prefix2",
      "suffix5",
      "suffix3",
      "suffix2",
      "upper",
      "title",
      "digit",
      "pattern",
    ],
    ["low", "title", "upper"],
  ]
  # The maximum number of iterations for optimization algorithms.
  "max_iterations": 50
  # weight of the L1 regularization
  "L1_c": 0.1
  # weight of the L2 regularization
  "L2_c": 0.1
  # Name of dense featurizers to use.
  # If list is empty all available dense features are used.
  "featurizers": []
  # Indicated whether a list of extracted entities should be split into individual entities for a given entity type
  "split_entities_by_comma":
      address: False
      email: True
```

> 注意
>
> 如果使用 POS 功能（pos 或 pos2），您需要在管道中安装 SpacyTokenizer。
>
> 如果使用模式特征，则需要在管道中使用 RegexFeaturizer。

- Duckling

摘要：Duckling 可让您以多种语言提取常见实体，例如日期、金额、距离等。

输出: `entities`

依赖: Nothing

输出实例

```json
{
    "entities": [{
        "end": 53,
        "entity": "time",
        "start": 48,
        "value": "2017-04-10T00:00:00.000+02:00",
        "confidence": 1.0,
        "extractor": "DucklingEntityExtractor"
    }]
}
```

**描述**

要使用这个组件，您需要运行一个小鸭服务器。最简单的选择是使用 `docker run -p 8000:8000 rasa/duckling` 启动 docker 容器。

或者，您可以直接在您的机器上安装小鸭并启动服务器。

Duckling允许识别日期、数字、距离和其他结构化实体并将它们标准化。请注意，duckling 会尝试在不提供排名的情况下提取尽可能多的实体类型。例如，如果您将数字和时间都指定为小鸭组件的维度，则该组件将提取两个实体：10 作为数字和在 10 分钟内作为时间，来自文本` I will be there in 10 minutes`。在这种情况下，您的应用程序必须决定哪种实体类型是正确的。提取器将始终返回 1.0 作为置信度，因为它是基于规则的系统。

支持的语言列表可以在 Duckling GitHub 存储库中找到。

**配置**

配置duckling组件应该提取哪些维度，即实体类型。可以在duckling文档中找到可用尺寸的完整列表。未指定维度选项将提取所有可用维度。

```yml
pipeline:
- name: "DucklingEntityExtractor"
  # url of the running duckling server
  url: "http://localhost:8000"
  # dimensions to extract
  dimensions: ["time", "number", "amount-of-money", "distance"]
  # allows you to configure the locale, by default the language is
  # used
  locale: "de_DE"
  # if not set the default timezone of Duckling is going to be used
  # needed to calculate dates from relative expressions like "tomorrow"
  timezone: "Europe/Berlin"
  # Timeout for receiving response from http url of the running duckling server
  # if not set the default timeout of duckling http url is set to 3 seconds.
  timeout : 3
```

- DIET

摘要：Dual Intent Entity Transformer (DIET) 用于意图分类和实体提取

**描述**

您可以在 Intent Classifiers 部分找到 DIETClassifier 的详细说明。

- 正则

摘要：使用在训练数据中定义的查找表和/或正则表达式提取实体

输出: `entities`

依赖: Nothing

**描述**

该组件使用训练数据中定义的查找表和正则表达式提取实体。该组件检查用户消息是否包含查找表之一的条目或匹配正则表达式之一。如果找到匹配项，则将该值提取为实体。

此组件仅使用名称等于训练数据中定义的实体之一的那些正则表达式特征。确保为每个实体至少注释一个示例。

**配置**

通过添加 `case_sensitive: True` 选项使实体提取器区分大小写，默认为 `case_sensitive: False`。

要正确处理不使用空格进行分词的中文等语言，用户需要添加` use_word_boundaries: False` 选项，即默认为 `use_word_boundaries: True`。

```yml
    pipeline:
    - name: RegexEntityExtractor
      # text will be processed with case insensitive as default
      case_sensitive: False
      # use lookup tables to extract entities
      use_lookup_tables: True
      # use regexes to extract entities
      use_regexes: True
      # use match word boundaries for lookup table
      "use_word_boundaries": True
```

- 实体同义词映射

摘要：将同义实体值映射到相同的值。

输出: 修改先前实体提取组件找到的现有实体。

依赖: 实体提取器的提取器

**描述**

如果训练数据包含定义的同义词，该组件将确保检测到的实体值将映射到相同的值。例如，如果您的训练数据包含以下示例：

```json
[
    {
      "text": "I moved to New York City",
      "intent": "inform_relocation",
      "entities": [{
        "value": "nyc",
        "start": 11,
        "end": 24,
        "entity": "city",
      }]
    },
    {
      "text": "I got a new flat in NYC.",
      "intent": "inform_relocation",
      "entities": [{
        "value": "nyc",
        "start": 20,
        "end": 23,
        "entity": "city",
      }]
    }
]
```

该组件将允许您将实体 New York City 和 NYC 映射到 nyc。即使消息包含 NYC，实体提取也会返回 nyc。当此组件更改现有实体时，它会将自身附加到此实体的处理器列表中。

**配置**

```yml
pipeline:
- name: "EntitySynonymMapper"
```

> 注意
>
> 当使用 EntitySynonymMapper 作为 NLU 管道的一部分时，需要将其放置在配置文件中的任何实体提取器下方。

### 选择器

选择器从一组候选响应中预测机器人响应。

- Response

摘要：响应选择器

输出: 一个字典，键作为响应选择器的检索意图，值包含预测的响应、置信度和检索意图下的响应键

依赖: 用于用户消息和响应的 dense_features 和/或 sparse_features

**输出实例**

NLU 的解析输出将具有一个名为 `response_selector` 的属性，其中包含每个响应选择器组件的输出。每个响应选择器由该响应选择器的检索意图参数标识并存储两个属性：

```python
response
# 对应检索意图下的预测响应key，预测的置信度和相关响应。
ranking
# 排名前10个候选响应key的置信度。
```

实例

```json
{
    "response_selector": {
      "faq": {
        "response": {
          "id": 1388783286124361986,
          "confidence": 0.7,
          "intent_response_key": "chitchat/ask_weather",
          "responses": [
            {
              "text": "It's sunny in Berlin today",
              "image": "https://i.imgur.com/nGF1K8f.jpg"
            },
            {
              "text": "I think it's about to rain."
            }
          ],
          "utter_action": "utter_chitchat/ask_weather"
         },
        "ranking": [
          {
            "id": 1388783286124361986,
            "confidence": 0.7,
            "intent_response_key": "chitchat/ask_weather"
          },
          {
            "id": 1388783286124361986,
            "confidence": 0.3,
            "intent_response_key": "chitchat/ask_name"
          }
        ]
      }
    }
}
```

如果特定响应选择器的检索意图参数保留为其默认值，则相应的响应选择器将在返回的输出中被标识为默认值。

```json
{
    "response_selector": {
      "default": {
        "response": {
          "id": 1388783286124361986,
          "confidence": 0.7,
          "intent_response_key": "chitchat/ask_weather",
          "responses": [
            {
              "text": "It's sunny in Berlin today",
              "image": "https://i.imgur.com/nGF1K8f.jpg"
            },
            {
              "text": "I think it's about to rain."
            }
          ],
          "utter_action": "utter_chitchat/ask_weather"
         },
        "ranking": [
          {
            "id": 1388783286124361986,
            "confidence": 0.7,
            "intent_response_key": "chitchat/ask_weather"
          },
          {
            "id": 1388783286124361986,
            "confidence": 0.3,
            "intent_response_key": "chitchat/ask_name"
          }
        ]
      }
    }
}
```

**描述**

响应选择器组件可用于构建响应检索模型，以直接从一组候选响应中预测机器人响应。对话管理器使用该模型的预测来发出预测的响应。它将用户输入和响应标签嵌入到同一空间中，并遵循与 DIETClassifier 完全相同的神经网络架构和优化。

要使用此组件，您的训练数据应包含检索意图。要定义这些，请查看有关 NLU 训练示例的文档和有关为检索意图定义响应话语的文档。

> 注意
>
> 如果在预测期间，一条消息仅包含训练期间未见过的单词，并且没有使用 Out-Of-Vocabulary 预处理器，则以 0.0 的置信度预测空响应 None。如果您仅将 CountVectorsFeaturizer 与单词分析器一起用作特征化器，则可能会发生这种情况。如果您使用 char_wb 分析器，您应该始终得到置信度值 > 0.0 的响应。

**配置**

该算法几乎包括了 DIETClassifier 使用的所有超参数。如果要调整模型，请首先修改以下参数：

```python
epochs
# 此参数设置算法将看到训练数据的次数（默认值：300）。一个 epoch 等于所有训练示例的一次前向传递和一次反向传递。有时模型需要更多的 epoch 才能正确学习。有时更多的时期不会影响性能。 epoch 数越少，模型训练的速度越快。
hidden_layers_sizes
# 此参数允许您定义前馈层数及其用户消息和意图的输出维度（默认值：text:[256, 128]，label:[256, 128]）。列表中的每个条目都对应一个前馈层。比如你设置 text:[256, 128]，我们会在transformer前面添加两个前馈层。输入标记的向量（来自用户消息）将被传递到这些层。第一层的输出维度为 256，第二层的输出维度为 128。如果使用空列表（默认行为），则没有提要 将添加转发层。确保仅使用正整数值。通常，使用 2 的幂数。此外，通常的做法是在列表中具有递减值：下一个值小于或等于之前的值。
embedding_dimension
# 此参数定义模型内部使用的嵌入层的输出维度（默认值：20）。我们在模型架构中使用了多个嵌入层。例如，完整话语和意图的向量在进行比较之前被传递到嵌入层并计算损失。
number_of_transformer_layers
# 此参数设置要使用的转换器层数（默认值：0）。转换器层数对应于模型使用的转换器块。
transformer_size
# 此参数设置转换器中的单元数（默认值：无）。来自转换器的向量将具有给定的转换器大小。
weight_sparsity
# 此参数定义 模型中所有前馈层设置为 0 的内核权重分数（默认值：0.8）。该值应介于 0 和 1 之间。如果将 weight_sparsity 设置为 0，则不会将内核权重设置为 0，该层充当标准前馈层。您不应将 weight_sparsity 设置为 1，因为这将导致所有内核权重为 0，即模型无法学习。
constrain_similarities
# 此参数设置为 True 时会在所有相似项上应用 sigmoid 交叉熵损失。这有助于将输入标签和负标签之间的相似性保持为较小的值。这应该有助于更好地将模型推广到真实世界的测试集。
model_confidence
# 此参数允许用户配置在推理过程中如何计算置信度。它可以取两个值：•softmax：置信度在 [0, 1] 范围内（旧行为和当前默认值）。使用 softmax 激活函数对计算的相似性进行归一化。
linear_norm
# 置信度在范围内 [0, 1]。计算的点积相似度使用线性函数进行归一化。
# 请尝试使用 linear_norm 作为 model_confidence 的值。这应该更容易调整 FallbackClassifier 的回退阈值。 
```

该组件还可以配置为针对特定检索意图训练响应选择器。参数retrieval_intent 设置了训练此响应选择器模型的检索意图的名称。默认为无，即模型针对所有检索意图进行训练。

在其默认配置中，组件使用带有响应键（例如 faq/ask_name）的检索意图作为训练标签。或者，也可以通过将 use_text_as_label 切换为 True 来将其配置为使用响应的文本作为训练标签。在这种模式下，组件将使用具有文本属性的第一个可用响应进行训练。如果没有找到，则回退到使用检索意图和响应键作为标签。

上述配置参数是您应该配置的参数，以使您的模型适合您的数据。但是，存在可以调整的附加参数。

### 自定义组件

您可以创建一个自定义组件来执行 NLU 目前不提供的特定任务（例如，情绪分析）。下面是 `rasa.nlu.components.Component`类的规范以及您需要实现的方法。

您可以通过添加模块路径将自定义组件添加到管道中。因此，如果您有一个名为 `SentimentAnalyzer` 类的名为 `SentimentAnalyzer` 的模块：

```yml
pipeline:
- name: "sentiment.SentimentAnalyzer"
```

还请务必阅读有关组件生命周期的部分。

要开始使用，您可以使用这个框架，其中包含您应该实现的最重要的方法：

```yml
import typing
from typing import Any, Optional, Text, Dict, List, Type

from rasa.nlu.components import Component
from rasa.nlu.config import RasaNLUModelConfig
from rasa.shared.nlu.training_data.training_data import TrainingData
from rasa.shared.nlu.training_data.message import Message

if typing.TYPE_CHECKING:
    from rasa.nlu.model import Metadata


class MyComponent(Component):
    """A new component"""

    # Which components are required by this component.
    # Listed components should appear before the component itself in the pipeline.
    @classmethod
    def required_components(cls) -> List[Type[Component]]:
        """Specify which components need to be present in the pipeline."""

        return []

    # Defines the default configuration parameters of a component
    # these values can be overwritten in the pipeline configuration
    # of the model. The component should choose sensible defaults
    # and should be able to create reasonable results with the defaults.
    defaults = {}

    # Defines what language(s) this component can handle.
    # This attribute is designed for instance method: `can_handle_language`.
    # Default value is None which means it can handle all languages.
    # This is an important feature for backwards compatibility of components.
    supported_language_list = None

    # Defines what language(s) this component can NOT handle.
    # This attribute is designed for instance method: `can_handle_language`.
    # Default value is None which means it can handle all languages.
    # This is an important feature for backwards compatibility of components.
    not_supported_language_list = None

    def __init__(self, component_config: Optional[Dict[Text, Any]] = None) -> None:
        super().__init__(component_config)

    def train(
        self,
        training_data: TrainingData,
        config: Optional[RasaNLUModelConfig] = None,
        **kwargs: Any,
    ) -> None:
        """Train this component.

        This is the components chance to train itself provided
        with the training data. The component can rely on
        any context attribute to be present, that gets created
        by a call to :meth:`components.Component.pipeline_init`
        of ANY component and
        on any context attributes created by a call to
        :meth:`components.Component.train`
        of components previous to this one."""
        pass

    def process(self, message: Message, **kwargs: Any) -> None:
        """Process an incoming message.

        This is the components chance to process an incoming
        message. The component can rely on
        any context attribute to be present, that gets created
        by a call to :meth:`components.Component.pipeline_init`
        of ANY component and
        on any context attributes created by a call to
        :meth:`components.Component.process`
        of components previous to this one."""
        pass

    def persist(self, file_name: Text, model_dir: Text) -> Optional[Dict[Text, Any]]:
        """Persist this component to disk for future loading."""

        pass

    @classmethod
    def load(
        cls,
        meta: Dict[Text, Any],
        model_dir: Text,
        model_metadata: Optional["Metadata"] = None,
        cached_component: Optional["Component"] = None,
        **kwargs: Any,
    ) -> "Component":
        """Load this component from file."""

        if cached_component:
            return cached_component
        else:
            return cls(meta)

```

当您在训练数据中为意图示例定义元数据时，您的组件可以在处理期间访问意图元数据和意图示例元数据：

```python
# in your component class

    def process(self, message: Message, **kwargs: Any) -> None:
        metadata = message.get("metadata")
        print(metadata.get("intent"))
        print(metadata.get("example"))
```

> 自定义分词
>
> 如果您创建自定义标记器，您应该实现 rasa.nlu.tokenizers.tokenizer.Tokenizer 的方法。 train 和 process 方法已经实现，您只需要覆盖 tokenize 方法。
>
> 自定义特征化
>
> 如果您创建自定义特征化器，您可以返回两种不同的特征：序列特征和句子特征。序列特征是一个大小矩阵（`number-of-tokens X feeature-dimension`），例如该矩阵包含序列中每个标记的特征向量。句子特征由大小矩阵（`1 X feature-dimension`）表示。

## 策略

您的助手使用策略来决定在对话的每个步骤中要执行的操作。您的助手可以同时使用机器学习和基于规则的策略。

您可以通过在项目的 config.yml 中指定策略键来自定义助手使用的策略。有不同的策略可供选择，您可以在单个配置中包含多个策略。以下是策略列表的示例：

`config.yml`

```yml
language:  # your language
pipeline:
  # - <pipeline components>

policies:
  - name: MemoizationPolicy
  - name: TEDPolicy
    max_history: 5
    epochs: 200
  - name: RulePolicy
```

### 动作选择

在每一个转折点，您的配置中定义的每个策略都会以一定的置信度预测下一个动作。有关每项政策如何做出决定的更多信息，请阅读下面的政策说明。以最高置信度进行预测的策略决定了助手的下一步行动。

> 最大预测次数
>
> 默认情况下，您的助手最多可以预测每条用户消息后的 10 个下一步操作。要更新此值，您可以将环境变量 MAX_NUMBER_OF_PREDICTIONS 设置为所需的最大预测数。

- 策略优先

如果两个策略以相同的置信度进行预测（例如，记忆策略和规则策略可能都以置信度 1 进行预测），则考虑策略的优先级。 Rasa 开源政策具有默认优先级，这些优先级已设置为确保在出现平局的情况下获得预期结果。它们看起来像这样，数字越大优先级越高：

```
6 - RulePolicy
3 - MemoizationPolicy or AugmentedMemoizationPolicy
2 - UnexpecTEDIntentPolicy
1 - TEDPolicy
```

通常，不建议在您的配置中为每个优先级设置多个策略。如果您有 2 个具有相同优先级的策略并且它们以相同的置信度进行预测，则将随机选择生成的操作。

如果您创建自己的策略，请使用这些优先级作为确定策略优先级的指南。如果您的策略是机器学习策略，它很可能具有优先级 1，与 TEDPolicy 相同。

### 机器学习策略

- TED策略

Transformer 嵌入对话 (TED) 策略是一种用于下一步动作预测和实体识别的多任务架构。该架构由两个任务共享的几个转换器编码器组成。通过在用户序列转换器编码器输出之上的条件随机场 (CRF) 标记层预测实体标签序列，该输出对应于输入的令牌序列。对于下一个动作预测，对话转换器编码器输出和系统动作标签被嵌入到单个语义向量空间中。我们使用点积损失来最大化与目标标签的相似性并最小化与负样本的相似性。

如果您想了解有关该模型的更多信息，请查看我们的论文和我们的 youtube 频道。我们在这里详细解释了模型架构。

TED 策略架构包括以下步骤：

1. 连接特征： a. 用户输入（用户意图和实体）或通过用户序列转换器编码器处理的用户文本，b.先前系统操作或通过机器人序列转换器编码器处理的机器人话语，c.槽和活动表单。对于每个时间步，进入对话转换器之前的嵌入层的输入向量。
2. 将输入向量的嵌入馈送到对话转换器编码器中。
3. 将密集层应用于对话转换器的输出，以获得每个时间步的对话嵌入。
4. 应用密集层为每个时间步的系统动作创建嵌入。
5. 计算对话嵌入和嵌入式系统动作之间的相似性。此步骤基于 StarSpace 的思想。
6. 将用户序列转换器编码器的令牌级输出与对话转换器编码器的每个时间步的输出连接起来.
7. 应用 CRF 算法预测每个用户文本输入的上下文实体.

**配置**

您可以使用 config.yml 文件将配置参数传递给 TEDPolicy。如果要微调模型，请首先修改以下参数：

`epochs`

此参数设置算法将看到训练数据的次数（默认值：1）。一个 epoch 等于所有训练示例的一次前向传递和一次反向传递。有时模型需要更多的 epoch 才能正确学习。有时更多的时期不会影响性能。时期数越少，模型训练得越快。这是配置的样子：

```yml
`config.yml`
policies:
- name: TEDPolicy
  epochs: 200
```

`max_history`

此参数控制模型查看多少对话历史来决定下一步要采取的行动。此策略的默认 max_history 为 None，这意味着自会话重新启动以来的完整对话历史记录被考虑在内。如果你想限制模型只能看到一定数量的先前对话轮次，你可以将 max_history 设置为一个有限值。请注意，您应该仔细选择 max_history，以便模型有足够的先前对话轮次来创建正确的预测。有关更多详细信息，请参阅特征化器。这是配置的样子

```yml
`config.yml`
policies:
- name: TEDPolicy
  max_history: 8
```

`number_of_transformer_layers`

此参数设置序列转换器编码器层的数量，用于用户、动作和动作标签文本的序列转换器编码器以及对话转换器编码器。 （默认值：`text:1，action_text:1，label_action_text:1，dialogue:1`）。序列转换器编码器层的数量对应于用于模型的转换器块。

`transformer_size`



`weight_sparsity`



`split_entities_by_comma`



`constrain_similarities`



`model_confidence`

- 意外意图策略

- 内存策略
- 增强记忆策略

### 基于规则策略

### 配置策略

- 最大历史
- 数据增强
- 特征化

### 自定义策略

您还可以编写自定义策略并在配置中引用它们。在下面的示例中，最后两行显示了如何使用自定义策略类并将参数传递给它。

```yml
policies:
  - name: "TEDPolicy"
    max_history: 5
    epochs: 200
  - name: "RulePolicy"
  - name: "path.to.your.policy.class"
    arg1: "..."
```

## 导入

### Rasa文件导入

### 多项目导入

### 自定义导入



## 语言支持

### 任意语言下训练模型

### 使用预训练语言模型



