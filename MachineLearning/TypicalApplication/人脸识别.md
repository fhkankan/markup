# 人脸识别

## SVM

```python
import numpy as np
import pandas as pd
import matplotlib as mpl
import seaborn as sns
import time
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

faces = fetch_lfw_people(min_faces_per_person=60)
print(faces.target_names)
# ['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'
#  'Gerhard Schroeder' 'Hugo Chavez' 'Junichiro Koizumi' 'Tony Blair']
print(faces.images.shape)
# (1348, 62, 47)

# 画一些人脸，查看需要处理的数据
# fig, ax = plt.subplots(3, 5)
# for i, axi in enumerate(ax.flat):
#     axi.imshow(faces.images[i], cmap='bone')
#     axi.set(xticks=[], yticks=[], xlabel=faces.target_names[faces.target[i]])
# plt.show()

# 主成分分析提取150个基本元素，而不是使用每个像素作为特征
pca = PCA(n_components=150, whiten=True, random_state=42)
svc = SVC(kernel='rbf', class_weight='balanced')
model = make_pipeline(pca, svc)

# 数据集分离
Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)
# 网格搜索寻找超参数最优值
param_grid = {
    "svc__C": [ 1, 5, 10, 50],
    "svc__gamma": [0.0001, 0.0005, 0.001, 0.005]
}
grid = GridSearchCV(model, param_grid)

now = time.process_time()
grid.fit(Xtrain, ytrain)
print(time.process_time() - now)  # 138.956965
print(grid.best_params_)  # {'svc__C': 10, 'svc__gamma': 0.001}
# 最优参数是在网格的中间位置，若是在边缘位置，需要扩展网格搜索范围

# 对测试集进行预测
model = grid.best_estimator_
yfit = model.predict(Xtest)

# 对比测试结果
# fig, ax = plt.subplots(4, 6)
# for i, axi in enumerate(ax.flat):
#     axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')
#     axi.set(xticks=[], yticks=[])
#     axi.set_ylabel(faces.target_names[yfit[i]].split()[-1], color='black' if yfit[i] == ytest[i] else 'red')
# fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)
# plt.show()

# 分类效果报告
res = classification_report(ytest, yfit, target_names=faces.target_names)
print(res)
"""
                   precision    recall  f1-score   support

     Ariel Sharon       0.65      0.73      0.69        15
     Colin Powell       0.80      0.87      0.83        68
  Donald Rumsfeld       0.74      0.84      0.79        31
    George W Bush       0.92      0.83      0.88       126
Gerhard Schroeder       0.86      0.83      0.84        23
      Hugo Chavez       0.93      0.70      0.80        20
Junichiro Koizumi       0.92      1.00      0.96        12
       Tony Blair       0.85      0.95      0.90        42

         accuracy                           0.85       337
        macro avg       0.83      0.84      0.84       337
     weighted avg       0.86      0.85      0.85       337
"""
# 混淆矩阵展示结果
mat = confusion_matrix(ytest, yfit)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
            xticklabels=faces.target_names, yticklabels=faces.target_names)
plt.xlabel('true label')
plt.ylabel('predicted label')
plt.show()
```

## Isomap

```python
import numpy as np
from matplotlib import offsetbox
import matplotlib.pyplot as plt
from matplotlib.image import imread
import seaborn as sns
from sklearn.datasets import fetch_lfw_people
from sklearn.decomposition import PCA
from sklearn.manifold import MDS, LocallyLinearEmbedding, Isomap, TSNE

faces = fetch_lfw_people(min_faces_per_person=30)
# print(faces.data.shape, faces.images.shape)
"""
(2370, 2914) (2370, 62, 47)
"""


# 有2370幅图像，每个图像有2914=62*47像素

# 快速可视化
# fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))
# for i, axi in enumerate(ax.flat):
#     axi.imshow(faces.images[i], cmap='gray')
# plt.show()

# PCA
# 判断主成分个数
# model = PCA(n_components=100, svd_solver='randomized').fit(faces.data)
# plt.plot(np.cumsum(model.explained_variance_ratio_))
# plt.xlabel(' n components')
# plt.ylabel('cumulative variable')
# plt.show()
# 通过累积方差图，知需要约100个成分才能保存90%的方差，说明数据所需的维度非常高，仅通过几个线性成分无法描述

# 采用非线性流形嵌入法Isomap
# model = Isomap(n_components=2)
# proj = model.fit_transform(faces.data)  # 输出对所有图像的一个二维投影
# print(proj.shape)  # (2370, 2)


# 在不同的投影位置输出图像的缩略图
def plot_components(data, model, images=None, ax=None, thumb_frac=0.05, cmap='gray'):
    ax = ax or plt.gca()
    proj = model.fit_transform(data)
    ax.plot(proj[:, 0], proj[:, 1], '.k')

    if images is not None:
        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2
        shown_images = np.array([2 * proj.max(0)])
        for i in range(data.shape[0]):
            dist = np.sum((proj[i] - shown_images) ** 2, 1)
            if np.min(dist) < min_dist_2:
                # 不展示相距很近的点
                continue
            shown_images = np.vstack([shown_images, proj[i]])
            imagebox = offsetbox.AnnotationBbox(offsetbox.OffsetImage(images[i], cmap=cmap), proj[i])
            ax.add_artist(imagebox)


fig, ax = plt.subplots(figsize=(10, 10))
plot_components(faces.data, model=Isomap(n_components=2), images=faces.images[:, ::2, ::2])
plt.show()
# 描述了图像的整体特征：图像明暗度从左至右持续斌华，人脸朝向从下到上持续变化。
# 可以根据这个结果将数据进行分类，用流形特征作为分类算法的输入数据
```

## 人脸识别管道

- HOG特征

一种图像体征提取技术-方向提督直方图(HOG)，它可以将图像鲜素转换成向量形式，与图像具体内容有关，与图像合成因素无关，如照度等。

HOG方法包含以下步骤

```
1.图像标准化(可选)，消除照度对图像的影响。
2.用与水平和垂直方向的亮度梯度相关的两个过滤器处理图像，捕捉图像的边、角和纹理信息。
3.将图像切割成预定义大小的图块，然后计算每个图块内梯度方向的频次直方图。
4.对比每个图块与相邻图块的频次直方图，并做标准化处理，进一步消除照度对图像的影响
5.获得描述的每个图块信息的一维特征向量
```

`scikit-image`中内置了一个快速HOG提取器，可以快速获取并可视化每个图块的方向梯度

```python
import numpy as np
import matplotlib.pyplot as plt
from skimage import data, color, feature

image = color.rgb2gray(data.chelsea())
hog_vec, hog_vis = feature.hog(image, visualize=True)

fig, ax = plt.subplots(1, 2, figsize=(12, 6), subplot_kw=dict(xticks=[], yticks=[]))
ax[0].imshow(image, cmap='gray')
ax[0].set_title('input image')

ax[1].imshow(hog_vis)
ax[1].set_title('visualization of HOG features')
plt.show()

```

- 简单人脸识别器

有了图像的HOG特征，可以用sklearn的任意评估器建立一个简单人来呢识别算法，如使用线性支持向量机。具体步骤如下

```
1.获取一组人脸图像缩略图，构建正(positive)训练样本
2.获取另一组人脸图像缩略图，构建负(negative)训练样本
3.提取训练样本的HOG特征
4.对样本训练一个线性SVM模型
5.对未知图像传递一个移动的窗口，用模型评估窗口的内容是否是人脸
6.如果发现和已知图像重叠，就将它们组合成一个窗口
```

示例

```python
import numpy as np
import matplotlib.pyplot as plt
from skimage import data, color, transform, feature
from sklearn.datasets import fetch_lfw_people
from sklearn.feature_extraction.image import PatchExtractor
from itertools import chain
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.svm import LinearSVC

# 1.获取一组正训练样本
faces = fetch_lfw_people()
positive_patches = faces.images
print(positive_patches.shape)
# (13233, 62, 47)
# 2.获取一组负训练样本
imgs_to_use = ['camera', 'text', 'coins', 'moon',
               'page', 'clock', 'immunohistochemistry',
               'chelsea', 'coffee', 'hubble_deep_field']
images = [color.rgb2gray(getattr(data, name)())
          for name in imgs_to_use]


def extract_patches(img, N, scale=1.0, patch_size=positive_patches[0].shape):
    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))
    extractor = PatchExtractor(patch_size=extracted_patch_size,
                               max_patches=N, random_state=0)
    patches = extractor.transform(img[np.newaxis])
    if scale != 1:
        patches = np.array([transform.resize(patch, patch_size)
                            for patch in patches])
    return patches


negative_patches = np.vstack([extract_patches(im, 1000, scale)
                              for im in images for scale in [0.5, 1.0, 2.0]])
print(negative_patches.shape)
# (30000, 62, 47)
# 查看图像
# fig, ax = plt.subplots(6, 10)
# for i, axi in enumerate(ax.flat):
#     axi.imshow(negative_patches[500 * i], cmap='gray')
#     axi.axis('off')


# 3.组合数据集并提取HOG特征
X_train = np.array([feature.hog(im)
                    for im in chain(positive_patches,
                                    negative_patches)])
y_train = np.zeros(X_train.shape[0])
y_train[:positive_patches.shape[0]] = 1
print(X_train.shape)
# (43233, 1215)

# 4.训练一个支持向量机
# a.用简单的高斯朴素贝叶斯分类器算一个初始解
res = cross_val_score(GaussianNB(), X_train, y_train)
print(res)
# array([ 0.9408785 ,  0.8752342 ,  0.93976823])
# 可知即使使用简单的朴素贝叶斯算法也可获得90%以上的准确率
# b.使用网格搜索获取支持向量机的最优边界软化参数c
grid = GridSearchCV(LinearSVC(), {'C': [1.0, 2.0, 4.0, 8.0]})
grid.fit(X_train, y_train)
print(grid.best_score_)
print(grid.best_params_)
"""
0.9884578497284486
{'C': 1.0}
"""
# c.用最优评估器重新训练
model = grid.best_estimator_
model.fit(X_train, y_train)

# 5.在新图像中寻找人脸
# a.使用一张宇航员找屁啊你的局部图像，在上面运行一个移动窗口来评估每次移动的结果
test_image = data.astronaut()
test_image = color.rgb2gray(test_image)
test_image = transform.rescale(test_image, 0.5)
test_image = test_image[:160, 40:180]


# plt.imshow(test_image, cmap='gray')
# plt.axis('off');


# 创建一个不断在图像中移动的窗口，然后计算每次移动位置的HOG特征
def sliding_window(img, patch_size=positive_patches[0].shape,
                   istep=2, jstep=2, scale=1.0):
    Ni, Nj = (int(scale * s) for s in patch_size)
    for i in range(0, img.shape[0] - Ni, istep):
        for j in range(0, img.shape[1] - Ni, jstep):
            patch = img[i:i + Ni, j:j + Nj]
            if scale != 1:
                patch = transform.resize(patch, patch_size)
            yield (i, j), patch


indices, patches = zip(*sliding_window(test_image))
patches_hog = np.array([feature.hog(patch) for patch in patches])
print(patches_hog.shape)  # (1911, 1215)
# c.收集这些HOG特征，并用训练好的模型来评估每个窗口中是否有人脸
labels = model.predict(patches_hog)
print(labels.sum())  # 49.0
# 用矩形把收集到的信息画在图像上
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

Ni, Nj = positive_patches[0].shape
indices = np.array(indices)

for i, j in indices[labels == 1]:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=0.3, lw=2, facecolor='none'))
plt.show()

```

注意事项与改进方案

```
1.训练集中的负样本特征并不完整：可以引入更多负训练集图像或使用困难负样本挖掘
2.目前的管道只搜索一个尺寸：可以采用不同尺寸的窗口，每次将图形提供给模型之前，都用skimage.transform.resize重置图像尺寸
3.应该将包含人脸的重叠窗口合并：可以通过一个无监督的聚类方法(Meanshift)或机器视觉常用算法如非极大值抑制来解决
4.管道可以更具流线型：将获取训练图像和预测华东窗口输出功能都封装在管道中
5.应该考虑深度学习等技术
```

