# 自动编码器

> AutoEncoder

自编码器的应用主要有两个方面

- 数据去噪
- 进行可视化而降维

自编码器可以学习到比PCA等技术更好的数据投影

## 原理

- 定义

<img src="images/自动编码器.png" alt="自动编码器" style="zoom:50%;" />

自动编码器是一种数据的压缩算法，一种使用神经网络学习数据值编码的无监督方式。

- 原理

![构建自编码器思路](images/构建自编码器思路.png)

搭建一个自动编码器需要完成下面三样工作：
```
1.搭建编码器
2.搭建解码器
3.设定一个损失函数，用以衡量由于压缩而损失掉的信息。

编码器和解码器一般都是参数化的方程，并关于损失函数可导，通常情况是使用神经网络。
```
编码过程：数据从输入层到隐藏层
$$
h(x) = f(W^Tx + b)
$$
解码过程：从隐藏层到输出层
$$
\hat{x} = f((W^*)^Th(x) + c)
$$
其中， 若$W^T=W^*$，则称为tied weights

- 损失函数

AE训练目标就是使得重构后的数据 $\hat{x}$ 能够尽量还原输入层数据 $x$。由此，得到构建AE的损失函数。

对于二值神经网络，输入层的每个神经元只能取值0或1，那么损失函数由交叉熵来定义
$$
L(W, b, c) = -\sum_{k=1}^n{x_k\log \hat{x_k} + (1-x_k)\log(1-\hat{x_k})}
$$
若输入神经元是一个任意实数，则通常采用均方误差来定义
$$
L(W,b,c)=\frac{1}{2}\sum_{k=1}^n{(x_k-\hat{x_k})^2}
$$

- 类别
```
- 普通自编码器
    编解码网络使用全连接层
- 多层自编码器
- 卷积自编码器
    编解码器使用卷积结构
- 正则化自编码器
    降噪自编码器
```
当隐藏层神经元个数小于输入层神经元个数时，称为undercomplete。改隐藏层设计使得输入层到隐藏层的变换本质上是一种降维的操作。网络试图以更小的维度去描述原始数据而尽量不损失数据信息，从而得到输入层的压缩表示。当隐藏层的激活函数采用线性函数时，自编码器也被称为线性自编码器，其效果等价于主成分分析。

当隐藏层神经元个数大于输入层神经元个数时，称为overcomplete。该隐藏层设计一般用于稀疏编码器，可以获得稀疏的特征表示，也就是隐藏层中有大量的神经元取值为0。

降噪自编码器（Denoising Autoencoder，简称DAE）的损失函数与AE的损失函数时一样的，也就是说DAE输出层仍然是最大限度底还原输入层，而不是经过噪音处理后的噪音层数据。

## 案例

### 普通

```python
from keras.layers import Input, Dense
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 编码器的输入结构
        input_img = Input(shape=(784,))
        # 定义编码器：输出32个神经元，使用relu激活函数，（32这个值可以自己制定）
        encoder = Dense(self.encoding_dim, activation='relu')(input_img)
        # 定义解码器：输出784个神经元，使用sigmoid函数，（784这个值是输出与原图片大小一致）
        decoder = Dense(self.decoding_dim, activation="sigmoid")(encoder)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改，由于全连接层的要求，将数据转换成二维[batch, feature]
        x_train = np.reshape(x_train, (len(x_train), np.prod(x_train.shape[1:])))
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        print(x_train.shape, x_test.shape)
        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 普通自编码器
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```

### 深度

将多个自编码器进行重叠，也叫栈式自编码器（Stacked Autoencoders，简称SAE），也叫堆栈自编码器、堆叠自编码器等。

```python
from keras.layers import Input, Dense
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 深度自编码器
        # 编码器的输入结构
        input_img = Input(shape=(784,))
        # 定义编码器：将多个编码器进行重叠
        encoder = Dense(128, activation='relu')(input_img)
        encoder  = Dense(64, activation='relu')(encoder)
        encoder = Dense(32, activation='relu')(encoder)
        # 定义解码器：将多个解码器进行宠得
        decoder = Dense(64, activation="relu")(encoder)
        decoder = Dense(128, activation="relu")(decoder)
        decoder = Dense(784, activation='sigmoid')(decoder)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改，由于全连接层的要求，将数据转换成二维[batch, feature]
        x_train = np.reshape(x_train, (len(x_train), np.prod(x_train.shape[1:])))
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        print(x_train.shape, x_test.shape)
        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 深度自编码器
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```

### 卷积

```python
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 卷积自编码器
        """
        编码器
            Conv2D(32, (3, 3), activation='relu', padding='same')
            MaxPooling2D((2, 2), padding='same')
            Conv2D(32, (3, 3), activation='relu', padding='same')
            MaxPooling2D((2, 2), padding='same')
            输出大小为:Tensor("max_pooling2d_2/MaxPool:0", shape=(?, 7, 7, 32), dtype=float32)
        解码器:反卷积过程
            Conv2D(32, (3, 3), activation='relu', padding='same')
            UpSampling2D((2, 2))
            Conv2D(32, (3, 3), activation='relu', padding='same')
            UpSampling2D((2, 2))
            Conv2D(1, (3, 3), activation='sigmoid', padding='same')
            输出大小：Tensor("conv2d_5/Sigmoid:0", shape=(?, 28, 28, 1), dtype=float32)
        """
        # 编码器的输入结构
        input_img = Input(shape=(28, 28, 1))
        # 定义编码器
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        encoder = MaxPooling2D((2, 2), padding='same')(x)
        # 定义解码器：将多个解码器进行宠得
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoder)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        decoder = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改
        x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        print(x_train.shape, x_test.shape)
        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 卷积自编码器
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```

### 降噪/正则

```python
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 降噪自编码器
        """
        对原始数据添加噪音,随机加上正态分布的噪音
        x_train + np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
        """
        # 编码器的输入结构
        input_img = Input(shape=(28, 28, 1))
        # 定义编码器
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        encoder = MaxPooling2D((2, 2), padding='same')(x)
        # 定义解码器：将多个解码器进行宠得
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoder)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        decoder = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改
        x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        print(x_train.shape, x_test.shape)
        # 进行躁点数据处理
        x_train_noisy = x_train + np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
        x_test_noisy = x_test + np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)
        # 重新进行限制每个像素值的大小在0~1之间
        x_train_noisy = np.clip(x_train_noisy, 0., 1.)
        x_test_noisy = np.clip(x_test_noisy, 0., 1.)

        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train_noisy, x_train, epochs=5, batch_size=256, shuffle=True,
                       validation_data=(x_test_noisy, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 卷积自编码器
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        # 处理躁点数据
        x_test_noisy = x_test + np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test_noisy[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```

### 稀疏编码器

由于稀疏编码器能够学习到输入数据的稀疏特征表示，因此也应用于无监督的特征提取学习中。

稀疏编码的网络结构与自编码器一样，同样是一个由三层结构构成的前馈神经网络，在稀疏编码中，期望模型能够对任意的输入数据 $x^t$，得到隐藏层表示 $h^t$，以及输出表示 $\hat{x^t}$。且满足如下性质

隐藏层向量是稀疏的，则向量 $h^t$有尽可能多的零元素

输出层数据 $\hat{x^t}$ 能够尽可能还原输入层数据  $x^t$

