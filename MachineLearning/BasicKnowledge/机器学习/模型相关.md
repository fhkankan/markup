# 模型相关

## 数据集                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  

离散型数据：由于记录不同类别个体的数目所获得的数据，又称计数数据，不能再细分，也不能提高精度

连续型数据：变量可以在某个范围内取任一数，即变量的取值可以是连续的，这类数据通常是非整数，含有小数部分

### 常用数据集

> 流行的开发数据存储库

Kaggle网址：<https://www.kaggle.com/datasets>

UCI数据集网址：<http://archive.ics.uci.edu/ml/>

Amazon的AWS数据集：<http://aws.amazon.com/fr/datasets/>

scikit-learn网址：[http://scikit-learn.org/stable/datasets/index.html#datasets](http://scikit-learn.org/stable/datasets/index.html)

> 元门户网站

<http://dataportals.org/>

<http://opendatamonitor.eu/>

<http://quandl.com/>

> 其他页面

维基百科的机器学习数据集<https://goo.gl/SJHN2k>

Quora.com 问题<http:/goo.gl/zDR78y>

Datasets subreddit<https://www.reddit.com/datasets>

> 经典数据集

[MINIST](http://yann.lecun.com/exdb/mnist/)

[CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html?usg=alkjrhjqbhw2llxlo8emqns-tbk0at96jq)

下载数据集

```python
import os
import tarfile
from six.moves import urllib

DOWNLOAD_ROOT = "https://raw.githubusercontent.com/ageron/handson-ml/master/"
HOUSING_PATH = os.path.join("datasets", "housing")
HOUSING_URL = DOWNLOAD_ROOT + "datasets/housing/housing.tgz"

def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):
    os.makedirs(housing_path, exist_ok=True)
    tgz_path = os.path.join(housing_path, "housing.tgz")
    urllib.request.urlretrieve(housing_url, tgz_path)
    housing_tgz = tarfile.open(tgz_path)
    housing_tgz.extractall(path=housing_path)
    housing_tgz.close()
```

### 数据集划分

训练数据：用于训练，构建模型

测试数据：用于校验，测试模型是否有效

划分比例：`70:30, 80:20, 75:30`

作用：可以测试模型的泛化能力

```python
import numpy as np


# 保证同一数据集测试数据的一致性和灵活性：使用seed
def train_test_split(X, y, test_ratio=0.2, seed=None):
    """将数据 X 和 y 按照test_ratio分割成X_train, X_test, y_train, y_test"""
    assert X.shape[0] == y.shape[0], \
        "the size of X must be equal to the size of y"
    assert 0.0 <= test_ratio <= 1.0, \
        "test_ration must be valid"
    if seed:
        np.random.seed(seed)
    shuffled_indexes = np.random.permutation(len(X))
    test_size = int(len(X) * test_ratio)
    test_indexes = shuffled_indexes[:test_size]
    train_indexes = shuffled_indexes[test_size:]
    X_train, y_train = X[train_indexes], y[train_indexes]
    X_test, y_test= X[test_indexes], y[test_indexes]

    return X_train, X_test, y_train, y_test


# 保证获取更新后数据集测试数据的一致性：标识符
from zlib import crc32

def test_set_check(identifier, test_ratio):
    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32

def split_train_test_by_id(data, test_ratio, id_column):
    ids = data[id_column]
    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))
    return data.loc[~in_test_set], data.loc[in_test_set]

```

## 模型类别

- 形式上

> 概率模型

利用训练样本数据，通过学习条件概率分布$P(Y|X)$来进行推断决策

> 非概率模型

通过学习决策函数$Y=f(x)$来进行推断

- 算法上

联合概率分布：假设输入输出的随机变量$X$ 和 $Y$ 遵循联合概率分布 $P(X, Y)$

> 生成模型

模型学习联合概率分布 $P(X,Y)$，然后求出$P(Y|X)=\frac{P(X,Y)}{P(X)}$。

之所以称为生成模型，是因为模型不仅可以用来预测结果输出${argmax_y}(P(Y|X))$，还可以通过联合分布$P(X,Y)$来生成新的样本数据集$(x_i, y_i)$。

典型生成模型：朴素贝叶斯、隐马尔可夫

优缺点

```
1.生成模型可以还原联合概率，而判别模型不行
2.学习收敛速度快，当岩本容量增加时，学到的模型可以更快收敛
3.当存在隐变量时，可以使用生成模型，而判别模型不行
```

> 判别模型是：

直接求取条件概率分布$P(Y|X)$或决策函数$Y=f(X)$

判别模型并不需要关心X和Y之间的生成关系，它直接关心的是对于给定的输入X应该得到怎样的输出Y。

大部分的分类模型都属于判别模型，包括：k近邻、感知机、决策树、逻辑回归、SVM、条件随机场等

优缺点

```
1.直接学习决策函数或条件概率，学习的准确率更高
2.可以对数据进行抽象，定义特征和使用特征，可以简化学习问题
```

## 模型选择理论

- 最大似然估计

- 奥卡姆剃刀定理

- 没有免费的午餐定理

模型是观察的简化，这个简化是丢弃了那些不大可能泛化至新实例上的多余细节。但是，要决定丢弃哪些数据以及保留哪些数据，必须要做出假设。如线性模型基于的假设为：数据基本上都是线性的，而实例与直线之间的距离都只是噪声，可以忽略它们。

没有免费午餐定理：如果你对数据绝对没有任何假设，那么你就没有理由会偏好于某个模型。

对不同的数据集，最佳模型可能是不同的。不存在一个先验模型能保证一定工作得更好。要想知道哪个模型最好的方法是对所有模型进行评估，但是实际上是不可能的，因此才会对数据做出一些合理的假设，然后只评估部分合理的模型。如：对于简单的任务，可能只会评估几个具有不同正则化水平的线性模型，而对于复杂问题，可能会评估多个神经网络模型。

## 拟合泛化

**欠拟合**：算法所训练的模型不能完整表述数据间的关系

**过拟合**：算法所训练的模型过多地表达了数据间的噪音关系

欠拟合也被称为模型具有高**偏差**，过拟合也被称为高**方差**

##  偏差方差均衡

Bias Variance Trade off

模型误差 = 偏差(Bias) + 方差(Variance) + 不可避免的误差

常见现象

```
偏差和方差通常是矛盾的，降低偏差，会提高方差；降低方差，会提高偏差

对于高偏差模型，模型在验证集的表现与在训练集上的表现类似；
对于高方差模型，模型在验证集的表现远远不如在训练集的表现。
```

偏差产生原因

```
对问题本身的假设不正确
如非线性回归使用线性回归，造成欠拟合
如特征选取错误
```

方差产生的原因

```
使用的模型太复杂
如高阶多项式回归，造成过拟合
```

算法原因

```
有一些算法天生是高方差的算法，如knn
非参数学习通常都是高方差算法，因为不对数据进行任何假设

有一些算法天生是高偏差的算法，如线性回归
参数学习通常都是高偏差算法，因为对数据具有极强的假设

大多数算法具有相应的参数，可以调整偏差和方差
如knn中的k,线性回归中使用多项式回归
```

机器学习算法的主要挑战，是方差

解决高方差的常用手段

```
1. 降低模型复杂度
2. 减少数据维度，降噪
3. 增加样本数
4. 使用验证集
5. 模型正则化
```

## 损失函数

损失函数是机器学习中预测模型一次预测结果好坏的函数，它是一个非负实数值函数，用$L(Y, f(X))$ 来表示，常用的损失函数有

- 0-1损失函数

0-1损失函数比较的是预测值与真实值是否相同
$$
L(Y,f(X))=
\begin{cases}
1, & Y=f(X)\\
0, & Y\ne f(X)
\end{cases}
$$
0-1损失函数是一个非凸函数，在求解过程中，存在很多不足。常作为衡量指标，而不是最优化的目标函数。

- 平方损失函数

线性回归模型常用的最优化目标函数
$$
L(Y, f(X))=(Y-f(x))^2
$$

- 对数损失函数

常用于分类模型的最优化目标函数
$$
L(Y, f(X))= -\ln P(Y|X)
$$

- Hinge损失函数

也称为最大间隔目标函数，是SVM采用的最优化目标
$$
L(Y, f(X))= \max (0, 1-Y *f(X))
$$
对于任意给定的损失函数，可以求得平均一一下的期望损失函数，期望损失函数也称为期望风险函数
$$
R_{exp}(f)=E(L(Y, f(X)))=\int{L(Y, f(X))P(x,y)dxdy}
$$
机器学习的目标是使期望风险函数最小，但由于联合分布函数 $P(x,y)$ 是不知道的，因此在实际应用中，通常的优化目标是经验风险最小化。

假设现有训练数据集
$$
T = \{(x_1, y_1),(x_2, y_2),\cdots, (x_N, y_N)\}
$$
模型 $f(x)$ 关于训练数据集T的经验风险函数为
$$
R_{emp}(x)=\frac{1}{N}{\sum_{i=1}^{N}L(y_i, f(x_i))}
$$
事实上，由概率论的大数定理可知，当N无穷大时，有
$$
\lim_{N \to \infty}{R_{emp}(f)}=R_{exp}(f)
$$


## 模型正则化

Regularization，限制参数的大小，可以提高模型泛化

- 原理

在线性回归的损失函数
$$
\sum_{i=1}^m{(y^{(i)}-\theta_0-\theta_1X_1^{(i)}-\ldots-\theta_nX_n^{(i)})^2}
$$
也就是
$$
J(\theta) = MSE(y, \hat{y}; \theta)
$$
加入模型正则化
$$
J(\theta) = MSE(y, \hat{y}; \theta) + \alpha\frac{1}{2}\sum_{i=1}^n{\theta_i^2}
$$

- L1、L2、L0正则

$L_p$范数
$$
\Arrowvert{x}\Arrowvert_p = (\sum_{i=1}^n{\arrowvert{x_i}\arrowvert^p})^{\frac{1}{p}}
$$
Ridge添加正则化部分
$$
\sum_{i=1}^n{\theta_i^2}
$$
被称为L2正则项

LASSO添加正则化部分
$$
\sum_{i=1}^n{\arrowvert{\theta_i}\arrowvert}
$$
被称为L1正则项
$$
J(\theta) = MSE(y, \hat{y}; \theta) + min\{number-of-non-zero-\theta\}
$$
使$J(\theta)$中$\theta$个数尽可能少，即为L0正则项

对于L0正则的优化是一个NP难的问题，通常使用L1取代L0

- 弹性网(Elastic Net)

$$
J(\theta) = MSE(y, \hat{y}; \theta) + r\alpha\sum_{i=1}^n\arrowvert{\theta_i}\arrowvert + \frac{1-r}{2}\alpha\sum_{i=1}^n{\theta_i^2}
$$

- 实现

回归算法中使用模型正则化来提高泛化能力的有岭回归、拉索回归等

- 应用

计算量可接受时，优先尝试岭回归

计算量过大时，优先使用弹性网

## 验证曲线

不断调整模型的复杂度，可以得到训练得分和验证得分的图形，称为验证曲线。有如下特征

```
1.训练得分肯定高于验证得分，一般情况下，模型拟合自己接触过的数据，比拟合没接触过的数据效果要好
2.使用复杂度较低的模型(高偏差)时，训练数据往往欠拟合，说明模型对训练数据和新数据都缺乏预测能力
3.使用复杂度较高的模型(高方差)时，训练数据往往过拟合，说明模型对训练数据预测能力很强，但是对新数据的预测能力很差
4.当使用复杂度适中的模型时，验证曲线得分最高，说明在该模型复杂度条件下 ，偏差与方差达到均衡状态
```

## 学习曲线

随着训练样本的逐渐增多，算法训练出的模型的表现能力变化。反映训练集规模的训练得分/验证得分曲线被称为学习曲线。有如下特征

```
1.特定复杂度的模型对较小的数据集容易过拟合：此时训练得分较高，验证得分较低
2.特定复杂度的模型对较大的数据集容易欠拟合：随着数据的增大，训练得分会不断降低，而验证得分会不断升高
3.模型的验证集得分永远不会高于训练集得分：两条曲线一直在靠近，但永远不会交叉
```

示例

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler

np.random.seed(666)
x = np.random.uniform(-3.0, 3.0, size=100)
X = x.reshape(-1, 1)
y = 0.5 * x ** 2 + x * 2 + np.random.normal(0, 1, size=100)

# plt.scatter(x, y)
# plt.show()
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)
print(X_train.shape)

train_score = []
test_score = []
for i in range(1, 76):
    lin_reg = LinearRegression()
    lin_reg.fit(X_train[:i], y_train[:i])
    y_train_predict = lin_reg.predict(X_train[:i])
    train_score.append(mean_squared_error(y_train[:i], y_train_predict))
    y_test_predict = lin_reg.predict(X_test)
    test_score.append(mean_squared_error(y_test, y_test_predict))

# plt.plot([i for i in range(1, 76)], np.sqrt(train_score), label="train")
# plt.plot([i for i in range(1, 76)], np.sqrt(test_score), label="test")
# plt.legend()
# plt.show()


# 封装函数
def plot_learning_curve(algo, X_train, X_test, y_train, y_test):
    train_score = []
    test_score = []
    for i in range(1, 76):
        algo.fit(X_train[:i], y_train[:i])
        y_train_predict = algo.predict(X_train[:i])
        train_score.append(mean_squared_error(y_train[:i], y_train_predict))
        y_test_predict = algo.predict(X_test)
        test_score.append(mean_squared_error(y_test, y_test_predict))

    plt.plot([i for i in range(1, 76)], np.sqrt(train_score), label="train")
    plt.plot([i for i in range(1, 76)], np.sqrt(test_score), label="test")
    plt.legend()
    plt.axis([0, len(X_train) + 1, 0, 4])
    plt.show()

# 线性回归调用
plot_learning_curve(LinearRegression(), X_train, X_test, y_train, y_test)


# 多项式回归调用
def PolynomialRegression(degree):
    return Pipeline([
        ("poly", PolynomialFeatures(degree=degree)),
        ("std_scaler", StandardScaler()),
        ("lin_reg", LinearRegression())
    ])


poly2_reg = PolynomialRegression(degree=2)
plot_learning_curve(poly2_reg, X_train, X_test, y_train, y_test)
# 过拟合调用
poly20_reg = PolynomialRegression(degree=20)
plot_learning_curve(poly20_reg, X_train, X_test, y_train, y_test)
```

## 交叉验证

Cross Validation

训练数据：训练模型使用的数据集

验证数据：调整超参数使用的数据集

测试数据：作为衡量最终模型性能的数据集

如果对所有的数据进行模型训练，则可能造成过拟合，上线后无法进行模型调整，故需要测试数据集

如是仅仅用测试数据集对模型进行验证调整，则可能造成针对特定测试数据集过拟合，故在数据中随机使用部分数据作为验证数据集

有了验证数据，则可以在数据训练时采用验证数据进行验证来调整超参数，之后再用测试数据集进行测试，但是随机带来新的问题，验证数据可能存在极端情况，会造成对验证数据集的过拟合，故需要交叉验证

缺点

```
把训练集分成k份，称为k-folds cross validation，每次训练K个模型，整体性能慢了k倍
```

留一法

```
LOO-CV
有m个样本，把训练数据集分成m份， 称为留一法，Leave-One-Out Cross Validation

优点：
完全不受随机的影响，最接近模型真正的性能指标
缺点：
计算量大
```

示例

```python
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

digits = datasets.load_digits()
X = digits.data
y = digits.target

# 测试数据集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=666)

# 手动循环超参数验证
best_score, best_p, best_k = 0, 0, 0
for k in range(2, 11):
  	for p in range(1, 6):
      	knn_clf = KNeighborsClassifier(weights="distance", n_neighbors=k, p=p)
        knn_clf.fit(X_train, y_train)
        score = knn_clf.score(X_test, y_test)
        if score > best_score:
          	best_score = score
            best_p = p
            best_k = k
print("best_score", best_score)
print("best_p", best_p)
print("bset_k", best_k)

# 交叉验证
knn_clf = KNeighborsClassifier()
cross_val_score(knn_clf, X_train, y_train)
# cross_val_score(knn_clf, X_train, y_train, cv=5)  # 指定训练集分割份数
best_score, best_p, best_k = 0, 0, 0
for k in range(2, 11):
  	for p in range(1, 6):
      	knn_clf = KNeighborsClassifier(weights="distance", n_neighbors=k, p=p)
        scores = cross_val_score(knn_clf, X_train, y_train)
        score = np.mean(scores)
        if score > best_score:
          	best_score = score
            best_p = p
            best_k = k
print("best_score", best_score)
print("best_p", best_p)
print("bset_k", best_k)

best_knn_clf = KNeighborsClassifier(weights="distance", n_neighbors=2 p=2)
best_knn_clf.fit(X_train, y_train)
score = best_knn_clf.score(X_test, y_test)
print(score)

# 网格搜索
param_grid = [
  {
    'weights': ['distance'],
    'n_neighbors': [ i for i in range(2, 11)],
    'p': [i for i in range(1, 6)]
  }
]
grid_search = GridSearchCV(knn_clf, param_grid, verbose=1)
# GridSearchCV(knn_clf, param_grid, verbose=1, cv=5)  # 指定训练集分割份数
grid_search.fit(X_train, y_train)
print(grid_search.best_score_)
print(grid_search.best_params_)
best_knn_clf = grid_search.best_estimator_
best_knn_clf.score(X_test, y_test)
```

## 网格搜索

在实际工作中，模型通常有多个得分转折带你，因此验证曲线和学习曲线的图形会从二维曲线变成多维曲线。这种高纬可视化很难展现，因此从图中找出验证得分的最大值不是一件简单的事。

模型参数：算法过程中学习的参数

超参数：在算法运行前需要决定的参数

超参数选择方法：领域知识、经验数值、实验（网格）搜索

在网格搜索中每组超参数都采用交叉验证来进行评估。

自定义实现

```python
best_method = ""
best_score = 0.0
best_k = -1
for method in ["uniform", "distance"]:
		for k in range(1, 11):
  			knn_clf = KNeighborsClassifier(n_neighbors=k)
    		knn_clf.fit(X_train, y_train)
    		score = knn_clf.score(X_test, y_test)
    		if score > best_score:
      			best_k = k
      			best_score = score
            best_method = method
print("best_k = ", best_k)
print("best_score = ", best_score)
print("best_method = ", best_method)
```

## 评价指标

### 回归

- 平均绝对误差(Mean Absolute Error)

$$
MAE = \frac{\sum_{i=1}^m y_{test}^{(i)}-\hat{y}_{test}^{(i)}\arrowvert}{m}
$$

计算绝对值的总和，对应 $l_1$范数，记作 $||\cdot||_{1}$。

- 均方误差(Mean Squared Error)

$$
MSE = \frac{\sum_{i=1}^m{(y_{test}^{(i)}-\hat{y}_{test}^{(i)})^2}}{m}
$$



- 均方根误差(Root Mean Squared Error)

$$
RMSE = \sqrt{MSE}
$$

计算平方和的根，对应 $l_2$ 范数，记为 $||\cdot||_{2}$。

相对MSE，可降低量纲的影响。相对MAE，更关注大的价值，忽略小的价值，异常值稀少时，表现更优异。


- R方

也被称为**判定系数**，用于河梁模型与目标值均值的对比结果。

其值小于等于1，等于1表示模型与数据吻合·，等于0表示模型不比简单取均值好，小于0表示模型还不如基准模型，可能不存在任何线性关系。
$$
\begin{aligned}
R^2 
&=  1 - \frac{SS_{redidual}}{SS_{total}} \\
&=1 - \frac{\sum_i{(\hat{y}^{(i)}-y^{(i)})^2}}{\sum_i{(\bar{y}^{(i)}-y^{(i)})^2}}\\
&=1 - \frac{(\sum_{i=1}^m{(\hat{y}^{(i)}-y^{(i)})^2})/m}{(\sum_{i=1}^m{(\bar{y}^{(i)}-y^{(i)})^2})/m} \\
&= 1 - \frac{MSE(\hat{y}, y)}{Var(y)}
\end{aligned}
$$

自定义实现

```python
# metrics.py
import numpy as np
from math import sqrt


def accuracy_score(y_true, y_predict):
    """计算y_true和y_predict之间的准确率"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum(y_true == y_predict) / len(y_true)


def mean_squared_error(y_true, y_predict):
    """计算y_true和y_predict之间的MSE"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum((y_true - y_predict)**2) / len(y_true)


def root_mean_squared_error(y_true, y_predict):
    """计算y_true和y_predict之间的RMSE"""

    return sqrt(mean_squared_error(y_true, y_predict))


def mean_absolute_error(y_true, y_predict):
    """计算y_true和y_predict之间的RMSE"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum(np.absolute(y_true - y_predict)) / len(y_true)


def r2_score(y_true, y_predict):
    """计算y_true和y_predict之间的R Square"""

    return 1 - mean_squared_error(y_true, y_predict)/np.var(y_true)

```

sklearn实现

```python
# 均方误差
from sklearn.metrics import mean_squared_error


# 根均方误差
sqrt(mean_squared_error())

# 平均绝对误差
from sklearn.metrics import mean_absolute_error


# R方
from sklearn.metrics import r2_score
```

### 分类

- 准确度

$$
accuracy = \frac{\sum_{i=1}^m{(y_{test}^{(i)}==\hat{y}_{test}^{(i)})}}{m}
$$

对于极度偏斜(Skewed Data)的数据，分类准确度时不够的

- 精准率/召回率

1为关注的事件(Positive)，0为对立事件(Negative)

| 真实\预测 | 0    | 1    |
| --------- | ---- | ---- |
| 0         | TN   | FP   |
| 1         | FN   | TP   |

**精准率**：表示的是预测为正的样本中有多少是真正的正样本。有两种可能：把正类预测为正类(TP)，是把负类预测为正类(FP)。
$$
precision = \frac{TP}{TP+FP}
$$
**召回率**：表示的是样本中的正例有多少被预测正确了。有两种可能：把原来的正类预测成正类(TP)，把原来的正类预测为负类(FN)。
$$
recall = \frac{TP}{TP+FN}
$$
- F1 Score

反应了模型的稳健性，是precision和recall的调和平均值
$$
\frac{1}{F1} = \frac{1}{2}(\frac{1}{precision}+\frac{1}{recall}) 
$$
得到
$$
\\
F1 = \frac{2\cdot{precision}\cdot{recall}}{precision+recall}
$$

- PR曲线

precision_recall_curve

随着阈值的变化，精准率和召回率呈现反向变化的情况，故需要寻找之间的平衡，可以确定较好的阈值来分类

mAP是为结局P、R、F-measure的单点值局限性的

召回率*准确率的面积越大，则map越大，模型越好

- ROC/AUC曲线

Receiver Operation Characteristic Curve

描述TPR和FPR之间的关系， 可用于比较不同的模型好坏。

其中，TPR叫做 真正类率，TNR叫做 真负类率，FPR叫做假正类率


$$
TPR = Recall = \frac{TP}{TP+FN} \\
TNR = \frac{TN}{TN+FP}\\
FPR = 1-TNR = \frac{FP}{TN+FP}
$$

> PR/ROC选择
>
> 当正类非常少见或更关注假正例而不是假负例时，选择PR曲线，否则选择ROC曲线

- 实现

自实现

```python
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

digits = datasets.load_digits()
X = digitis.data
y = digitis.target.copy()
# 对数据手动偏斜
y[digits.target==9] = 1
y[digits.target!=9] = 0

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)

def TN(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 0)&(y_predict == 0))

def FP(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 0)&(y_predict == 1))
  
def FN(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 1)&(y_predict == 0))
  
def TP(y_true, y_predict):
  	assert len(y_true) == len(y_predict)
    return np.sum((y_true == 1)&(y_predict == 1))
  
def confusion_matrix(y_true, y_predict):
		return np.array([
      	[TN(y_test, y_predict), FP(y_test, y_predict)],
      	[FN(y_test, y_predict), TP(y_test, y_predict)]
    ])

def precision_score(y_true, y_predict):
  	tp = TP(y_test, y_predict)
    fp = FP(y_test, y_log_predict)
    try:
      	return tp / (tp + fp)
    except:
      	retunr 0.0
  
def recall_score(y_true, y_predict):
  	tp = TP(y_test, y_predict)
    fn = FN(y_test, y_predict)
    try:
    		return tp / (tp + fn)
    except:
      	return 0.0
      
def f1_score(y_true, y_predict):
  	precision = precision_score(y_true, y_predict)
    recall = recall_score(y_true, y_predict)
  	try:
      	return 2 * precision*recall / (precision + recall)
    except:
      	return 0.0
      
def TPR(y_true, y_predict):
  	tp = TP(y_true, y_predict)
    fn = FN(y_true, y_predict)
    try:
      	return tp / (tp + fn)
    except:
      	return 0.

def FPR(y_true, y_predict):
  	fp = FP(y_true, y_predict)
    tn = TN(y_true, y_predict)
    try:
      	return fp / (fp + tn)
    except:
       	return 0.
  
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
log_reg.score(X_test, y_test)  # 准确度

y_log_predict = log_reg.predict(X_test)

TN(y_test, y_log_predict)
FP(y_test, y_log_predict)
FN(y_test, y_log_predict)
TP(y_test, y_log_predict)
confusion_matrix(y_test, y_log_predict)  # 混淆矩阵
precision = precision_score(y_test, y_log_predict)  # 精确度
print(precision)
recall = recall_score(y_test, y_log_predict)  # 召回率
print(recall)
f1_score = f1_score(y_test, y_log_predict)  # f1
print(f1_score)

# 决策函数返回score值，>0则预测为1，<0则预测为0
decision_scores = log_reg.decision_function(X_test)

# 使用5作为预测结果阈值
y_predict_2 = np.array(decision_scores >= 5, dtype='int')
confusion_matrix(y_test, y_predict_2)
precision = precision_score(y_test, y_predict_2)
recall = recall_score(y_test, y_predict_2)
f1_score = f1_score(y_test, y_predict_2)

# 自定义绘图precision-recall曲线
precisions = []
recalls = []
thresholds = np.arrange(np.min(decision_scores), np.max(decision_scores), 0.1)
for threshold in thresholds:
  	y_predict = np.array(decision_scores >= threshold, dtype='int')
    precisions.append(precision_score(y_test, y_predict))
    recalls.append(recall_score(y_test, y_predict))
    
plt.plot(thresholds, precisions)
plt.plot(thresholds, recalls)
plt.show()
plt.plot(precisions, recalls)
plt.show()

# ROC曲线
fprs = []
tprs = []
thresholds = np.arrange(np.min(decision_scores), np.max(decision_scores), 0.1)
for threshold in thresholds:
  	y_predict = np.array(decision_scores >= threshold, dtype='int')
    fprs.append(FPR(y_test, y_predict))
    tprs.append(TPR(y_test, y_predict))
    
plt.plot(fprs, tprs)
plt.show()
```

> sklearn实现

API

```python
sklearn.metrics.confusion_matrix(y_true, y_pred,)
# 参数
y_true：真实目标值
y_pred：估计器预测目标值


sklearn.metrics.classification_report(y_true, y_pred, target_names=None)
# 参数
y_true：真实目标值
y_pred：估计器预测目标值
target_names：目标类别名称
# 返回
每个类别精确率与召回率
```

示例

```python
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

digits = datasets.load_digits()
X = digitis.data
y = digitis.target.copy()
# 对数据手动偏斜
y[digits.target==9] = 1
y[digits.target!=9] = 0

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
log_reg.score(X_test, y_test)  # 准确度

y_log_predict = log_reg.predict(X_test)

confusion_matrix(y_test, y_log_predict)  # 混淆矩阵
precision = precision_score(y_test, y_log_predict)  # 精确度
recall = recall_score(y_test, y_log_predict)  # 召回率
f1_score = f1_score(y_test, y_log_predict)  # f1

# sklearn实现precision-recall曲线
precisions, recalls, thresholds = precision_recall_curve(y_test, decision_scores)
plt.plot(thresholds, precisions[:-1])
plt.plot(thresholds, recalls[:-1])
plt.show()
plt.plot(precisions, recalls)
plt.show()

# ROC
fprs, tprs, thresholds = roc_curve(y_test, decision_scores)
plt.plot(fprs, tprs)
plt.show()

roc_auc_score(y_test, decision_scores)
```

多分类

```python
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix

digits = datasets.load_digits()
X = digits.data
y = digits.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=666)

log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
log_reg.score(X_test, y_test)

y_predict = log_reg.predict(X_test)

cfm = confusion_matrix(y_test, y_predict)
print(cfm)
plt.matshow(cfm, cmap=plt.cm.gray)
plt.show()

row_sums = np.sum(cfm, axis=1)
err_matrix = cfm / row_sums
np.fill_diagonal(err_matrix, 0)
print(err_matrix)
plt.matshow(err_matrix, cmap=plt.cm.gray)
plt.show()  # 越亮的地方即错误最大的地方
```

### 聚类

- 轮廓系数

Silhouette Coefficient
$$
s_i = \frac{b_i-a_i}{max\{a_i,b_i\}}\\
s_i = \begin{cases}
			 1-\frac{a_i}{b_i},&a_i<b_i\\
			 0, & a_i=b_i\\
			 \frac{b_i}{a_i}-1, & a_i>b_i
			 \end{cases}
$$
计算样本i到同簇其他样本的平均距离$a_i$。$a_i$越小，说明样本i越应该被聚类到该簇。将$a_i$称为样本i的簇内不相似度。

计算样本i到其他某簇$C_j$的所有样本的平均距离$b_{ij}$，称为样本i与簇$C_j$的不相似度。定义为样本i的簇间不相似度：$b_i=min\{b_{i1},b_{i2},…,b_{ik}\}$

$s_i$接近1，则说明样本i聚类合理

$s_i$接近-1，则说明样本i更应该分类到另外的簇

$s_i$近似为0，则说明样本i在两个簇的边界上

sklearn实现

```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

labels = KMeans(n_clusters=3).fit(X).labels_
score = silhouette_score(X, labels)
```



## 模型保存与加载

svm模型

```python
# 保存模型
import pickle
with open("./svm.model", "wb") as f:
    pickle.dump(svc, f)

# 加载模型
with open("./svm.model", "rb") as f:
    svc = pickle.load(f)
```

## 向量化

有向量
$$
w = (w^{(1)}, w^{(2)}, ...,w^{(m)})
$$

$$
v = (v^{(1)}, v^{(2)},...,v^{(m)})^T
$$

可将如下求和公式
$$
\sum_{i=1}^m{w^{(i)}\cdot v^{(i)}}
$$
向量化
$$
w\cdot v
$$
向量化可以提高运算速度

## 最小二乘法

所谓最小二乘，其实也可以叫做最小平方和，其目的就是通过最小化误差的平方和，使得拟合对象无限接近目标对象。换句话说，最小二乘法可以用于对函数的拟合。
$$
\min e^2 = (y-\hat{y})^2
$$

## 梯度下降

梯度下降法(gradient descent)是一种常用的一阶(first-order)优化方法，是求解无约束优化问题最简单、最经典的方法之一。

考虑一个无约束优化问题$\min\limits_{x}f(x)$,  其中$f(x)$为连续可微函数，如果我们能够构造一个序列 $ x^0, x^1,\cdots$ ，并能够满足：
$$
f(x^{t+1}) < f(x^t), t=0,1,2,\cdots
$$
那么我们就能够不断执行该过程即可收敛到局部极小点。

如何找到下一个点 $x^{t+1}$，并保证$f(x^{t+1}<f(x^t))$ 呢？

假设当前的函数的形式是开口向上的抛物线形状，现在我们随机找了一个初始的点 $x_1$，对于一元函数来说，函数值只会随着$x$的变化而变化，那么我们就设计下一个 $x^{t+1}$ 是从上一个 $x^t$ 沿着某一方向走一小步 $\Delta x$ 得到的。

这一小步的方向是朝向哪里？

对于一元函数来说，$x$ 是会存在两个方向：要么是正方向（$\Delta x >0$），要么是负方向（$\Delta x < 0$），如何选择每一步的方向，就需要用到泰勒公式。

先看一下下面这个泰勒展式：
$$
f(x + \Delta x) \approx f(x)+\Delta x \nabla f(x)
$$
左边就是当前的 $x$  移动一小步 $\Delta x$ 之后的下一个点位，它近似等于右边。前面我们说了关键问题是找到一个方向，使得$f(x + \Delta x) < f(x)$，那么根据上面的泰勒展式，显然我们需要保证：
$$
\Delta x \nabla f(x) < 0
$$
可选择令：
$$
\Delta x = - \alpha \nabla f(x), (\alpha>0)
$$

其中步长 $\alpha$ 是一个较小的正数，从而： 
$$
\Delta x \nabla f(x) = - \alpha (\nabla f(x))^2
$$

由于任何不为0的数的平方均大于0，因此保证了

$$
\Delta x \nabla f(x) < 0
$$

从而，设定：
$$
f(x + \Delta x) = f(x- \alpha \nabla f(x))
$$

则可保证：
$$
f(x + \Delta x) < f(x)
$$

那么更新 $x$ 的计算方式就很简单了，可按如下公式更新 $x$
$$
x^{'} \leftarrow x - \alpha \nabla f(x)
$$

这就是所谓的**沿负梯度方向走一小步**。

到此为止，这就是梯度下降的全部原理。

实现

```python
import numpy as np
import matplotlib.pyplot as plt


def f(x):
    return np.power(x, 2)

def d_f_1(x):
    return 2.0 * x

def d_f_2(f, x, delta=1e-4):
    return (f(x+delta) - f(x-delta)) / (2 * delta)


# plot the function
xs = np.arange(-10, 11)
plt.plot(xs, f(xs))
plt.show()

learning_rate = 0.1
max_loop = 30

x_init = 10.0
x = x_init
lr = 0.1
for i in range(max_loop):
    # d_f_x = d_f_1(x)
    d_f_x = d_f_2(f, x)
    x = x - learning_rate * d_f_x
    print(x)

print('initial x =', x_init)
print('arg min f(x) of x =', x)
print('f(x) =', f(x))
```

## 距离度量

聚类是一个基于距离划分数据集的过程，令 $d(x,y)$ 表示向量 $x,y$ 之间的距离，则$d(x,y)$ 需满足下面四个条件

- 非负性：$d(x,y)\ge 0$
- 同一性：$d(x,x)=0$
- 对称性 ：$d(x, y)=d(y,x)$
- 三角不等式性：$d(x,z)\le d(x,y)+d(y,z)$

> 有序数据

有序数据常用的距离计算方法是Minkowski距离，假设当前有两个n维空间的点x和y，满足
$$
x = (x_1,x_2,\cdots, x_n)^T,y=(y_1,y_2,\cdots,y_n)^T
$$
则x和y的Minkowski距离
$$
d(x,y)=(\sum_{i=1}^m(x_i-y_i)^p)^{\frac{1}{p}}
$$
当 $p=2$ 时，是欧几里德距离；当 $p=1$ 时，是曼哈顿距离。

如果每一个特征的权重不一样，则可修如下
$$
d(x,y)=(\sum_{i=1}^m w_i(x_i-y_i)^p)^{\frac{1}{p}}
$$
其中，$w_i$ 是对应于第$i$ 个特征的权重大小

高斯距离也是一种常用的计算有序数据距离的方式
$$
d(x,y)= \exp (-\frac{||x-y||}{2\sigma^2})
$$

> 无序数据

无序数据不能直接使用Minkowski距离来衡量两者之间的距离，常用VDM距离来衡量

形式化定义为：设 $m_{ia}$ 表示在第i个特征中取值为a的样本数，$m_{iaj}$ 表示在第j个簇中，第i个特征取值为a的样本数，

设有k个簇，则特征取值为a和取值为b的距离为
$$
VDM(a,b)=\sum_{j=1}^{k}{(\frac{m_{iaj}}{m_{ia}}-\frac{m_{ibj}}{m_{ib}})}^p
$$

> 混合

当数据点中既含有有序特征，也含有无序特征时，可的混合的距离计算公式
$$
d(x,y)=(\sum_{i=1}^{s}{(x_i-y_i)^p}+\sum_{i=s+1}^{m}{VDM(x_i, y_i)})^{\frac{1}{p}}
$$


