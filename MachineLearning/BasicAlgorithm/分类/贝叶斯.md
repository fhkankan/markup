# 贝叶斯

优缺点

```
# 优点
1.朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。
2.对缺失数据不太敏感，算法也比较简单，常用于文本分类。
3.分类准确度高，速度快
4.容易解释
5.可调参数非常少

# 缺点
1.需要知道先验概率P(F1,F2,…|C)，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳
```

适用场景

```
1.假设分布函数与数据匹配
2.各种类型的区分度很高，模型复杂度不重要
3.非常高维度的数据，模型复杂度不重要
```

## 原理

贝叶斯定理
$$
P(B|A)=\frac{P(A|B)P(B)}{P(A)}
$$

当事件(特征)相互独立时，贝叶斯准则转变为朴素贝叶斯，朴素贝叶斯是贝叶斯准则中的一种特殊情况。

在贝叶斯分类中，我们希望确定一个具有某些特征的样本属于某类标签的概率，记为 $P(L|特征) $，可用如下公式计算
$$
P(L|特征) = \frac{P(特征｜L)P(L)}{P(特征)}
$$
假如需要确定两种标签，定义为 $L_1,L_2$，一种方法就是计算这两个标签的后验概率的比值
$$
\frac{P(L_1|特征)}{P(L_2|特征)} = \frac{P(特征｜L_1)P(L_1)}{P(特征｜L_2)P(L_2)}
$$
现在需要一种模型，帮我们计算每个标签的 $P(特征|L_i)$。这种模型称为**生成模型**。因为它可以训练出生成数据的假设随机过程（或称为概率分布）。为每个标签生成模型是贝叶斯分类器训练过程的主要部分。虽然这个训练步骤通常很难做，但是可以通过对模型进行随机分布的假设，来简化训练工作。

之所以称为**朴素**，是因为如果对每种标签的生成模型进行非常简单的假设，就能找到每种类型生成模型的近似解，然后就可以使用贝叶斯分类。不同类型的朴素贝叶斯分类器是由对数据的不同假设决定的。

- 高斯朴素贝叶斯

假设每个标签的数据都服从简单的高斯分布

- 多项式朴素贝叶斯

假设特征是由一个简单多项式分布生成。

多项分布可以描述各种类型样本出现次数的概率，因此多项式朴素贝叶斯非常适合用于描述出现次数或者出现次数比例的特征。

## sklearn

### API

```python
# 高斯朴素贝叶斯
from sklearn.naive_bayes import GaussianNB

# 多项式朴素贝叶斯
from sklearn.naive_bayes import MultinomialNB
```

- 拉普拉斯平滑

```python
由于样本数较少，会出现p(A|B)的概率为0，防止此情况出现，使用拉普莱斯平滑

拉普拉斯平滑系数ɑ, 默认为1
p=Ni/N    ---> p=(Ni+a)/(N+am)
m为训练文档中特征词个数，Ni为xi在分类ci下出现的次数，N为分类ci下词频总数。

MultinomialNB(alpha=0.1)
```

### 示例

- 高斯朴素贝叶斯

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.naive_bayes import GaussianNB

X, y = make_blobs(100, 2, centers=2, random_state=2, cluster_std=1.5)
# plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')
# plt.show()
# 训练
model = GaussianNB()
model.fit(X, y)
# 预测新数据
rng = np.random.RandomState(0)
Xnew = [-6, -14] + [14, 18] * rng.rand(2000, 2)
ynew = model.predict(Xnew)

# 画图寻找决策边界的位置
plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')
lim = plt.axis()
plt.scatter(Xnew[:, 0], Xnew[:, 1], c=ynew, s=20, cmap='RdBu', alpha=0.1)
plt.axis(lim)
plt.show()

# 计算某个样本属于某个标签的概率
yprob = model.predict_proba(Xnew)
print(yprob[-8:].round(2))
# [[0.89 0.11]
#  [1.   0.  ]
#  [1.   0.  ]
#  [1.   0.  ]
#  [1.   0.  ]
#  [1.   0.  ]
#  [0.   1.  ]
#  [0.15 0.85]]
# 前两个标签的后验概率。若要评估分类器的不确定性，这类贝叶斯方法很有用
```

- 多项式朴素贝叶斯

```python
# 1.导入需要的包
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

# 2.载入数据
news = fetch_20newsgroups(subset="all")
# 3.特征选取
# 特征值,文章内容
x = news.data
# 目标值，文章的类别
y = news.target
print(len(y))
# 4.分割训练集
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)
# 5.TF-IDF生成文章特征词
# 特征抽取
cv = TfidfVectorizer()
x_train = cv.fit_transform(x_train)  # 词频矩阵
x_test = cv.transform(x_test)  # 按照训练集抽取特征词统计词频
# 6.朴素贝叶斯estimator流程进行预估
mnb = MultinomialNB()
mnb.fit(x_train, y_train)
mnb.predict(x_test)
score = mnb.score(x_test, y_test)
print(score)
```

示例2

```python
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix

data = fetch_20newsgroups()
print(data.target_names)
# ['alt.atheism', 'comp.graphics', ..., 'talk.politics.misc', 'talk.religion.misc']
# 选择四类新闻
categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics']
train = fetch_20newsgroups(subset='train', categories=categories)
test = fetch_20newsgroups(subset='test', categories=categories)
# 创建管道，将TF-IDF向量化同多项式朴素贝叶斯分类器组合
model = make_pipeline(TfidfVectorizer(), MultinomialNB())
# 训练数据
model.fit(train.data, train.target)
labels = model.predict(test.data)

# 评估评估器性能
# 使用混淆矩阵统计测试数据的真是标签与预测标签的结果
mat = confusion_matrix(test.target, labels)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
            xticklabels=train.target_names, yticklabels=train.target_names)
plt.xlabel('true label')
plt.ylabel('predicted label')
plt.show()


# 快速返回字符串的预测结果
def predict_category(s, train=train, model=model):
    pred = model.predict([s])
    return train.target_names[pred[0]]


res = predict_category('sending a payload to the ISS')
print(res)  # sci.space

```

