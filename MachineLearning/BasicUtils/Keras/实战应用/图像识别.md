# 图像识别

端到端的MNIST训练数字识别

```python
import numpy as np
from keras.datasets import mnist
import keras
import gc

from keras.models import Sequential, Model
from keras.layers import Input, Dense, Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D

# 读入数据
(X_train, y_train), (X_test, y_test) = mnist.load_data()
print(X_train[0].shape, y_train[0], sep="\n")
# 将训练集中的手写黑白字体变成标准的四维张量形式(样本数量，长，宽，1)
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')
# 把像素值变成浮点格式
X_train /= 255
X_test /= 255

'''
也可以使用keras.utils.to_categorical(y, num_classes=None)方法。
这是是为了展示one hot encoding具体是怎么生成的
'''


def tran_y(y):
    y_ohe = np.zeros(10)
    y_ohe[y] = 1
    return y_ohe


y_train_ohe = np.array([tran_y(y_train[i]) for i in range(len(y_train))])
y_test_ohe = np.array([tran_y(y_test[i]) for i in range(len(y_test))])
y_train_ohe = y_train_ohe.astype('float32')
y_test_ohe1 = y_test_ohe.astype('float32')
# y_test_ohe2 = keras.utils.to_categorical(y_test, dtype='float32')

# 定义模型结构。
model = Sequential()
# 添加一层卷积层，构造64个过滤器，每个过滤器覆盖范围是3*3*1，
# 过滤器的移动步长为1，图像四周补一圈0，并用relu进行非线性变换
model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same',
                 activation='relu', input_shape=(28, 28, 1)))
# 添加一层MaxPooling，在2*2的格子中取最大值
model.add(MaxPooling2D(pool_size=(2, 2)))
# 建立Dropout层，将概率设置为0.5
model.add(Dropout(0.5))
model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))
model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))
# 将当前层节点展平
model.add(Flatten())
# 构造全连接神经网络层
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(10, activation='softmax'))

# 我们可以定制各种选项，比如下面就定制了优化器选项。
adamoptimizer = keras.optimizers.Adam(lr=1e-4)
# 定义损失函数，一般分类问题的损失函数选择交叉熵
model.compile(loss='categorical_crossentropy', optimizer=adamoptimizer, metrics=['accuracy'])
# 放进批量样本，进行训练
model.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=10, batch_size=128*2)
# 在测试集上评价模型的准确度
scores = model.evaluate(X_test, y_test_ohe, verbose=0)
print(scores)
```

使用VGG16网络进行字体识别

```python
from keras.datasets import mnist
from keras.utils import to_categorical
from keras.models import Model
from keras.layers import Dense, Dropout, Flatten
from keras.applications.vgg16 import VGG16
from keras.optimizers import SGD
import gc
import cv2
import numpy as np

"""
首先将数据整合为VGG所需维度，由于硬件配置限制，我们选用48个像素点而不是原VGG16所采用的224个像素点。
即使这样仍然需要24GB以上内存或者使用数据生成器。
"""
# 如果硬件配置较高，比如主机具备32GB以上内存，GPU具备8GB以上显存，可以适当增大这个值。VGG要求至少48像素
ishape = 48
(X_train, y_train), (X_test, y_test) = mnist.load_data()

X_train = [cv2.cvtColor(cv2.resize(i, (ishape, ishape)), cv2.COLOR_GRAY2BGR) for i in X_train]
X_train = np.concatenate([arr[np.newaxis] for arr in X_train]).astype('float32')
X_train /= 255.0

X_test = [cv2.cvtColor(cv2.resize(i, (ishape, ishape)), cv2.COLOR_GRAY2BGR) for i in X_test]
X_test = np.concatenate([arr[np.newaxis] for arr in X_test]).astype('float32')
X_test /= 255.0

y_train_ohe = to_categorical(y_train, dtype="float32")
y_test_ohe = to_categorical(y_test, dtype="float32")

# 1.VGG16全参重训迁移学习
# 新建一个模型，将VGG16顶层去掉，只保留其余网络结构。
model_vgg = VGG16(include_top=False, weights='imagenet', input_shape=(ishape, ishape, 3))
model = Flatten(name='flatten')(model_vgg.output)
model = Dense(4096, activation='relu', name='fc1')(model)
model = Dense(4096, activation='relu', name='fc2')(model)
model = Dropout(0.5)(model)
model = Dense(10, activation='softmax')(model)
model_vgg_mnist = Model(model_vgg.input, model, name='vgg16')

model_vgg_mnist.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])
model_vgg_mnist.summary()
# 2的小批量数保证在一台32GB内存的PC上用一个1060 6GB版本GPU可以运行
model_vgg_mnist.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=2, batch_size=2)

# 直接使用VGG16会发现拟合效果非常差。一个解决办法是将卷积层的参数固化，不参与训练。
try:
    del (model_vgg_mnist)
except:
    print('object gone')
# 很多时候需要多次回收垃圾才能彻底收回内存。如果不行，重新启动单独执行下面的模型
for i in range(10):
    gc.collect()

# 2.VGG16部分参数重训迁移学习
ishape = 224
model_vgg = VGG16(include_top=False, weights='imagenet', input_shape=(ishape, ishape, 3))
# for i, layer in enumerate(model_vgg.layers):
#    if i<20:
for layer in model_vgg.layers:
    layer.trainable = False  # 对不需要重新训练的权重冷冻
model = Flatten()(model_vgg.output)
model = Dense(4096, activation='relu', name='fc1')(model)
model = Dense(4096, activation='relu', name='fc2')(model)
model = Dropout(0.5)(model)
model = Dense(10, activation='softmax', name='prediction')(model)
model_vgg_mnist_pretrain = Model(model_vgg.input, model, name='vgg16_pretrain')
model_vgg_mnist_pretrain.summary()

sgd = SGD(lr=0.05, decay=1e-5)
model_vgg_mnist_pretrain.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

model_vgg_mnist_pretrain.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=10, batch_size=64)

# 回收显存和内存垃圾可以使用如下方法，通常需要多次调用gc.collect()才能清除干净。如果异常退出，则无法清除干净显存，需要重新启动notebook。
# del(model_vgg_mnist_pretrain, model_vgg, model)
for i in range(100):
    
    gc.collect()

```

