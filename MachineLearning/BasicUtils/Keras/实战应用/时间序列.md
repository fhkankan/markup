# 时间序列

## 查看数据

```python
from time import time
from datetime import datetime
import warnings  # warnings package is to eliminate annoying warning message from KPSS test
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import signal
from scipy.signal import periodogram
import statsmodels.api as sm
from statsmodels.tsa.stattools import acf
from statsmodels.tsa.tsatools import lagmat
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import keras
import keras.models as kModels
import keras.layers as kLayers
import peakutils as peak

plt.rcParams['figure.figsize'] = (20, 10)
font = {'size': 20}
plt.rc('font', **font)

"""
示例数据
我们的时间序列数据来自于 DataMarket 的时间序列数据库： https://datamarket.com/data/list/?q=provider:tsdl 。 
这个库由澳大利亚莫纳什大学的统计学教授 Rob Hyndman 创建，收集了数十个公开的时间序列数据集。。Rob Hyndman教授也是R统计语言里面
forecast软件包的开发者。本章我们采用其中两个数据作为实例。为了方便读者，都已经存入本地文件夹


第一个数据是在汉口测量的长江每月流量数据作为实例，该数据记录了从1865年一月到1978年十二月间在汉口记录的长江每月流量，总计1368个数据点，
计量单位未知，不过不妨碍我们的分析过程和结果。从下图可以看出，该数据具备很强的不同长度的周期性。我们将该数据下载后存入本地磁盘，
路径为：./data/TimeSeries/， 文件名为monthly-flows-chang-jiang-at-hankou.csv。
"""
parser = lambda date: datetime.strptime(date, '%Y-%m')
df1 = pd.read_csv("./data/TimeSeries/monthly-flows-chang-jiang-at-hankou.csv", engine="python", skipfooter=3,
                  names=["YearMonth", "WaterFlow"], parse_dates=[0], infer_datetime_format=True, date_parser=parser,
                  header=0)
print(df1.head())
"""
   YearMonth  WaterFlow
0 1865-01-01       3880
1 1865-02-01       3290
2 1865-03-01       4910
3 1865-04-01       8760
4 1865-05-01      13800
"""
df1.YearMonth = pd.to_datetime(df1.YearMonth)
df1.set_index("YearMonth", inplace=True)
df1.plot()
plt.savefig('./data/TimeSeries/WaterFlow.png')
plt.show()

"""
第二个数据是1949年一月到1960年十二月的月度国际航空旅客数量。该数据有144个数据点，数据单位为千人，与第一个数据不同的是该数据包含极强的
趋势要素和周期要素，因此在具体的分析上能体现不同的要求。下面我们读入该数据，并展示。该数据下载后在本地磁盘存为：
./data/TimeSeries/international-airline-passengers.csv 。
"""
parser = lambda date: datetime.strptime(date, '%b-%y')
df2 = pd.read_csv("./data/TimeSeries/international-airline-passengers.csv", engine="python", skipfooter=3,
                  names=["YearMonth", "Passenger"], header=0)
df2.YearMonth = df2.YearMonth.str[:4] + '19' + df2.YearMonth.str[-2:]
df2.YearMonth = pd.to_datetime(df2.YearMonth, infer_datetime_format=True)
df2.set_index("YearMonth", inplace=True)
print(df2.head())
"""
            Passenger
YearMonth            
1949-01-01        112
1949-02-01        118
1949-03-01        132
1949-04-01        129
1949-05-01        121
"""
df2.plot(fontsize=20)
plt.savefig('./data/TimeSeries/Passenger.png')
plt.show()
plt.close()

```

## ARIMA

```python
"""
由于国际航空旅客数量具有很强的趋势性和周期性，适合展示建模的不通步骤
下面对数据的平稳性进行检验，使用ADF和KPSS两个统计测试量。同时生成其自相关和偏自相关图。
需要注意的是KPSS测试在p值过小或者过大的情况下，会打印“警告”warnings信息。出于排版美观的要求，我们在下面的检验中，使用了warnings软件库
里的catch_warnings方法来对KPSS函数的warnings打印信息进行控制，直接忽略不打印。
"""
order = 1
diff1 = df2.Passenger.diff(order)[order:]
logdiff1 = np.log(df2.Passenger).diff(order)[order:]
adftest = sm.tsa.stattools.adfuller(diff1)
adftestlog = sm.tsa.stattools.adfuller(logdiff1)
print("ADF test result on Difference shows test statistic is %f \
and p-value is %f" % (adftest[:2]))
print("ADF test result on Log Difference shows test statistic is %f \
and p-value is %f" % (adftestlog[:2]))

with warnings.catch_warnings():
    warnings.filterwarnings("ignore")
    kpsstest = sm.tsa.stattools.kpss(diff1)
    kpsstestlog = sm.tsa.stattools.kpss(logdiff1)

print("KPSS test result on Difference shows test statistic is %f \
and p-value is %f" % (kpsstest[:2]))
print("KPSS test result on Log difference shows test statistic is %f \
and p-value is %f" % (kpsstestlog[:2]))
"""
ADF test result on Difference shows test statistic is -3.045022 and p-value is 0.030898
ADF test result on Log Difference shows test statistic is -2.706950 and p-value is 0.072843
KPSS test result on Difference shows test statistic is 0.078160 and p-value is 0.100000
KPSS test result on Log difference shows test statistic is 0.059560 and p-value is 0.100000
除了ADF检验对原数据直接取一阶差分的情况刚好通过平稳性检验，KPSS检验两个差分数据都没通过平稳性检验，而对数差分数据没有通过ADF检验
"""

# # 可视化ACF, PACF
fig, ax = plt.subplots()
ax1 = fig.add_subplot(221)
sm.graphics.tsa.plot_acf(diff1, ax=ax1);

ax2 = fig.add_subplot(222)
sm.graphics.tsa.plot_pacf(diff1, ax=ax2);

ax3 = fig.add_subplot(223)
sm.graphics.tsa.plot_acf(logdiff1, ax=ax3);

ax4 = fig.add_subplot(224)
sm.graphics.tsa.plot_pacf(logdiff1, ax=ax4);

plt.savefig('./data/TimeSeries/ACF_PACF_diff1.png')
plt.show()

plt.close()
```

## 长江汉口数据

### ARIMA

```python
"""
在使用ARIMA模型进行建模是，标准步骤如下
1.首先对示例数据进行标准分析，包括识别其平稳性以及是否是随机行走或者具有单位根问题
2.使用周期图法来识别季节性
3.对于去除季节性的数据，通过ACF和PACF函数提供的信息得到自回归和移动平均部分所需的滞后项个数。这些数据用于对ARIMA(p,d,q)模型的参数进行标定
4.然后对时间序列数据进行拟合，并得到相应的检验量
5.对残差检验Q统计量和JB统计量以及计算ACF和PACF函数，确定没有额外的信息游离于模型之外
6.最后对样本外的测试数据进行预测并检验模型的准确度

使用LSTM模型对时间序列建模时，1、2、4步骤相同，其他变化
1.首先对示例数据进行标准分析，包括识别其平稳性以及是否是随机行走或者具有单位根问题
2.使用周期图法来识别季节性
3.对于去除季节性的数据，通过ACF和PACF函数提供的信息得到建模所需包含的滞后项个数，包括在LSTM模型中需要将多久以前的信息带入当期
4.对数据进行处理，使其符合keras的LSTM模型的API要求
5.拟合多种不通结构的LSTM模型并比较其在样本内数据上的表现
6.对残差计算ACF和PACF函数，确定没有额外的信息游离于模型之外
7.最后对样本外的数据进行预测，并检验其表现
"""

"""
下面对长江汉口月度水量使用传统的SARIMA模型进行建模
"""


def test_stationarity(timeseries, window=12):
    """
    检验数据是否具有平稳性，并分析是否需要进行相应的操作以获得平稳想
    :param timeseries:时间序列数据
    :param window:
    :return:
    """
    df = pd.DataFrame(timeseries)
    df['Rolling.Mean'] = timeseries.rolling(window=window).mean()
    df['Rolling.Std'] = timeseries.rolling(window=window).std()
    adftest = sm.tsa.stattools.adfuller(timeseries)
    adfoutput = pd.Series(adftest[0:4], index=['统计量', 'p-值 ', '滞后量', '观测值数量'])
    for key, value in adftest[4].items():
        adfoutput['临界值 (%s)' % key] = value
    return (adfoutput, df)


# 将数据分为训练集和测试集
cutoff = 24
train = df1.WaterFlow[:-cutoff]  # 训练集
test = df1.WaterFlow[-cutoff:]  # 测试集
startYear = '1960'
endYear = '1975'

# 检验平稳性
fig = plt.figure()
ax0 = fig.add_subplot(221)
adftest, dftest0 = test_stationarity(train)
dftest0.plot(ax=ax0)
print('原始数据平稳性检验')
print(adftest)

ax1 = fig.add_subplot(222)
adftest, dftest1 = test_stationarity(train[startYear:endYear])
dftest1.plot(ax=ax1)
print('局部数据平稳性检验')
print(adftest)
"""
虽然Dicky-Fully检验的统计量显著表明，不论是真个训练集还是所选取的局部，对于统计测试都显得是平稳的，但是仔细观察移动平均和移动均方差，发现
其波动幅度还是很大的，并且具有非常强的季节性。
"""


def CalculateCycle(ts, lags=36):
    """
    计算季节性的周期，侦测季节性周期使用ACF函数，对原始数据的ACF序列金蒜周期图法，
    通常在周期的时间点上有高度的能量集中，从而能够识别周期长度
    :param ts: 时间序列数据
    :param lags:
    :return:
    """
    acf_x, acf_ci = acf(ts, alpha=0.05, nlags=lags)
    fs = 1
    f, Pxx_den = signal.periodogram(acf_x, fs)

    index = peak.indexes(Pxx_den)
    cycle = (1 / f[index[0]]).astype(int)
    fig = plt.figure()
    ax0 = fig.add_subplot(111)
    plt.vlines(f, 0, Pxx_den)
    plt.axhline(y=0)
    plt.plot(f[index], Pxx_den[index], marker='o', linestyle='none', color='red')
    plt.title("Identified Cycle of %i" % (cycle))
    plt.xlabel('frequency [Hz]')
    plt.ylabel('PSD [V**2/Hz]')
    plt.savefig('./data/TimeSeries/CalculateCycle.png')
    plt.show()
    return (index, f, Pxx_den)


# 对原始数据计算周期性
CalculateCycle(train)
"""
发现周期间隔为12个月，展示了对ACF运营周期图法找季节性周期的可靠性
"""

# 去除季节性周期后检验平稳性
Seasonality = 12
waterFlowS12 = train.diff(Seasonality)[Seasonality:]
waterFlowS12d1 = waterFlowS12.diff(1)[1:]
adftestS12 = sm.tsa.stattools.adfuller(waterFlowS12)
print("ADF test result shows test statistic is %f and p-value is %f" % (adftestS12[:2]))

nlag = 36
xvalues = np.arange(nlag + 1)

acfS12, confiS12 = sm.tsa.stattools.acf(waterFlowS12, nlags=nlag, alpha=0.05, fft=False)
confiS12 = confiS12 - confiS12.mean(1)[:, None]

fig = plt.figure()
ax0 = fig.add_subplot(221)
waterFlowS12.plot(ax=ax0)

ax1 = fig.add_subplot(222)
sm.graphics.tsa.plot_acf(waterFlowS12, lags=nlag, ax=ax1)
plt.show()
"""
去除季节性的数据图像显示这个时间序列有非常强饿均值回归行为，ACF图显示为逐渐递减的序列直到第12个滞后项，但是12的倍数滞后项都没有显著的数据值，
说明两点：首先将数据去除季节性是比较成功的，其次去掉季节性的数据仍然需要再做一阶差分
"""
# 一阶差分以后的ACF和PACF图
fig = plt.figure()
ax0 = fig.add_subplot(221)
sm.graphics.tsa.plot_acf(waterFlowS12d1, ax=ax0, lags=48)
ax1 = fig.add_subplot(222)
sm.graphics.tsa.plot_pacf(waterFlowS12d1, ax=ax1, lags=48)
plt.show()
"""
ACF图表明可能需要1个季节性预测误差滞后项。表明需要一个季节性ARIMA，即SARIMA(p,d,q)(P,D,Q,S)模型
"""
# 拟合SARIMA模型
arima_order1 = (0, 1, 0)
season_order1 = (0, 1, 1, 12)
mod1 = sm.tsa.statespace.SARIMAX(train, trend='n', order=arima_order1, seasonal_order=season_order1).fit()
pred = mod1.predict()
print(mod1.summary())  # 展示拟合结果

# 查看样本内数据的结果，包括模型检验的结果
subtrain = train['1960':'1970']
MAPE = (np.abs(train - pred) / train).mean()
subMAPE = (np.abs(subtrain - pred['1960':'1970']) / train).mean()

fig = plt.figure()
ax0 = fig.add_subplot(211)
plt.plot(pred, label='Fitted');
plt.plot(train, color='red', label='Original')
plt.legend(loc='best')
plt.title("SARIMA %s%s Model, MAPE = %.4f" % (arima_order1, season_order1, MAPE))

ax1 = fig.add_subplot(212)
plt.plot(pred['1960':'1970'], label='Fitted');
plt.plot(subtrain, color='red', label='Original')
plt.legend(loc='best')
plt.title("Details from 1960 to 1970, MAPE = %.4f" % subMAPE)
plt.show()
"""
测试了添加一个季节性自回归项，或者添加一个普通的自回归项/移动平均项的SARIMA模型，其结果都没有当前的模型好，MAPE的值分别上升19.1%和19.8%。
只有当同时添加一个普通自回归项和一个普通移动平均项，即SARIMA(1,1,1)(0,1,1,12)模型，样本内的数据的MAPE值降为17.2%
"""
# 测试不同参数的SARIMA模型
arima_order2 = (1, 1, 1)
season_order2 = (0, 1, 1, 12)
mod2 = sm.tsa.statespace.SARIMAX(train, trend='n', order=arima_order1, seasonal_order=season_order1).fit()
forecast1 = mod1.predict(start='1976-12-01', end='1978', dynamic=True)
forecast2 = mod2.predict(start='1976-12-01', end='1978', dynamic=True)
MAPE1 = ((test - forecast1).abs() / test).mean() * 100
MAPE2 = ((test - forecast2).abs() / test).mean() * 100

plt.plot(test, color='black', label='Original')
plt.plot(forecast1, color='green', label='Model 1 : SARIMA' + str(arima_order1) + str(season_order1))
plt.plot(forecast2, color='red', label='Model 2 : SARIMA' + str(arima_order2) + str(season_order2))
plt.legend(loc='best')
plt.title('Model 1 MAPE=%.f%%; Model 2 MAPE=%.f%%' % (MAPE1, MAPE2))
"""
两个SARIMA模型在最后的预测上没有本质的区别，几乎重合，因此倾向于保留比较简单、更稳定的SARIMA(0,1,0)(0,1,1,12)模型
"""
```

### 深度学习

```python
"""
下面使用深度学习的LSTM模型对流量数据进行建模。
1.将数据标准化，可以使用z-score法，也可以将数据纳入[0,1]中
2.按照需要的神经网络模型构造数据格式。LSTM的输入的自变量数据[样本数，时间步，特征变量数]，因变量[样本数，前进时间步]
3.按照keras要求定义神经网络，比如对时间序列模型一般要定义一个序列模型(Sequential)，通常是多个网络层的线性堆叠，因此需要在这个模块中添加不同的神经网络层，
一般是先加一个LSTM层作为输入信息和隐藏状态的桥梁，再加一个全连接层(Dense)来链接隐藏状态和输出信息
"""

#  首先定义数据生成函数
def create_dataset(dataset, timestep=1, look_back=1, look_ahead=1):
    ds = dataset.reshape(-1, 1)
    dataX = lagmat(dataset, maxlag=timestep * look_back, trim="both", original='ex')
    dataY = lagmat(dataset[(timestep * look_back):], maxlag=look_ahead, trim="backward", original='ex')
    # reshape and remove redundent rows
    dataX = dataX.reshape(dataX.shape[0], timestep, look_back)[:-(look_ahead - 1)]
    return np.array(dataX), np.array(dataY[:-(look_ahead - 1)])

# 检验该函数的正确性
temp = np.arange(100) + 1
tempX, tempY = create_dataset(temp, timestep=3, look_back=2, look_ahead=2)
print(tempY[-1, :])
print(tempX[-1, :, :])

# 进行数据准备工作
scaler = MinMaxScaler(feature_range=(0, 1))
trainstd = scaler.fit_transform(train.values.astype(float).reshape(-1, 1))
teststd = scaler.transform(test.values.astype(float).reshape(-1, 1))

lookback = 60
lookahead = 24
timestep = 1
trainX, trainY = create_dataset(trainstd, timestep=1, look_back=lookback, look_ahead=lookahead)
trainX = trainX.astype('float32')
trainY = trainY.astype('float32')

# 定义并训练我们的简单LSTM模型
# define LSTM model
batch_size = 1  # 一般来说，批量数越小，在其他参数不变的情况下拟合效果越好，但是时间也越长，过拟合风险增大
model = kModels.Sequential()
model.add(kLayers.LSTM(48, batch_size=batch_size, input_shape=(1, lookback), kernel_initializer='he_uniform'))
model.add(kLayers.Dense(lookahead))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=20, batch_size=batch_size, verbose=1)  # verbose设为0时，要求不显示拟合过程的输出状态，
# 当为1时，则会显示最终的拟合结果，若为2时，则会将每次迭代的结果显示出来。在批处理下，会显示一个字符形式的进度条

# 下面使用训练后得到的模型进行预测并显示预测结果
# visual
feedData = scaler.transform(df1.WaterFlow['1972':'1976'].values.reshape(-1, 1)).copy()
feedX = (feedData).reshape(1, 1, lookback)
feedX = (feedX).astype('float32')
prediction1 = model.predict(feedX)

predictionRaw = scaler.inverse_transform(prediction1.reshape(-1, 1))
actual1 = df1.WaterFlow['1977':'1978'].copy().values.reshape(-1, 1)
MAPE = (np.abs(predictionRaw - actual1) / actual1).mean()

plt.plot(predictionRaw, label='Prediction')
plt.plot(actual1, label='Actual')
plt.title("MAPE = %.4f" % MAPE)
plt.legend(loc='best')
plt.xlim((0, 23))
plt.xlabel("Month")
plt.show()
"""
预测的MAPE的值只有24%，比SARMIMA的模型的35%要低很多，拟合的曲线更加平滑。
实验显示，一个简单的LSTM模型在拟合这种周期性很强的时间序列上具备较好的性能，尤其是不需要建模统计师具体分析周期的多少，然后再对自回归项和
移动平均项参数进行选择，从而大大降低了建模的难度。分析师可以直接对几个关键参数进行逐一筛选，从而可以有效提高工作效率
"""

# 叠加LSTM模型
# 希望不同的LSTM层能捕捉不通的波动。但是容易过拟合，并不一定比单层的好。
# create and fit the Stacked LSTM network
batch_size = 100
model2 = kModels.Sequential()
model2.add(kLayers.LSTM(96, batch_size=batch_size, input_shape=(1, lookback), return_sequences=True))
# return_sequences指定将上一次计算的输出返回到下一层数据，还是将原始的整个序列返回。设置为True，表示将原始的整个序列返回，而不是计算
# 出来的序列供下一层使用
model2.add(kLayers.Dropout(0.1))  # 防止过拟合
model2.add(kLayers.LSTM(48))
# return_sequences默认为False，表示最后一个LSTM层里不返回原始的序列数据，而是将计算出的序列数据供输出层或全连接层使用
model2.add(kLayers.Dense(lookahead))
model2.compile(loss='mape', optimizer='adam')
model2.fit(trainX, trainY, epochs=15, batch_size=batch_size, verbose=1)

# visual
feedData = df1.WaterFlow['1972':'1976'].copy()
feedX = scaler.transform(feedData.values.reshape(-1, 1)).reshape(1, 1, lookback).astype('float32')
prediction2 = model2.predict(feedX)
predictionRaw = scaler.inverse_transform(prediction2.reshape(-1, 1))
actual1 = df1.WaterFlow['1977':'1978'].copy().values.reshape(-1, 1)
MAPE = (np.abs(predictionRaw - actual1) / actual1).mean()

plt.plot(predictionRaw, label='Prediction')
plt.plot(actual1, label='Actual')
plt.title("MAPE = %.4f" % MAPE)
plt.legend(loc='best')
plt.xlim((0, 23))
plt.xlabel("Month")
plt.show()
"""
预测效果与简单的单层LSTM的模型差不多，MAPE略低于24%，没有显著差异。造成这种结果的原因可能有两种：一种是这个模型迭代次数过多，有过拟合；
另一种是需要更多LSTM层来抽取更为细节的信息。
"""

# 不同程度的叠加LSTM，验证上面可能的原因
# stacked LSTM
def SLSTM(epoch=10, stacks=1, batchsize=5):
    """
    可以控制多个LSTM层的叠加数量，也可以控制迭代的次数和批量数的大小
    :param epoch:
    :param stacks:
    :param batchsize:
    :return:
    """
    batch_size = batchsize
    model2 = kModels.Sequential()
    model2.add(kLayers.LSTM(48, batch_size=batchsize, input_shape=(1, lookback), return_sequences=True))
    model2.add(kLayers.Dropout(0.1))
    for i in range(stacks - 1):
        # 在第一层LSTM之外额外增加两层LSTM，每层都有10%的Dropout比率来控制过度拟合，最后用全连接层连接输出层
        model2.add(kLayers.LSTM(32, return_sequences=True))
        model2.add(kLayers.Dropout(0.1))
        model2.add(kLayers.LSTM(32, return_sequences=False))
        model2.add(kLayers.Dense(lookahead))
        model2.compile(loss='mape', optimizer='adam')
        t0 = time()
        model2.fit(trainX, trainY, epochs=epoch, batch_size=batch_size, verbose=1)

        feedData = df1.WaterFlow['1972':'1976'].copy()
        feedX = scaler.transform(feedData.values.reshape(-1, 1)).reshape(1, 1, lookback).astype('float32')
        prediction2 = model2.predict(feedX)
        predictionRaw = scaler.inverse_transform(prediction2.reshape(-1, 1))
        actual1 = df1.WaterFlow['1977':'1978'].copy().values.reshape(-1, 1)
        deltatime = time() - t0
        MAPE = (np.abs(predictionRaw - actual1) / actual1).mean()
        print("Epoch= %.1f, MAPE=%.5f, 消耗时间=%.4f 秒" % (epoch, MAPE, deltatime))

# 实验不同的迭代次数对结果的影响
for epoch in [4, 5, 6, 7, 8, 9, 10]:
    SLSTM(epoch, stacks=2, batchsize=5)

"""
通过增加LSTM模型叠加的层数，确实可以让模型更快地学习数据的模式，但是在使用叠加层数的LSTM模型时，需要适当降低迭代的次数，并通过Dropout等
技术来防止过度拟合
"""
```

## 国航旅客数据

### ARIMA

```python
"""
在使用ARIMA模型进行建模是，标准步骤如下
1.首先对示例数据进行标准分析，包括识别其平稳性以及是否是随机行走或者具有单位根问题
2.使用周期图法来识别季节性
3.对于去除季节性的数据，通过ACF和PACF函数提供的信息得到自回归和移动平均部分所需的滞后项个数。这些数据用于对ARIMA(p,d,q)模型的参数进行标定
4.然后对时间序列数据进行拟合，并得到相应的检验量
5.对残差检验Q统计量和JB统计量以及计算ACF和PACF函数，确定没有额外的信息游离于模型之外
6.最后对样本外的测试数据进行预测并检验模型的准确度

使用LSTM模型对时间序列建模时，1、2、4步骤相同，其他变化
1.首先对示例数据进行标准分析，包括识别其平稳性以及是否是随机行走或者具有单位根问题
2.使用周期图法来识别季节性
3.对于去除季节性的数据，通过ACF和PACF函数提供的信息得到建模所需包含的滞后项个数，包括在LSTM模型中需要将多久以前的信息带入当期
4.对数据进行处理，使其符合keras的LSTM模型的API要求
5.拟合多种不通结构的LSTM模型并比较其在样本内数据上的表现
6.对残差计算ACF和PACF函数，确定没有额外的信息游离于模型之外
7.最后对样本外的数据进行预测，并检验其表现
"""

"""
下面我们使用国际航空旅客数量作为例子来展示ARIMA模型的建模过程。使用这个数据是因为从图像上看这个数据具有很强的趋势和周期性，因此能够充分
展示建模的不同步骤。
"""


def test_stationarity(timeseries, window=12):
    """
    检验数据是否具有平稳性，并分析是否需要进行相应的操作以获得平稳想
    :param timeseries:时间序列数据
    :param window:
    :return:
    """
    df = pd.DataFrame(timeseries)
    df['Rolling.Mean'] = timeseries.rolling(window=window).mean()
    df['Rolling.Std'] = timeseries.rolling(window=window).std()
    adftest = sm.tsa.stattools.adfuller(timeseries)
    adfoutput = pd.Series(adftest[0:4], index=['统计量', 'p-值 ', '滞后量', '观测值数量'])
    for key, value in adftest[4].items():
        adfoutput['临界值 (%s)' % key] = value
    return (adfoutput, df)


# 验证数据平稳性
cutoff = 21
train2 = df2.Passenger[:-cutoff]
test2 = df2.Passenger[-cutoff:]

fig = plt.figure()
ax0 = fig.add_subplot(221)
adftest, dftest0 = test_stationarity(train2)
dftest0.plot(ax=ax0)
print('原始数据平稳性检验')
print(adftest)

ax1 = fig.add_subplot(222)
adftest, dftest1 = test_stationarity(train2['1955':'1960'])
dftest1.plot(ax=ax1)
print('局部数据平稳性检验')


def CalculateCycle(ts, lags=36):
    """
    计算季节性的周期，侦测季节性周期使用ACF函数，对原始数据的ACF序列金蒜周期图法，
    通常在周期的时间点上有高度的能量集中，从而能够识别周期长度
    :param ts: 时间序列数据
    :param lags:
    :return:
    """
    acf_x, acf_ci = acf(ts, alpha=0.05, nlags=lags)
    fs = 1
    f, Pxx_den = signal.periodogram(acf_x, fs)

    index = peak.indexes(Pxx_den)
    cycle = (1 / f[index[0]]).astype(int)
    fig = plt.figure()
    ax0 = fig.add_subplot(111)
    plt.vlines(f, 0, Pxx_den)
    plt.axhline(y=0)
    plt.plot(f[index], Pxx_den[index], marker='o', linestyle='none', color='red')
    plt.title("Identified Cycle of %i" % (cycle))
    plt.xlabel('frequency [Hz]')
    plt.ylabel('PSD [V**2/Hz]')
    plt.savefig('./data/TimeSeries/CalculateCycle.png')
    plt.show()
    return (index, f, Pxx_den)


# 识别周期性
index, f, Power = CalculateCycle(train2)
"""
在数据不平稳的情况下，侦测效果不好。这个数据明显在12个月左右，但是结果显示37个月。
这表明要使用周期图法来侦测周期性，至少要求数据没有明显的趋势性
"""
# 进行一阶差分将趋势性去掉
train2d1 = train2.diff(1)[1:]
index, f, Power = CalculateCycle(train2d1)
"""
即使差分过后的数据仍然存在异方差性，周期图法也能比较容易发现数据的周期为12。
目前看来，异方差性如果是单调增减的，那么对数据的周期性侦测影响不大
"""

season = 12
train2d1s12 = train2d1.diff(season)[season:]

nlags = 48
fig = plt.figure()
ax0 = fig.add_subplot(221)
sm.graphics.tsa.plot_acf(train2d1s12, ax=ax0, lags=48)
ax1 = fig.add_subplot(222)
sm.graphics.tsa.plot_pacf(train2d1s12, ax=ax1, lags=48)
plt.show()
"""
显示其不具备任何显著的自回归或者移动平均项，或者最多使用一个一阶自回归项即可。
因此随遇SARIMA模型的参数，可以设定为季节性部分参数为(1,1,0,12)，对于非季节性部分的参数设置为(0,1,0)
"""

# 下面来拟合SARIMA模型
# fit a seasonal ARIMA model
arima_order3 = (0, 1, 0)
season_order3 = (1, 1, 0, 12)
mod1 = sm.tsa.statespace.SARIMAX(train2, trend='c', order=arima_order3, seasonal_order=season_order3).fit()
pred = mod1.predict()
print(mod1.summary())

subtrain = train2['1955':'1956']
MAPE = (np.abs(train2 - pred) / train2).mean()
subMAPE = (np.abs(subtrain - pred['1955':'1956']) / train2).mean()

fig = plt.figure()
ax0 = fig.add_subplot(221)
plt.plot(pred, label='Fitted')
plt.plot(train2, color='red', label='Original')
plt.legend(loc='best')
plt.title("SARIMA%s%s Model, MAPE = %.4f" % (arima_order3, season_order3, MAPE))

ax1 = fig.add_subplot(222)
plt.plot(pred['1955':'1956'], label='Fitted')
plt.plot(subtrain, color='red', label='Original')
plt.legend(loc='best')
plt.title("Details from 1955 to 1956, MAPE = %.4f" % subMAPE)

plt.savefig("./data/TimeSeries/Flight_SARIMA_plot.png")
plt.show()

forecast1 = mod1.predict(start='1958-12-01', end='1960-09-01', dynamic=True)
MAPE1 = ((test2 - forecast1[1:]).abs() / test2).mean() * 100
print(MAPE1)

plt.plot(df2, color='black', label='Original')
plt.plot(forecast1, color='green', label='Model 1 : SARIMA' + str(arima_order3) + str(season_order3))
plt.legend(loc='best')
plt.title('Model 1 MAPE=%.f%%;' % (MAPE1))

plt.savefig("./data/TimeSeries/Flight_SARIMA_pred.png")
"""
拟合效果较好，对于训练集，其综合MAPE仅为5%左右，而局部MAPE值甚至只有2.7%.
测试数据与预测数据对比表明，MAPE值为12.4%，显示SARIMA模型有一定过度拟合的可能。
误差主要原因是预测的数据不能有效地拟合乘客数量不停增长的趋势。这个趋势对于这个数据而言其实表现为异方差性随时间而增大，因为一阶差分以后的数据
总平均值保持在一个接近零的水平，且不随时间而变动，只有数据的波动随时间增大
"""


# 使用消除异方差的数据建模
train2log = np.log(train2)
test2log = np.log(test2)

train2logd1s12 = (train2log.diff(1)[1:]).diff(12)[12:]
fig = plt.figure()
ax0 = fig.add_subplot(221)
sm.graphics.tsa.plot_acf(train2logd1s12, ax=ax0, lags=48)

ax1 = fig.add_subplot(222)
sm.graphics.tsa.plot_pacf(train2logd1s12, ax=ax1, lags=48)
plt.savefig("./data/TimeSeries/Flight_log_ACF_PACF.png")
plt.show()
plt.close()

mod1 = sm.tsa.statespace.SARIMAX(train2log, trend='n', order=(0, 1, 0), seasonal_order=(2, 1, 1, 12)).fit()
pred = mod1.predict()
print(mod1.summary())

forecast1 = mod1.predict(start='1958-12-01', end='1960-09-01', dynamic=True)
forecast1 = np.exp(forecast1)
MAPE1 = ((test2 - forecast1[1:]).abs() / test2).mean() * 100
print(MAPE1)

plt.plot(df2, color='black', label='Original')
plt.plot(forecast1, color='green', label='Model 1 : SARIMA' + str(arima_order3) + str(season_order3))
plt.legend(loc='best')
plt.title('Model 1 MAPE=%.f%%;' % (MAPE1))

plt.savefig("./data/TimeSeries/Flight_log_SARIMA_pred.png")
plt.show()
plt.close()
"""
消除异方差性后的差分平稳性很好，12个月的周期在ACF和PACF图上都明显显示，而且都表现出更为明显的二阶自回归和一阶移动平均要求。
因此ASRIMA模型在季节性参数上使用(2,1,1,12)而不是原来的(1,1,0,12)。预测数据在重新返回到原始的尺度上后，与实际数据比较的MAPE
值现在降低到仅为5%。相对于不消除异方差性的情况准确度提高了一倍，效果显著。并且现在的预测数据有效地体现乘客数量平均水平和波动幅度
随时间增大的情况
"""
```

### 深度学习

```python
"""
下面为LSTM模型准备数据
"""


#  首先定义数据生成函数
def create_dataset(dataset, timestep=1, look_back=1, look_ahead=1):
    ds = dataset.reshape(-1, 1)
    dataX = lagmat(dataset, maxlag=timestep * look_back, trim="both", original='ex')
    dataY = lagmat(dataset[(timestep * look_back):], maxlag=look_ahead, trim="backward", original='ex')
    # reshape and remove redundent rows
    dataX = dataX.reshape(dataX.shape[0], timestep, look_back)[:-(look_ahead - 1)]
    return np.array(dataX), np.array(dataY[:-(look_ahead - 1)])


scaler = MinMaxScaler(feature_range=(0, 1))
trainstd2 = scaler.fit_transform(train2.values.astype(float).reshape(-1, 1))
teststd2 = scaler.transform(test2.values.astype(float).reshape(-1, 1))
lookback = 60
lookahead = 24
timestep = 1
trainX2, trainY2 = create_dataset(trainstd2, timestep=1, look_back=lookback, look_ahead=lookahead)
trainX2 = trainX2.astype('float32')
trainY2 = trainY2.astype('float32')

# build LSTM
batch_size = 1
model = kModels.Sequential()
model.add(kLayers.LSTM(96, batch_size=batch_size, input_shape=(1, lookback), kernel_initializer='he_uniform'))
# model.add(kLayers.Dense(32))
model.add(kLayers.Dense(lookahead))
# model.compile(loss='mean_squared_error', optimizer='adam')
model.compile(loss='mape', optimizer='adam')
model.fit(trainX2, trainY2, epochs=30, batch_size=batch_size, verbose=0)

feedData = scaler.transform(df2.Passenger['1954-01-01':'1958-12-01'].values.reshape(-1, 1)).copy()
feedX = (feedData).reshape(1, 1, lookback)
feedX = (feedX).astype('float32')
prediction1 = model.predict(feedX)
# prediction1.shape

predictionRaw = scaler.inverse_transform(prediction1.reshape(-1, 1))[:-2]
# predictionRaw = (prediction1.reshape(-1, 1))
actual1 = df2.Passenger['1958-12-01':'1960-09-01'].copy().values.reshape(-1, 1)
MAPE = (np.abs(predictionRaw - actual1) / actual1).mean()
plt.plot(actual1, label='Actual')
plt.plot(predictionRaw, label='Prediction')
plt.title("MAPE = %.4f" % MAPE)
plt.legend(loc='best')
plt.xlim((0, 21))
plt.xlabel("Month")

plt.savefig("./data/TimeSeries/Flight_LSTM_pred.png")
plt.show()

predAll = df2.Passenger * np.nan
predAll[-22:] = predictionRaw.reshape(-1)
plt.plot(df2.Passenger)
plt.plot(predAll)
plt.show()

# 使用消除异方差的数据建模
train2log = np.log(train2)
test2log = np.log(test2)

train2logd1s12 = (train2log.diff(1)[1:]).diff(12)[12:]
fig = plt.figure()
ax0 = fig.add_subplot(221)
sm.graphics.tsa.plot_acf(train2logd1s12, ax=ax0, lags=48)

ax1 = fig.add_subplot(222)
sm.graphics.tsa.plot_pacf(train2logd1s12, ax=ax1, lags=48)
plt.savefig(".././data/timeseries/Flight_log_ACF_PACF.png")
plt.show()
plt.close()

mod1 = sm.tsa.statespace.SARIMAX(train2log, trend='n', order=(0, 1, 0), seasonal_order=(2, 1, 1, 12)).fit()
pred = mod1.predict()
print(mod1.summary())

forecast1 = mod1.predict(start='1958-12-01', end='1960-09-01', dynamic=True)
forecast1 = np.exp(forecast1)
MAPE1 = ((test2 - forecast1[1:]).abs() / test2).mean() * 100
print(MAPE1)

plt.plot(df2, color='black', label='Original')
plt.plot(forecast1, color='green', label='Model 1 : SARIMA' + str(arima_order3) + str(season_order3))
plt.legend(loc='best')
plt.title('Model 1 MAPE=%.f%%;' % (MAPE1))

plt.savefig("./data/TimeSeries/Flight_log_SARIMA_pred.png")
plt.show()
plt.close()

scaler2 = MinMaxScaler(feature_range=(0, 1))
trainlogstd2 = scaler2.fit_transform(train2log.values.astype(float).reshape(-1, 1))
testlogstd2 = scaler2.transform(test2log.values.astype(float).reshape(-1, 1))

lookback = 60
lookahead = 24
timestep = 1,
trainlogX2, trainlogY2 = create_dataset(trainlogstd2, timestep=1, look_back=lookback, look_ahead=lookahead)
trainlogX2 = trainlogX2.astype('float32')
trainlogY2 = trainlogY2.astype('float32')

batch_size = 10
model = kModels.Sequential()
model.add(kLayers.LSTM(96, input_shape=(1, lookback), kernel_initializer='he_uniform'))
model.add(kLayers.Dense(lookahead))
model.compile(loss='mape', optimizer='adam')
model.fit(trainlogX2, trainlogY2, epochs=60, batch_size=batch_size, verbose=1)

# 对数变换以后深度学习模型的预测效果较差。

feedData = df2.Passenger['1954-01-01':'1958-12-01'].values.reshape(-1, 1).copy()
feedData = np.log(feedData)
feedData = scaler2.transform(feedData)
feedX = (feedData).reshape(1, 1, lookback).astype('float32')
prediction1 = model.predict(feedX)
# prediction1.shape

prediction1 = scaler2.inverse_transform(prediction1.reshape(-1, 1))[:-2]
# predictionRaw = (prediction1).reshape(-1, 1)
predictionRaw = np.exp(prediction1.reshape(-1, 1))
actual1 = df2.Passenger['1958-12-01':'1960-09-01'].copy().values.reshape(-1, 1)
MAPE = (np.abs(predictionRaw[:] - actual1) / actual1).mean()
plt.plot(actual1, label='Actual')
plt.plot(predictionRaw, label='Prediction')
plt.title("MAPE = %.4f" % MAPE)
plt.legend(loc='best')
plt.xlim((0, 21))
plt.xlabel("Month")
plt.show()

predAll = df2.Passenger * np.nan
predAll[-22:] = predictionRaw.reshape(-1)
plt.plot(df2.Passenger)
plt.plot(predAll)
plt.title("MAPE = %.4f" % MAPE)
plt.show()


# 使用消除异方差的数据建模
train2log = np.log(train2)
test2log = np.log(test2)

scaler2 = MinMaxScaler(feature_range=(0, 1))
trainlogstd2 = scaler2.fit_transform(train2log.values.astype(float).reshape(-1, 1))
testlogstd2 = scaler2.transform(test2log.values.astype(float).reshape(-1, 1))

lookback = 60
lookahead = 24
timestep = 1,
trainlogX2, trainlogY2 = create_dataset(trainlogstd2, timestep=1, look_back=lookback, look_ahead=lookahead)
trainlogX2 = trainlogX2.astype('float32')
trainlogY2 = trainlogY2.astype('float32')

batch_size = 10
model = kModels.Sequential()
model.add(kLayers.LSTM(96, input_shape=(1, lookback), kernel_initializer='he_uniform'))
model.add(kLayers.Dense(lookahead))
model.compile(loss='mape', optimizer='adam')
model.fit(trainlogX2, trainlogY2, epochs=60, batch_size=batch_size, verbose=1)

# 对数变换以后深度学习模型的预测效果较差。

feedData = df2.Passenger['1954-01-01':'1958-12-01'].values.reshape(-1, 1).copy()
feedData = np.log(feedData)
feedData = scaler2.transform(feedData)
feedX = (feedData).reshape(1, 1, lookback).astype('float32')
prediction1 = model.predict(feedX)
# prediction1.shape

prediction1 = scaler2.inverse_transform(prediction1.reshape(-1, 1))[:-2]
# predictionRaw = (prediction1).reshape(-1, 1)
predictionRaw = np.exp(prediction1.reshape(-1, 1))
actual1 = df2.Passenger['1958-12-01':'1960-09-01'].copy().values.reshape(-1, 1)
MAPE = (np.abs(predictionRaw[:] - actual1) / actual1).mean()
plt.plot(actual1, label='Actual')
plt.plot(predictionRaw, label='Prediction')
plt.title("MAPE = %.4f" % MAPE)
plt.legend(loc='best')
plt.xlim((0, 21))
plt.xlabel("Month")
plt.show()

predAll = df2.Passenger * np.nan
predAll[-22:] = predictionRaw.reshape(-1)
plt.plot(df2.Passenger)
plt.plot(predAll)
plt.title("MAPE = %.4f" % MAPE)
plt.show()
"""
对原始数据进行非线性处理之后，深度学习模型的预测能力退化较大，无论是单层还是多层LSTM模型，在数据的预测上都出现了较大的偏差。这显示在时间序列建模中，如果要使用深度学习算法，则保持原有数据的相对比例很重。
"""
```

