# Tensorflow

## 概述

数据模型：Tensor，计算模型：Graph，运行模型：Session

图结构：数据(tensor)+操作(operation)

安装

```python
# 注意版本号与python的对应关系
pip install tensorflow==1.8.0
```

引用

```python
import tensorflow as tf

# 在tensoflow2下使用v1时需加声明
tf.compat.v1.disable_eager_execution()
```

一般流程

```
1.导入/生成样本数据集
2.转换和归一化数据
3.划分样本数据集为训练样本集、测试样本集和验证样本集
4.设置机器学习参数
5.初始化变量和占位符
6.定义模型结构
7.创建损失函数
8.初始化模型和训练模型
9.评估机器学习模型
10.调优超参数
11.分布/预测结果
```

## 组件

###张量

Tensorflow的主要数据结构是张量，它用张量来操作计算图。在Tensorflow里可以把变量或占位符声明为张量。

张量就是一个n维数组，类型为`tf.Tensor`。

- 创建张量

```python
# 固定值张量
tf.zeros(shape, dtype=tf.float32, name=None)  # 创建所有元素为零的张量
tf.ones(shape, dtype=tf.float32, name=None)  # 创建所有元素为1的张量
tf.fill(dims, value, name=None)  # 创建一个相撞为dims，并填充了标量值的张量
tf.constant(value, dtype=None, shape=None, name='Const')  # 创建一个常数张量

# 形状相似的张量
tf.zeros_like(tensor, dtype=tf.float32, name=None)  # 创建与指定tensor相同类型和形状的所有元素为零的张量
tf.ones_like(tensor, dtype=None, name=None)  # 创建与指定tensor相同类型和形状的所有元素为1的张量

# 序列张量
tf.linspace(start=0, stop=1, num=3)  # 创建初始为0.0，终值为1.0，等间隔的总数为3的序列张量
tf.range(start=6, limit=15, delta=3)  # 创建初始为6，小于15，间隔为3的序列张量

# 随机张量
tf.random_uniform([row_dim, col_dim], minval=0, maxval=1)  # 均匀分布的随机数，创建值域为[minval, maxval)的随机均匀分布
tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)  # 正态分布的随机数
tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)  # 带有指定边界的正态分布的随机数，其正态分布的随机数位于指定均值到两个标准差之间的区间
tf.random_shuffle(input_tensor)  # 张量/数组的随机化
tf.random_crop(input_tensor, crop_size)  # 对张量指定大小的随机剪裁

# 稀疏张量，类似相性代数里的稀疏矩阵
res = tf.SparseTensor(indices=[[0, 0], [1,2]], values=[1,2], dense_shape=[3,4])

# 不使用内建函数创建张量
tf.convert_to_tensor(value)  # 将任意numpy数组转换为python列表，或将常量转换为一个张量，也接收张量作为输入
```

- 张量的属性

```python
dtype	# 张量中元素的数据类型
shape	# 返回张量的数据形状 
devices # 产生张量的设备的名字
graph	# 包含张量的图
name  	# 张量的字符串名字
op		# 将张量作为输出的操作
```

- Tensor的表示法

```python
Tensor("Mul:0", shape=(), dtype=float32)
类型	 名字	 索引	 形状		 数据类型
```

- 张量的数据类型

| 数据类型     | python类型   | 描述                                               |
| ------------ | ------------ | -------------------------------------------------- |
| DT_FLOAT     | tf.float32   | 32位浮点数                                         |
| DT_DOUBLE    | tf.float64   | 64位浮点数                                         |
| DT_INT64     | tf.int64     | 64位有符号整型                                     |
| DT_INT32     | tf.int32     | 32位有符号整型                                     |
| DT_INT16     | tf.int16     | 16位有符号整型                                     |
| DT_INT8      | tf.int8      | 8位有符号整型                                      |
| DT_UINT8     | tf.uint8     | 8位无符号整型                                      |
| DT_STRING    | tf.string    | 可变长度的字节数组，每一个张量元素都是一个字节数组 |
| DT_BOOL      | tf.bool      | 布尔型                                             |
| DT_COMPLEX64 | tf.complex64 | 由两个32位浮点数组成的复数：实数和虚数             |
| DT_QINT32    | tf.qint32    | 用于量化Ops的32位有符号整型                        |
| DT_QINT8     | tf.qint8     | 用于量化Ops的8位有符号整型                         |
| DT_QUINT8    | tf.quint8    | 用于量化Ops的8位无符号整型                         |

- 张量的阶

| 阶   | 数学实例 | python     | 例子                                                |
| ---- | -------- | ---------- | --------------------------------------------------- |
| 0    | 纯量     | 只有大小   | s=23                                                |
| 1    | 向量     | 大小和方向 | v =[1,2,3]                                          |
| 2    | 矩阵     | 数据表     | m=[[1,2,3],[4,5,6],[7,8,9]]                         |
| 3    | 3阶张量  | 数据立体   | t= [[[2],[4],[6]],[[8],[10],[12]],[[14],[16],[18]]] |
| n    | n阶      | ...        | ...                                                 |

示例

```python
tensor1 = tf.constant(4.0)
tensor2 = tf.constant([1,2,3,4])
linear_squares = tf.constant([[4],[9],[16],[25]], dtype=tf.int32)

print(tensor1)  # Tensor("Const:0", shape=(), dtype=float32)
print(tensor2)  # Tensor("Const_1:0", shape=(4,), dtype=int32)
print(linear_squares)  # Tensor("Const_2:0", shape=(4, 1), dtype=int32)
```
- 张量的变换

类型的改变

```python
tf.string_to_number(string_tensor, out_type=None, name=None)
tf.to_double(x, name='ToDouble')
tf.to_float(x, name='ToFloat')
tf.to_bfloat(x, name='ToBFloat16')
tf.to_int32(x, name='ToInt32')
tf.to_int64(x, name='ToInt64')
tf.cast(x, dtype, name=None)  # 原始不变，返回改变后的tensor
```

形状的改变

```python
# 动态形状
# 动态创建新张量时，元素个数必须匹配
tf.reshape(tensor,shape)  # 原始不变，返回改变后的tensor
# 静态形状
# 转换静态形状时，不能跨阶数改变形状；对于已经固定的张量的静态形状，不能再次设置静态形状
tensor.set_shape(shape)
```

- 张量的数学运算

算数运算符

基本数学函数

矩阵运算

reduce操作

序列索引操作

### 变量/占位符

- 变量

一旦创建好张量，可以通过`tf.Variable()`封装张量为变量。变量是Tensorflow机器学习算法的参数，是表示程序处理的共享持久状态的最佳方法，维护这些变量的状态来优化机器学习算法。

变量的特点：存储持久化、可修改值、可指定被训练

```python
# 创建变量
tf.Variable(initial_value=None, trainable=True, collections=None,name=None)
# 参数
- initial_value：初始化的值
- trainable：是否被训练
- collections: 新变量将添加到列出的图的集合中collections,默认为[GraphKeys.GLOBAL._VARIABLES]，如果trainable是True变量也被添加到图形集合GraphKeys.TRAINABLE_VARIABLES
    
# 使用变量：需要显式初始化，才能运行值
a = tf.Variable(initial_value=50)
b = tf.Variable(initial_value=30)
c = tf.add(a, b)
print(a,b,c)

init = tf.global_variables_initializer()  # 一次性初始化所创建的所有变量
with tf.Session() as sess:
    sess.run(init)
    a_v,b_v,c_v = sess.run([a, b, c])
    print(a_v, b_v, c_v)
    
# 修改变量的命名空间
with tf.name_scope("name"):
    var = tf.Variable(name='var', initial_value=[4], dtype=tf.float32)
    var_double = tf.Variable(name='var', initial_value=[4], dtype=tf.float32)
```

- 占位符

占位符是Tensorflow对象，用于表述输入输出数据的格式，允许传入指定类型和形状的数据，并依赖计算图计算结果。

```python
# 占位符仅仅声明数据位置，用于传入数据到计算图。
data1 = tf.placeholder(tf.float32)
data2 = tf.placeholder(tf.float32)
dataAdd = tf.add(data1, data2)
with tf.Session() as sess:
  print(sess.run(dataAdd, feed_dict={data1:6, data2:2}))  # 在会话中的feed_dict参数获取数据
```

### 操作

一个操作对象（Operation）是TensorFlow图中的一个节点，可以接收0个或多个输入Tensor，并且可以输出0个或者多个Tensor，Operation对象是通过op构造函数(`tf.matmul()`)创建的。

```python
import tensorflow as tf
data1 = tf.constant(6)  # tf.constant是操作函数，输入int值，经过Const操作对象，输出tensor对象data1
data2 = tf.constant(2) 
dataAdd = tf.add(data1, data2)  # tf.add是操作函数，输入是tensor对象data1/data2，经过Add操作对象，输出tensor对象dataAdd
```

- 指令名称

一个图是一个命名空间，一个命名空间中指令名称不能重复；对于新的图，张量相当于重新开始，可以与其他图的指令名称相同

```python
import tensorflow as tf
data1 = tf.constant(6)
print(data1)  # Tensor("Const:0", shape=(), dtype=int32)
```

经过操作对象产生的Tensor名称的形式为`<OP_NAME>:<i>`，其中，`<OP_NAME>`是生成该张量的指令的名称；`<i>`是一个整数，表示该张量在指令的输出中的索引。

```python
# 修改指令名称
a = tf.constant(3, name='a')  # Tensor("a:0", shape=(), dtype=int32)
```

- 常见OP构造函数

| 类型           | 实例                                           |
| -------------- | ---------------------------------------------- |
| 标量运算       | add,sub,mul,div,exp,log,greater,lesse,equal    |
| 向量运算       | concat,slice,splot,constant,rank,shape,shuffle |
| 矩阵运算       | matmul,matrix_inverse,matrix_deteminant        |
| 带状态的运算   | variable,assgin,assginadd                      |
| 神经网络组建   | softmax,sigmod,relu,convolution,max_pool       |
| 存储，恢复     | save,restore                                   |
| 队列及同步运算 | Enqueue,Dequeue,MutexAcquire,MutexRelease      |
| 控制流         | Merge,Switch,Enter,Leave,NextIteration         |

- 示例

常量间

```python
import tensorflow as tf
data1 = tf.constant(6)
data2 = tf.constant(2)
dataAdd = tf.add(data1, data2)  # 加
dataMul = tf.multiply(data1, data2)  # 乘
dataSub = tf.subtract(data1, data2)  # 减
dataDiv = tf.divide(data1, data2) # 除
with tf.Session() as sess:
  print(
    sess.run(dataAdd),
    sess.run(dataMul),
    sess.run(dataSub),
    sess.run(dataDiv)
       )
```

常量与变量

```python
import tensorflow as tf
data1 = tf.constant(6)
data2 = tf.Variable(2)
dataAdd = tf.add(data1, data2)
dataCopy = tf.assign(data2, dataAdd)  # data2 <= dataAdd
dataMul = tf.Multiply(data1, data2)
dataSub = tf.subtract(data1, data2)
dataSiv = tf.divide(data1, data2)
init = tf.global_variables_initializer()
with tf.Session() as sess:
  sess.run(init)
  print(
  	sess.run(dataAdd),
    sess.run(dataMul),
    sess.run(dataSub),
    sess.run(dataDiv)
  )
  print('sess.run(dataCopy)', sess.run(dataCopy))  # 8
  print('dataCopy.eval()', dataCopy.eval())  # 14
  print('tf.get_default_session()', tf.get_default_session().run(dataCopy))  # 20
```

### 会话

一个运行TensorFlow operation的类，包含两种开启方式

```python
tf.Session  # 用于完整的程序当中
tf.InteractiveSession  # 用于交互式上下文中的Tensorflow，如shell
```

> `tf.Session`对象使用分布式Tensorflow运行时提供对本地计算机中的设备和远程设备的访问权限

- `__init__`

```python
__init__(target='', graph=None, config=None)

# 参数
- target: 如果将此参数留空，会话将仅使用本地计算机中的设备。可以指定grpc://网址，以便制定TensorFlow服务器的地址，这使得会话可以访问服务器控制的计算机上的所有设备
- graph:默认情况下，新的tf.Session将绑定当前的默认图
- config：此参数允许您指定一个tf.ConfigProto以便控制会话的行为。如ConfigProto协议用于打印设备使用信息
```

会话可能拥有的资源，如`tf.Variable`，`tf.QueueBase`和`tf.ReaderBase`。当这些资源不再需要时，需要释放这些资源。故常常使用`with`上下文管理器，等价于手动调用`tf.Session.close()`

```python
import tensorfow as tf

# with上下文
# 使用默认图
with tf.Session() as sess:
	res = sess.run(...)
    
# 使用新图
new_g = tf.Graph()
with tf.Session(graph=new_g) as new_sess:
    new_res = new_sess.run(...)
    
# 手动处理
sess = tf.Session()
...
sess.close()

# 运行会话并打印设备信息
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,
                                       log_device_placement=True))
```

会话可以分配不同的资源在不同的设备上运行

```
/job:worker/replica:0/task:0/device:CPU:0
```

- `run`

```python
run(fetches, feed_dict=None, options=None, run_metadata=None)

# 参数
- fetches:单一的operation，或者列表、元组（其他不属于tensorflow的类型不行）
- feed_dict:参数允许调用者覆盖图中张量的值，运行时赋值。与tf.placeholder搭配使用，则会检查值的形状是否与占位符兼容
```

> 使用`tf.operation.eval()`也可以运行operation，但需要在会话中运行

```python
# 创建图
a = tf.constant(5)
b = tf.constant(2)
c = a + b
# 创建会话
sess = tf.Session()
# 计算C的值,两种等价
print(sess.run(c))  # print(sess.run([a,b,c]))
print(c.eval(session=sess))
```

- `feed`

`placeholder`提供占位符，`run`的时候通过`feed_dict`指定参数

```python
imoport tensorflow as tf

data1 = tf.placeholder(tf.float32)
data2 = tf.placeholder(tf.float32)
dataAdd = tf.add(data1, data2)
with tf.Session() as sess:
  print(sess.run(dataAdd, feed_dict={data1:6, data2:2}))
print('end')
```

### 图

- 简单图操作

查看默认图

```python
a = tf.constant(2)  # tensor
b = tf.constant(3)
c = a + b  # op
# 查看默认图
# 方法一：调用方法
default_g = tf.get_default_graph()
print('default_g:', default_g)
# 方法二：查看属性
print("a的图属性：",a.graph)
print("b的图属性：",b.graph)
with tf.Session() as sess:  # 会话
    c_v = sess.run(c)
    print("c_v_res: {}". format(c_v)) 
    print("c_v的图属性：",c.graph)      
```

创建新图

```python
# 自定义图
new_g = tf.Graph()
with new_g.as_default():
    a_new = tf.constant(2)
    b_new = tf.constant(3)
    c_new = a_new + b_new
    print('c_new的图属性：', c_new.graph)
with tf.Session(graph=new_g) as new_sess:
      c_new_v = new_sess.run(c_new)
      print('c_new_v的res:{}'.format(c_new_v))
      print('new_session的图属性：', new_sess.graph)
```

- 嵌入Layer

单层Layer

```python
import numpy as np
import tensorflow as tf

tf.compat.v1.disable_eager_execution()

# 创建数据和占位符
my_array = np.array([[1., 3., 5., 7., 9.],
                     [-2., 0., 2., 4., 6.],
                     [-6., -3., 0., 3., 6.]])
x_vals = np.array([my_array, my_array + 1])
x_data = tf.compat.v1.placeholder(tf.float32, shape=(3, 5))
# 创建矩阵乘法和加法中的常量矩阵
m1 = tf.compat.v1.constant([[1.], [0.], [-1.], [2.], [4.]])
m2 = tf.compat.v1.constant([[2.]])
a1 = tf.compat.v1.constant([[10.]])
# 声明操作，表示成计算图
prod1 = tf.matmul(x_data, m1)
prod2 = tf.matmul(prod1, m2)
add1 = tf.add(prod2, a1)
with tf.compat.v1.Session() as sess:
    tf.compat.v1.summary.FileWriter('./tmp/summary/', graph=sess.graph)
    for x_val in x_vals:
        print(sess.run(add1, feed_dict={x_data: x_val}))
```

多层Layer

```python
import numpy as np
import tensorflow as tf

tf.compat.v1.disable_eager_execution()

# 创建图片和占位符
x_shape = [1, 4, 4, 1]
x_val = np.random.uniform(size=x_shape)
x_data = tf.compat.v1.placeholder(tf.float32, shape=x_shape)
# 创建4*4的滑动窗口
my_filter = tf.constant(0.25, shape=[2, 2, 1, 1])
my_strides = [1, 2, 2, 1]
mov_avg_layer = tf.nn.conv2d(x_data, my_filter, my_strides, padding="SAME", name="Moving_Avg_Window")

# 定义一个自定义Layer，操作滑动窗口平均的2*2的返回值
def custom_layer(input_matrix):
    input_matrix_sqeezed = tf.squeeze(input_matrix)
    A = tf.constant([[1., 2], [-1., 3.]])
    b = tf.constant(1., shape=[2, 2])
    temp1 = tf.matmul(A, input_matrix_sqeezed)
    temp = tf.add(temp1, b)  # Ax+b
    return tf.sigmoid(temp)

# 把定义的Layer加入到计算图中
with tf.name_scope("Custom_Layer") as scope:  # 折叠图层
    custom_layer1 = custom_layer(mov_avg_layer)

with tf.compat.v1.Session() as sess:
    tf.compat.v1.summary.FileWriter('./tmp/summary/', graph=sess.graph)
    res = sess.run(custom_layer1, feed_dict={x_data: x_val})
    print(res)
```

## 图变量显示

- 图显示

将图序列化为本地events文件

```python
tf.summary.FileWriter('./tmp/summary/', graph=sess.graph)
```

shell启动tensorboard，在浏览器中访问`127.0.0.1:6006`

```shell
tenorboard --logdir='./tmp/summary/'
```

- 变量显示

步骤

```
创建事件文件
收集变量
合并变量
每次迭代运行一次合并变量
每次迭代将summary对象写入事件文件
```

实现

```python
# 收集变量
tf.summary.scalar(name='', tensor)  # 收集单值变量
tf.summary.histogram(name='', tensor)  # 收集高纬度的变量参数
tf.summary.image(name='', tensor)  # 收集输入的图片张量能显示图片
# 合并变量
merged = tf.summary.merge_all()
with tf.Session() as sess:
	# 创建事件文件
	file_writer = tf.summary.FileWriter('./tmp/summary/', graph=sess.graph)
    for i in range(100):
        ...
    	# 运行合并
    	summary = sess.run(merged)  # 每次迭代都需运行
    	# 添加
    	file_writer.add_summary(summary, i)  # i表示第i此的值 
```

## 激励函数

```python
# ReLU
tf.nn.relu([-3, 3, 10])  # max(0, x)
tf.nn.relu6([-3, 3, 10])  # min(max(0, x), 6)
# sigmoid
tf.nn.sigmoid([-1, 0, 1])
# tanh
tf.nn.tanh([-1. 0, 1])
# softsign
tf.nn.softsign([-1, 0, 1])
# softplus
tf.nn.softplus([-1, 0, -1])
# ELU
tf.nn.elu([-1, 0, -1])
```

## 损失函数

```python
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.python.framework import ops

ops.reset_default_graph()

sess = tf.Session()

######回归算法损失函数######
x_vals = tf.linspace(-1., 1., 500)
target = tf.constant(0.)

# L2正则损失函数
# L = (pred - actual)^2
l2_y_vals = tf.square(target- x_vals)  
l2_y_out = sess.run(l2_y_vals)

# L1正则损失函数
# L = abs(pred - actual)
l1_y_vals = tf.abs(target - x_vals) 
l1_y_out = sess.run(l1_y_vals)

# Pseudo-Huber损失函数，依赖于delta
# L = delta^2 * (sqrt(1 + ((pred - actual)/delta)^2) - 1)
delta1 = tf.constant(0.25)
phuber1_y_vals = tf.multiply(tf.square(delta1), tf.sqrt(1. + tf.square((target - x_vals)/delta1)) - 1.)
phuber1_y_out = sess.run(phuber1_y_vals)

delta2 = tf.constant(5.)
phuber2_y_vals = tf.multiply(tf.square(delta2), tf.sqrt(1. + tf.square((target - x_vals)/delta2)) - 1.)
phuber2_y_out = sess.run(phuber2_y_vals)

# Plot the output:
x_array = sess.run(x_vals)
plt.plot(x_array, l2_y_out, 'b-', label='L2 Loss')
plt.plot(x_array, l1_y_out, 'r--', label='L1 Loss')
plt.plot(x_array, phuber1_y_out, 'k-.', label='P-Huber Loss (0.25)')
plt.plot(x_array, phuber2_y_out, 'g:', label='P-Huber Loss (5.0)')
plt.ylim(-0.2, 0.4)
plt.legend(loc='lower right', prop={'size': 11})
plt.grid()
plt.show()

###### 分类算法损失函数 ######
x_vals = tf.linspace(-3., 5., 500)
target = tf.constant(1.)
targets = tf.fill([500,], 1.)

# Hinge损失函数，主要用于评估支持向量机，有时神经网络
# L = max(0, 1 - (pred * actual))
hinge_y_vals = tf.maximum(0., 1. - tf.multiply(target, x_vals))
hinge_y_out = sess.run(hinge_y_vals)

# 两类交叉熵损失函数
# L = -actual * (log(pred)) - (1-actual)(log(1-pred))
xentropy_y_vals = - tf.multiply(target, tf.log(x_vals)) - tf.multiply((1. - target), tf.log(1. - x_vals))
xentropy_y_out = sess.run(xentropy_y_vals

# sigmoid交叉损失函数
# L = -actual * (log(sigmoid(pred))) - (1-actual)(log(1-sigmoid(pred)))
# or
# L = max(actual, 0) - actual * pred + log(1 + exp(-abs(actual)))
x_val_input = tf.expand_dims(x_vals, 1)
target_input = tf.expand_dims(targets, 1)
xentropy_sigmoid_y_vals = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_val_input,
                                                                  labels=target_input)
xentropy_sigmoid_y_out = sess.run(xentropy_sigmoid_y_vals) 

# 加权交叉熵损失函数
# L = -actual * (log(pred)) * weights - (1-actual)(log(1-pred))
# or
# L = (1 - pred) * actual + (1 + (weights - 1) * pred) * log(1 + exp(-actual))
weight = tf.constant(0.5)
xentropy_weighted_y_vals = tf.nn.weighted_cross_entropy_with_logits(logits=x_vals, targets=targets,pos_weight=weight)
xentropy_weighted_y_out = sess.run(xentropy_weighted_y_vals)

# Plot the output
x_array = sess.run(x_vals)
plt.plot(x_array, hinge_y_out, 'b-', label='Hinge Loss')
plt.plot(x_array, xentropy_y_out, 'r--', label='Cross Entropy Loss')
plt.plot(x_array, xentropy_sigmoid_y_out, 'k-.', label='Cross Entropy Sigmoid Loss')
plt.plot(x_array, xentropy_weighted_y_out, 'g:', label='Weighted Cross Entropy Loss (x0.5)')
plt.ylim(-1.5, 3)
#plt.xlim(-1, 3)
plt.grid()
plt.legend(loc='lower right', prop={'size': 11})
plt.show()                          
                          
# softmax交叉熵损失函数，只针对单个目标分类的计算损失，将结果转换为概率分布计算真值概率分布的损失
# L = -actual * (log(softmax(pred))) - (1-actual)(log(1-softmax(pred)))
unscaled_logits = tf.constant([[1., -3., 10.]])
target_dist = tf.constant([[0.1, 0.02, 0.88]])
softmax_xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=unscaled_logits,labels=target_dist)
print(sess.run(softmax_xentropy)) 

# 稀疏softmax交叉熵损失函数，把目标分类为true的转换为index
# L = sum( -actual * log(pred) )
unscaled_logits = tf.constant([[1., -3., 10.]])
sparse_target_dist = tf.constant([2])
sparse_xentropy =  tf.nn.sparse_softmax_cross_entropy_with_logits(logits=unscaled_logits,labels=sparse_target_dist)
print(sess.run(sparse_xentropy))
```

## 反向传播

tensorflow可以维护操作状态和基于反向传播自动地更新模型的变量。

tensorflow通过计算图实现最小化损失函数的误差反向传播进而更新变量。这步将通过声明优化函数来实现。一旦声明好优化函数，将通过它在所有的计算图中解决反向传播的项。当我们传入数据，最小化损失函数，tensorflow会在计算图中根据状态相应地调节变量。

过程

```
1.生成数据，所有样本需要通过占位符进行加载
2.初始化占位符和变量
3.创建损失函数
4.定义一个优化器算法
5.通过随机数据样本进行迭代，更新变量
```

实例

```python
import numpy as np
import tensorflow as tf
from tensorflow.python.framework import ops
ops.reset_default_graph()

# Create graph
sess = tf.Session()

# 回归
# We will create sample data as follows:
# x-data: 100 random samples from a normal ~ N(1, 0.1)
# target: 100 values of the value 10.
# We will fit the model:
# x-data * A = target
# Theoretically, A = 10.

# 生成数据，创建占位符和变量A
x_vals = np.random.normal(1, 0.1, 100)
y_vals = np.repeat(10., 100)
x_data = tf.placeholder(shape=[1], dtype=tf.float32)
y_target = tf.placeholder(shape=[1], dtype=tf.float32)
A = tf.Variable(tf.random_normal(shape=[1]))  # 模型变量

# 增加乘法操作
my_output = tf.multiply(x_data, A)

# 增加L2增则损失函数
loss = tf.square(my_output - y_target)

# 声明优化器
my_opt = tf.train.GradientDescentOptimizer(0.02)  # 标准梯度下降，选取合适的学习率
train_step = my_opt.minimize(loss)

# 运行之前，初始化变量
init = tf.global_variables_initializer()
sess.run(init)

# 训练算法：选择一个随机的x,y传入计算图中，将自动计算损失，调整A偏差来最小化损失
for i in range(100):  # 迭代101次
    rand_index = np.random.choice(100)
    rand_x = [x_vals[rand_index]]
    rand_y = [y_vals[rand_index]]
    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})
    if (i+1)%25==0:  # 每25次迭代打印结果
        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))
        print('Loss = ' + str(sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})))

        
# 分类
# We will create sample data as follows:
# x-data: sample 50 random values from a normal = N(-1, 1)
#         + sample 50 random values from a normal = N(1, 1)
# target: 50 values of 0 + 50 values of 1.
#         These are essentially 100 values of the corresponding output index
# We will fit the binary classification model:
# If sigmoid(x+A) < 0.5 -> 0 else 1
# Theoretically, A should be -(mean1 + mean2)/2

# 重置计算图
ops.reset_default_graph()

# Create graph
sess = tf.Session()

# 生成数据，占位符和变量
x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(3, 1, 50)))
y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))
x_data = tf.placeholder(shape=[1], dtype=tf.float32)
y_target = tf.placeholder(shape=[1], dtype=tf.float32)
A = tf.Variable(tf.random_normal(mean=10, shape=[1]))  # 模型变量

# 增加转换操作
# Want to create the operstion sigmoid(x + A)
# Note, the sigmoid() part is in the loss function
my_output = tf.add(x_data, A)

# Now we have to add another dimension to each (batch size of 1)
my_output_expanded = tf.expand_dims(my_output, 0)
y_target_expanded = tf.expand_dims(y_target, 0)

# 初始化变量
init = tf.global_variables_initializer()
sess.run(init)

# 声明损失函数，使用带非归一化的logits的交叉熵的损失函数，同时用sigmoid函数转换
xentropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=my_output_expanded, labels=y_target_expanded)

# 创建优化器
my_opt = tf.train.GradientDescentOptimizer(0.05)
train_step = my_opt.minimize(xentropy)

# 训练算法
for i in range(1400):
    rand_index = np.random.choice(100)
    rand_x = [x_vals[rand_index]]
    rand_y = [y_vals[rand_index]]
    
    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})
    if (i+1)%200==0:
        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))
        print('Loss = ' + str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y})))

# 评估预测值
predictions = []
for i in range(len(x_vals)):
    x_val = [x_vals[i]]
    prediction = sess.run(tf.round(tf.sigmoid(my_output)), feed_dict={x_data: x_val})
    predictions.append(prediction[0])
    
accuracy = sum(x==y for x,y in zip(predictions, y_vals))/100.
print('Ending Accuracy = ' + str(np.round(accuracy, 2)))
```

## 优化器算法

标准梯度下降

```python
tf.train.GradientDescentOptimizer(learning_rate)
# 参数
大学习率：结果不精确，但收敛快，适用于若算法收敛太慢，可提高学习率
小学习率：收敛慢，但结果精确，适用于若算法不稳定，先降低学习率
```

为了解决标准梯度下降算法的明显卡顿或收敛过慢（梯度为0的附近）

```python
tf.train.MomentumOptimizer(learning_rate,momentum)
# 增加了momentum势能，前一次迭代过程的梯度下降值的倒数
```

更改步长优化的Adagrad算法，考虑整个历史迭代的变量梯度

```python
tf.train.AdagradOptimizer(learning_rate, initial_accumulator_value=0.1)
```

由于Adagrad算法计算整个历史迭代的梯度，导致梯度迅速变为0，解决方法

```python
tf.train.AdadeltaOptimizer(learning_rate=0.001, rho=0.95, epsilon=1e-8)
```

## 批量随机训练

- 回归

随机训练

```python
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.python.framework import ops
ops.reset_default_graph()

# We will implement a regression example in stochastic and batch training

# Stochastic Training:
# Create graph
sess = tf.Session()

# Create data
x_vals = np.random.normal(1, 0.1, 100)
y_vals = np.repeat(10., 100)
x_data = tf.placeholder(shape=[1], dtype=tf.float32)
y_target = tf.placeholder(shape=[1], dtype=tf.float32)

# Create variable (one model parameter = A)
A = tf.Variable(tf.random_normal(shape=[1]))

# Add operation to graph
my_output = tf.multiply(x_data, A)

# Add L2 loss operation to graph
loss = tf.square(my_output - y_target)

# Create Optimizer
my_opt = tf.train.GradientDescentOptimizer(0.02)
train_step = my_opt.minimize(loss)

# Initialize variables
init = tf.global_variables_initializer()
sess.run(init)

loss_stochastic = []
# Run Loop
for i in range(100):
    rand_index = np.random.choice(100)
    rand_x = [x_vals[rand_index]]
    rand_y = [y_vals[rand_index]]
    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})
    if (i+1)%5==0:
        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))
        temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})
        print('Loss = ' + str(temp_loss))
        loss_stochastic.append(temp_loss)
       
```

批量训练

```python
# Re-initialize graph
ops.reset_default_graph()
sess = tf.Session()

# 声明批量大小
batch_size = 20

# Create data
x_vals = np.random.normal(1, 0.1, 100)
y_vals = np.repeat(10., 100)
x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)
y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)

# Create variable (one model parameter = A)
A = tf.Variable(tf.random_normal(shape=[1,1]))

# Add operation to graph
my_output = tf.matmul(x_data, A)

# Add L2 loss operation to graph
loss = tf.reduce_mean(tf.square(my_output - y_target))

# Create Optimizer
my_opt = tf.train.GradientDescentOptimizer(0.02)
train_step = my_opt.minimize(loss)

# Initialize variables
init = tf.global_variables_initializer()
sess.run(init)

loss_batch = []
# Run Loop
for i in range(100):
    rand_index = np.random.choice(100, size=batch_size)
    rand_x = np.transpose([x_vals[rand_index]])
    rand_y = np.transpose([y_vals[rand_index]])
    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})
    if (i+1)%5==0:
        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))
        temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})
        print('Loss = ' + str(temp_loss))
        loss_batch.append(temp_loss)
        
plt.plot(range(0, 100, 5), loss_stochastic, 'b-', label='Stochastic Loss')
plt.plot(range(0, 100, 5), loss_batch, 'r--', label='Batch Loss, size=20')
plt.legend(loc='upper right', prop={'size': 11})
plt.show()
```

- 分类

```python
# Combining Everything Together
#----------------------------------
# This file will perform binary classification on the
# iris dataset. We will only predict if a flower is
# I.setosa or not.
#
# We will create a simple binary classifier by creating a line
# and running everything through a sigmoid to get a binary predictor.
# The two features we will use are pedal length and pedal width.
#
# We will use batch training, but this can be easily
# adapted to stochastic training.

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets
import tensorflow as tf
from tensorflow.python.framework import ops
ops.reset_default_graph()

# Load the iris data
# iris.target = {0, 1, 2}, where '0' is setosa
# iris.data ~ [sepal.width, sepal.length, pedal.width, pedal.length]
iris = datasets.load_iris()
binary_target = np.array([1. if x==0 else 0. for x in iris.target])
iris_2d = np.array([[x[2], x[3]] for x in iris.data])

# Declare batch size
batch_size = 20

# Create graph
sess = tf.Session()

# Declare placeholders
x1_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)
x2_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)
y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)

# Create variables A and b (0 = x1 - A*x2 + b)
A = tf.Variable(tf.random_normal(shape=[1, 1]))
b = tf.Variable(tf.random_normal(shape=[1, 1]))

# Add model to graph:
# x1 - A*x2 + b
my_mult = tf.matmul(x2_data, A)
my_add = tf.add(my_mult, b)
my_output = tf.subtract(x1_data, my_add)

# Add classification loss (cross entropy)
xentropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=my_output, labels=y_target)

# Create Optimizer
my_opt = tf.train.GradientDescentOptimizer(0.05)
train_step = my_opt.minimize(xentropy)

# Initialize variables
init = tf.global_variables_initializer()
sess.run(init)

# Run Loop
for i in range(1000):
    rand_index = np.random.choice(len(iris_2d), size=batch_size)
    #rand_x = np.transpose([iris_2d[rand_index]])
    rand_x = iris_2d[rand_index]
    rand_x1 = np.array([[x[0]] for x in rand_x])
    rand_x2 = np.array([[x[1]] for x in rand_x])
    #rand_y = np.transpose([binary_target[rand_index]])
    rand_y = np.array([[y] for y in binary_target[rand_index]])
    sess.run(train_step, feed_dict={x1_data: rand_x1, x2_data: rand_x2, y_target: rand_y})
    if (i+1)%200==0:
        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + ', b = ' + str(sess.run(b)))
        

# Visualize Results
# Pull out slope/intercept
[[slope]] = sess.run(A)
[[intercept]] = sess.run(b)

# Create fitted line
x = np.linspace(0, 3, num=50)
ablineValues = []
for i in x:
  ablineValues.append(slope*i+intercept)

# Plot the fitted line over the data
setosa_x = [a[1] for i,a in enumerate(iris_2d) if binary_target[i]==1]
setosa_y = [a[0] for i,a in enumerate(iris_2d) if binary_target[i]==1]
non_setosa_x = [a[1] for i,a in enumerate(iris_2d) if binary_target[i]==0]
non_setosa_y = [a[0] for i,a in enumerate(iris_2d) if binary_target[i]==0]
plt.plot(setosa_x, setosa_y, 'rx', ms=10, mew=2, label='setosa')
plt.plot(non_setosa_x, non_setosa_y, 'ro', label='Non-setosa')
plt.plot(x, ablineValues, 'b-')
plt.xlim([0.0, 2.7])
plt.ylim([0.0, 7.1])
plt.suptitle('Linear Separator For I.setosa', fontsize=20)
plt.xlabel('Petal Length')
plt.ylabel('Petal Width')
plt.legend(loc='lower right')
plt.show()
```

## 模型评估

使用tensorflow时，需要把模型评估加入到计算图中，然后在模型训练完成后调用模型评估。

分类

```python
# Evaluating models in TensorFlow
#
# This code will implement two models.  The first
#  is a simple regression model, we will show how to
#  call the loss function, MSE during training, and
#  output it after for test and training sets.
#
# The second model will be a simple classification
#  model.  We will also show how to print percent
#  classified correctly during training and after
#  for both the test and training sets.

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.python.framework import ops
ops.reset_default_graph()

# Create graph
sess = tf.Session()

# Regression Example:
# We will create sample data as follows:
# x-data: 100 random samples from a normal ~ N(1, 0.1)
# target: 100 values of the value 10.
# We will fit the model:
# x-data * A = target
# Theoretically, A = 10.

# Declare batch size
batch_size = 25

# Create data
x_vals = np.random.normal(1, 0.1, 100)
y_vals = np.repeat(10., 100)
x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)
y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)

# Split data into train/test = 80%/20%
train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)
test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))
x_vals_train = x_vals[train_indices]
x_vals_test = x_vals[test_indices]
y_vals_train = y_vals[train_indices]
y_vals_test = y_vals[test_indices]

# Create variable (one model parameter = A)
A = tf.Variable(tf.random_normal(shape=[1,1]))

# Add operation to graph
my_output = tf.matmul(x_data, A)

# Add L2 loss operation to graph
loss = tf.reduce_mean(tf.square(my_output - y_target))

# Create Optimizer
my_opt = tf.train.GradientDescentOptimizer(0.02)
train_step = my_opt.minimize(loss)

# Initialize variables
init = tf.global_variables_initializer()
sess.run(init)

# Run Loop
for i in range(100):
    rand_index = np.random.choice(len(x_vals_train), size=batch_size)
    rand_x = np.transpose([x_vals_train[rand_index]])
    rand_y = np.transpose([y_vals_train[rand_index]])
    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})
    if (i+1)%25==0:
        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))
        print('Loss = ' + str(sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})))

# Evaluate accuracy (loss) on test set
mse_test = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])})
mse_train = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])})
print('MSE on test:' + str(np.round(mse_test, 2)))
print('MSE on train:' + str(np.round(mse_train, 2)))
```
分类
```python
# Classification Example
# We will create sample data as follows:
# x-data: sample 50 random values from a normal = N(-1, 1)
#         + sample 50 random values from a normal = N(1, 1)
# target: 50 values of 0 + 50 values of 1.
#         These are essentially 100 values of the corresponding output index
# We will fit the binary classification model:
# If sigmoid(x+A) < 0.5 -> 0 else 1
# Theoretically, A should be -(mean1 + mean2)/2

ops.reset_default_graph()

# Create graph
sess = tf.Session()

# Declare batch size
batch_size = 25

# Create data
x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(2, 1, 50)))
y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))
x_data = tf.placeholder(shape=[1, None], dtype=tf.float32)
y_target = tf.placeholder(shape=[1, None], dtype=tf.float32)

# Split data into train/test = 80%/20%
train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)
test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))
x_vals_train = x_vals[train_indices]
x_vals_test = x_vals[test_indices]
y_vals_train = y_vals[train_indices]
y_vals_test = y_vals[test_indices]

# Create variable (one model parameter = A)
A = tf.Variable(tf.random_normal(mean=10, shape=[1]))

# Add operation to graph
# Want to create the operstion sigmoid(x + A)
# Note, the sigmoid() part is in the loss function
my_output = tf.add(x_data, A)

# Add classification loss (cross entropy)
xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=my_output, labels=y_target))

# Create Optimizer
my_opt = tf.train.GradientDescentOptimizer(0.05)
train_step = my_opt.minimize(xentropy)

# Initialize variables
init = tf.global_variables_initializer()
sess.run(init)

# Run loop
for i in range(1800):
    rand_index = np.random.choice(len(x_vals_train), size=batch_size)
    rand_x = [x_vals_train[rand_index]]
    rand_y = [y_vals_train[rand_index]]
    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})
    if (i+1)%200==0:
        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))
        print('Loss = ' + str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y})))
        
# Evaluate Predictions on test set
y_prediction = tf.squeeze(tf.round(tf.nn.sigmoid(tf.add(x_data, A))))
correct_prediction = tf.equal(y_prediction, y_target)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
acc_value_test = sess.run(accuracy, feed_dict={x_data: [x_vals_test], y_target: [y_vals_test]})
acc_value_train = sess.run(accuracy, feed_dict={x_data: [x_vals_train], y_target: [y_vals_train]})
print('Accuracy on train set: ' + str(acc_value_train))
print('Accuracy on test set: ' + str(acc_value_test))

# Plot classification result
A_result = -sess.run(A)
bins = np.linspace(-5, 5, 50)
plt.hist(x_vals[0:50], bins, alpha=0.5, label='N(-1,1)', color='blue')
plt.hist(x_vals[50:100], bins[0:50], alpha=0.5, label='N(2,1)', color='red')
plt.plot((A_result, A_result), (0, 8), 'k--', linewidth=3, label='A = '+ str(np.round(A_result, 2)))
plt.legend(loc='upper right')
plt.title('Binary Classifier, Accuracy=' + str(np.round(acc_value_test, 2)))
plt.show()
```

##模型保存加载 

函数

```python
# 保存
tf.train.Saver(var_list=None, max_to_keep=5)
# 参数
- var_list:指定将要保存的变量，可以作为一个dict或list
- max_to_keep:指定 要保留的最近检查点文件的最大数量。创建新文件时会删除较旧的文件

# 加载
tf.train.Restore()
```

使用

```python
saver = tf.train.Saver()

# 保存模型
with tf.Session() as sess:
    for i in range(100):
        saver.save(sess, './tmp/model/my_linear.ckpt')
        
# 加载模型
with tf.Session() as sess:
    if os.path.exists('./tmp/model/checkpoint'):
        saver.restore(sess, './tmp/model/my_linear.ckpt')
```

## 命令行参数

```python
tf.app.flags
# 支持应用从命令行接受参数，可以用来指定集群配置等，在tf.app.flags下面有各种定义参数的类型：
- DEFINE_string(flag_name, default_value, docstring)
- DEFINE_integer(flag_name, default_value, docstring)
- DEFINE_boolean(flag_name, default_value, docstring)
- DEFINE_float(flag_name, default_value, docstring)

tg.apps.flags.FLAGS
# 获取命令行参数，可以调用上面定义的flag_name
```

使用

```python
# 代码
tf.app.flags.DEFINE_integer("max_step", 0, "训练模型的步数")  # 训练步数
tf.app.flags.DEFINE_string("model_dir", "", "模型保存的路径+模型的名字")  # 定义模型的路径
FLAGS = tf.app.flags.FLAGS  # 定义获取命令行参数

for i in range(FLAGS.max_step):  # 使用命令行参数
    sess.run(train_op)

def main(argv):
    print(argv)
    
if __name__=="__main__":
    tf.app.run()  # 命令行启动时自动调用main函数，传参argv
```

命令行

```
python demo.py --max_step=1
```

## API

基础

| 名称           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| `tf.app`       | 相当于为TensorFlow运行的脚本提供一个main函数入口，可以定义脚本运行的flags |
| `tf.image`     | TensorFlow的图像处理操作，主要是一些颜色变换、变形和图像的编码和解码 |
| `tf.gfile`     | 这个模块提供了一组文件操作函数                               |
| `tf.summary`   | 用来生成`TensorBoard`可用的统计日志，目前`Summary`主要提供了4中类型：`audio,image,histogram,scalar` |
| `tf.python_io` | 用来读写TFRecords文件                                        |
| `tf.train`     | 提供了一些训练器，与`tf.nn`组合起来，实现一些网络的优化计算  |
| `tf.nn`        | 提供了一些构建神经网络的底层函数。Tensrflow构建网络的核心模块。其中包含了添加各种层的函数，比如添加卷积层、池化层等 |

高级

| 名称           | 声明                                                         |
| -------------- | ------------------------------------------------------------ |
| `tf.keras`     | Keras是一个独立的深度学习库，增加此在于快速构建模型          |
| `tf.layers`    | 以更高级的概念层来定义一个模型。类似`tf.keras`               |
| `tf.contrib`   | 提供够将计算图中的网络层、正则化、摘要操作，是构建计算图的高级操作，但是包含不稳定和实验代码，可能后期API会改变 |
| `tf.estimator` | 相当于`Model+Training+Evaluate`，在模块中，已经实现了几种简单的分类器和回归器，包括:`Baseline,Learning,DNN`。这里`DNN`的网络，只是全连接网络，没有提供卷积之类的。 |

