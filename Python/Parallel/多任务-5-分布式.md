# 分布式

分布式计算的基本理念是将工作划分位一个一个的小任务，通常每个任务都有名称。分布式网络中的电脑可以完美无缺地完成这些合理大小的任务并返回结果。在分布式计算中，网络中的机器必须要保持可用(延迟误差、意外宕机、电脑联网等)。因此，需要一个持续监控架构。

使用这种技术所带来的根本问题，主要在于对(传输与接收没有出错)流量(数据、工作、命令等)的合理管理。另外，还有一个源自分布式计算基本特征的问题：分布式网络中共存的机器支持不同的操作系统，而这些系统通常相互不兼容。事实上，由于需要在分布式环境中使用多种多样的资源，逐渐出现了不同的计算模型。它们的目标基本上都是为如何描述分布式应用的进程之间的协作提供框架。可以这样说，不同的模型的区别基本在于其对分布式所提供机会的利用能力。使用最广泛的模型是客户端-服务端(client-server)模型。它可以让位于不同电脑中的进程通过交换信息实现实时协作，因此性能比之前的模型有很大的提升，后者要求转移所有的文件，而且要离线对数据进行计算。客户端-服务器模型通常通过远程进程调用(扩大本机调用的范围)，或分布式对象范式(面向对象中间件)实现。

常用的与面向对象模式和远程调用模式实现分布式架构的库，如Celery、SCOOP、Pyro4、RPyc，以及使用其他不同方法实现的库，如PyCSP和Disco，后两者是python中对应于MapReduce的算法

## Celery

celery是一个用于管理分布式任务的python框架，采用的是面向对象中间件的方法实现。其主要特性包括处理大量小型任务，并将其分发给大量计算节点。最后，每个任务的结果重新组合，构成最终的答案。

Celery是由Python开发、简单、灵活、可靠的分布式任务队列，其本质是生产者消费者模型，生产者发送任务到消息队列，消费者负责处理任务。Celery侧重于实时操作，但对调度支持也很好，其每天可以处理数以百万计的任务。

Celery由以下三部分构成：消息中间件(Broker)、任务执行单元Worker、结果存储(Backend)

![消息中介架构](images/消息中介架构.png)

celery通过消息进行通信，通常使用一个叫Broker(中间人)来协client(任务的发出者)和worker(任务的处理者). clients发出消息到队列中，broker将队列中的信息派发给worker来处理。

工作原理

```
- 任务模块Task包含异步任务和定时任务。其中，异步任务通常在业务逻辑中被触发并发往消息队列，而定时任务由Celery Beat进程周期性地将任务发往消息队列；

- 任务执行单元Worker实时监视消息队列获取队列中的任务执行；

- Woker执行完任务后将结果保存在Backend中;
```

应用场景

```
- web应用
当用户在网站进行某个操作需要很长时间完成时，我们可以将这种操作交给Celery执行，直接返回给用户，等到Celery执行完成以后通知用户，大大提好网站的并发以及用户的体验感。

- 任务场景
比如在运维场景下需要批量在几百台机器执行某些命令或者任务，此时Celery可以轻松搞定。

- 定时任务
向定时导数据报表、定时发送通知类似场景，虽然Linux的计划任务可以帮我实现，但是非常不利于管理，而Celery可以提供管理接口和丰富的API。
```

### 安装

使用python的包管理器pip来安装:

```
pip install -U Celery
```

从官方直接下载安装包:<https://pypi.python.org/pypi/celery/>

```
tar xvfz celery-0.0.0.tar.gz
cd celery-0.0.0
python setup.py build
python setup.py install
```

### broker

消息中介是一个不依赖于celery的软件组件，是一个中间件，用于向分布式任务工作进程发送和接收消息。消息中介也被称为消息中间件。它负责通信网络中的消息交换。这类中间件的编址方案(addressing scheme)不再是点对点式的，而是面向消息式的，其中最知名的就是发布/订阅范式。Celery支持多种类型的消息中介，如RabbitMQ、Redis、Amazon SQS、MongoDB、Memcached 等，其中最为完整的是RabbitMQ和Redis。

- RabbitMQ

它是一个面向消息的中间件(中介消息传递，broker messaging)，它实现了高级消息队列协议(AMQP)。RabbitMQ采用Erlang语言编写，其基础是用于管理集群和故障切换的开放电信平台(OTP)框架。

使用RabbitMQ的细节参照以下链接：<http://docs.celeryproject.org/en/latest/getting-started/brokers/rabbitmq.html#broker-rabbitmq>

```
RabbitMQ是一个功能完备，稳定的并且易于安装的broker. 它是生产环境中最优的选择。

如果我们使用的是Ubuntu或者Debian发行版的Linux，可以直接通过下面的命令安装RabbitMQ: sudo apt-get install rabbitmq-server 安装完毕之后，RabbitMQ-server服务器就已经在后台运行。如果您用的并不是Ubuntu或Debian, 可以在以下网址： http://www.rabbitmq.com/download.html 去查找自己所需要的版本软件。
```

- Redis

关于是有那个Redis作为Broker，可访下面网址：<http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html#broker-redis>

```
Redis也是一款功能完备的broker可选项，但是其更可能因意外中断或者电源故障导致数据丢失的情况。
```

### worker

Worker是任务执行单元，负责从消息队列中取出任务执行，它可以启动一个或者多个，也可以启动在不同的机器节点，这就是其实现分布式的核心

```python
# 我们首先创建tasks.py模块
from celery import Celery

# 我们这里案例使用redis作为broker
# Celery第一个参数是给其设定一个名字， 第二参数我们设定一个中间人broker
app = Celery('demo', broker='redis://127.0.0.1/1')
# app = Celery('demo', broker='amqp://guest@localhost//')

# 创建任务函数, 通过加上装饰器app.task, 将其注册到broker的队列中
@app.task
def my_task():
    print("任务函数正在执行....")
```

现在我们在创建一个worker， 等待处理队列中的任务.打开终端，cd到tasks.py同级目录中，执行命令:

```
celery -A tasks worker --loglevel=info

celery -A tasks worker -l info
```

### backend

Backend结果存储官方也提供了诸多的存储方式支持：RabbitMQ、 Redis、Memcached,SQLAlchemy, Django ORM、Apache Cassandra、Elasticsearch。

使用Redis作为存储结果的方案，任务结果存储配置我们通过Celery的backend参数来设定。我们将tasks模块修改如下:

```python
# 修改tasks.py
from celery import Celery

# 我们这里案例使用redis作为broker
# 我们给Celery增加了backend参数，指定redis作为结果存储,并将任务函数修改为两个参数，并且有返回值。
app = Celery('demo',
backend='redis://127.0.0.1:6379/2',
broker='redis://127.0.0.1:6379/1')

# 创建任务函数
@app.task
def my_task(a, b):
    print("任务函数正在执行....")
    return a + b
```

### 任务执行

任务加入到broker队列中，以便刚才我们创建的celery workder服务器能够从队列中取出任务并执行。如何将任务函数加入到队列中，可使用如下方法

```python
# 该任务发送一个任务消息
apply_async(args[, kwargs[, ...]])
# 发送任务消息的便捷方法，不支持添加执行选项
delay(*args, **kwargs)

# 使用样例
task.delay(arg1, arg2, kwarg1='x', kwarg2='y')
task.apply_async(args=[arg1, arg2], kwargs={'kwarg1':'x', 'kwarg2':'y'})
```

默认多进程执行，也可以多协程处理(greenlet/gevent)

进入python终端, 执行如下代码:

```python
from tasks import my_task
# 执行,返回执行的对象
task_obj = my_task.delay()
# 获取任务编号
print(task_obj.id)
# 获取异步任务结果，默认阻塞
task_obj.get()
```

- django中使用

```python
# 创建和开启任务
from celery import Celery
import os

os.environ["DJANGO_SETTINGS_MODULE"] = "dj_py2_demo.settings"

# django不不需开启，celery端需要开启
# import django
# django.setup()

app = Celery(
    'sum_two',
    broker='redis://127.0.0.1:6379/1',
    backend='redis://127.0.0.1:6379/2',
)

@app.task
def sum_two(a, b):
    c = a + b
    return c

# 发布和获取结果
from celery_tasks.sum_two import sum_two

result = sum_two.delay(5,7)
result.get()
```

### 任务监控

flower是一个用于监控任务(运行进度、任务详情、图标、数据)的web工具。

```python
# 安装
pip install -U flower

# 运行flower命令启动web-server
celery -A proj flower

# 设置端口
# 缺省的端口是http://localhost:5555, 可以使用–port参数改变
celery -A proj flower --port=5555

# 设置broker的URL
celery flower --broker=amqp://guest:guest@localhost:5672//
celery flower --broker=redis://guest:guest@localhost:6379/0    

# 浏览器访问
open http://localhost:5555
        
# api使用
# 获取woker信息
curl http://127.0.0.1:5555/api/workers
```

## SCOOP

SCOOP全称Scalable Concurrent Operations in Python，意为"python中的可伸缩式并发运算"，是一个将并发任务(被称为Futures)分发在异构计算节点(heterogeneous computational nodes)上运行的python模块。其架构基于MQ包，后者提供了在分布式系统之间管理Futures的方法。SCOOP应用在需要使用全部可用计算资源执行诸多分布式任务的科学计算。

SCOOP采用了如下所示的这种中介模式来分发Futures。

![SCOOP架构](images/SCOOP架构.png)

通信系统的核心元素时负责于所有独立工作者进程交互、调度消息的中介。Futures并非创建于中心节点(中介)，而是通过一套统一的序列化程序在各个工作者进程中创建。这使得其拓扑架构更可靠，性能更高。实际上，中介的主要工作负载由网络和工作者进程间I/O构成，所需的CPU处理事件相对较少。

### 安装

SCOOP模块可在`https://github.com/soravux/scoop/`处获取，所需依赖如下

```
python>=2.6或>=3.2
Distribute>=0.6.2或setuptools>=0.7
Greenlet>=0.3.4
pyzmq>=13.1.0及libzmq>=3.2.0
SSH(用于远程执行)
```

和Disco一样，远程使用SCOOP需要SSH软件，而且哥哥节点之间必须开启为无须密码验证。

```python
# pip安装
pip install SCOOP
# 发布版的目录下安装
python setup.py install
```

### 科学计算

SCOOP库具有许多功能，主要用于科学计算。尽管求解科学计算问题的方法十分耗费计算资源，但幸好出现了蒙特卡罗算法。

如何使用SCOOP的特性并行化蒙特卡罗方法求解以下问题：计算数字$\pi$

```python
import math
from random import random
from scoop import futures
from time import time

def evaluate_number_of_points_in_unit_circle(attempts):
    points_fallen_in_unit_disk = 0
    for i in range(0, attempts):
        x = random()
        y = random()
        radius = math.sqrt(x*x + y*y)
        # 如果点落在单位圆内，则测试通过
        if radius < 1:
            # 测试通过后，增加圆内点的数目
            points_fallen_in_unit_disk  = points_fallen_in_unit_disk + 1
    return points_fallen_in_unit_disk


def pi_calculus_with_Montecarlo_Method(workers, attempts):
    print("number of workers %i - number of attempts %i" % (workers, attempts))
    bt = time()
    # 这时我们调用scoop.futures.map函数，然后求单位圆内点的数目
    # 函数以异步方式执行并且可以并发多次调用该函数
    evaluate_task = futures.map(evaluate_points_in_circle, [attempts] * workers)
    taskResult = sum(evaluate_task)
    print("%i points fallen in a unit disk after " % (taskResult/attempts))
    piValue = (4. * taskResult/float(workers * attempts))

    computationalTime = time() - bt
    print("value of pi = " + str(piValue))
    print("error percentage = " + str((((abs(piValue - math.pi)) * 100)/ math.pi)))
    print("total time: " + str(computationalTime))

if __name__ == "__main__":
    for i in range(1, 4):
        # 将工作者数量固定为2，也可以设置更高
        pi_calculus_with_Montecarlo_Method(i*1000, i*1000)
        print(" ")
```

运行

```
python -m scoop name_file.py
```

### 映射函数

在处理列表或其他数据序列时，有一个常见任务，即对列表中的每个元素应用相同的操作，然后收集结果。

```python
# 方法一
items = [1,2,3,4,5,6,7,8,9]
updated_items = []
for x in items:
    updated_items.append(x*2)
print(updated_items)   
# 方法二
items = [1,2,3,4,5,6,7,8,9]
def multipyFor2(x): return x*2
print(list(map(multipyFor2, items)))
# 方法三
items = [1,2,3,4,5,6,7,8,9]
print(list(map(lambda x:x*2, items)))
```

SCOOP模块定义了多个映射函数，支持可传播至其工作者的异步计算，如下

| 方法                                                         | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `futures.map(func, iterables, kargs)`                        | 返回一个以输入中相同顺序迭代结果的生成器。可作为标准库中的map()函数的并行版 |
| `futures.map_as_completed(func, iterables, kargs)`           | 只要结果一可用即生成结果                                     |
| `futures.scoop.futures.mapReduce(mapFunc, reductionOp, iterables, kargs)` | 支持在应用map()函数后将减项函数(reduction function)并行化，返回单个元素 |

对比MapReduce函数的SCOOP实现和串行实现

```python
import operator
import time
from scoop import futures


def simulateWorkload(inputData):
    # 模拟真实的计算工作负载
    time.sleep(0.01)
    return sum(inputdata)

def compareMapReduce():
    # SCOOP版的MapReduce
    mapScoopTime = time.time()
    # 参数1:调用该函数可执行Futures，可调用对象必须返回一个值
    # 参数2:调用该函数可归约(reduce)Futures运行结果，必须接受两个参数，并返回一个单一值
    # 参数3:将作为单独的Future传入可调用对象的可迭代对象
    res = futures.mapReduce(
        simulateWorkload,
        operator.add,
        list([a] * a for a in range(1000)),
    )
    mapScoopTime = time.time() - mapScoopTime
    print("futures.map in SCOOP executed in {0:3f}s with result: {1}".format(mapScoopTime, res))
	# 串行版的MapReduce
    mapPythonTime = time.time()
    # map()函数参数1:函数，参数2:可迭代对象
    # 为了结果规约，使用sum函数
    res = sum(
        map(
            simulateWorkload,
            list([a] * a for a in range(1000))
        )
    )
    mapPythonTime = time.time() - mapPythonTime
    print("map python executed in: {0:.3f}s with result: {1}".format(mapPythonTime, res))

    if __name__ == "__main__":
        compareMapReduce()
```

运行

```
python -m scoop map_reduce.py
```

## Pyro4

python远程对象(Python Remote Objects，简称Pyro4)是一个类似java中远程方法调用(Remote Method Invocation，简称RMI)的库，支持调用远程对象(属于不同的进程，可能位于另一台机器上)的方法，就好像它就是本地对象(同属于运行调用的那个进程)。远程过程调用(remote procedure call，简称RPC)的概念被按照面向对象范式重新组织(在面向对象的范式中，方法取代了过程)。在面向对象系统中使用远程方法调用机制，可以为项目带来极大的一致性、对称性优势，因为它可以让我们使用同一个概念工具来模拟分布式进程之间的交互，该工具也被用于表示一个应用或方法调用中不同对象的交互

Pyro4支持以客户端-服务器的形式管理和分发对象。这意味着一个Pyro4系统的主要部分可以从一个调用远程对象的客户端切换到一个调用来提供函数的对象。注意：在远程调用期间，一直存在两个明显的部分，即客户端发起调用，服务端接收并执行客户端调用。最后，这个机制的管理均由Pyro4以分布式的方式进行。

### 安装

```python
# pip安装
pip install pyro
# 包安装
python setup.py install
```

### 远程调用

使用pyro4中间件构建并使用一个简单的客户端-服务器通信

- server

```python
import Pyro4

# 远程访问对象Server类
class Server(object):
    # Server类的实例方法
    def welcomeMessage(self, name):
        return ("Hi welcome " + str(name))

    def startServer():
        # 构建类的实例
        server = Server()
        # 创建一个Pyro守护程序
        # 使用守护程序对象将传入的调用请求分配给相应的对象。服务器必须创建一个负责管理实例的守护程序
        # 每个服务器都有一个这样的守护程序，它掌握了该服务器提供的所有Pyro对象
        daemon = Pyro4.Daemon()
        # 执行脚本前，必须运行一个Pyro名称服务器，因此需定位该名称服务器
        ns = Pyro4.locateNS()
        # 需要将该服务器注册为Pyro对象object,只有在Pyro守护程序内部才知道该对象
        # 返回注册对象的URI
        uri = daemon.register(server)
        # 在名称服务器中使用一个名称注册该对象服务器
        ns.register("server", uri)
        print("Ready. Object uri = ", uri)
        # 函数运行结束，将调用守护程序的eventloop方法。将启动服务器的事件循环，并等待其他调用传入
        daemon.requestLoop()

if __name__ == "__main__":
    startServer()
```

- client

```python
import Pyro4

uri = input("What is the Pyro uri of the greeting object?")
name = input("What is your name? ").strip()
# 客户端向服务器发送执行命令，该远程调用首先会创建一个代理对象(Proxy object)。
# 事实上，Pyro4客户端使用代理对象转发对远程对象的方法调用，并将结果传递回调用代码
server = Pyro4.Proxy("PYRONAME:server")
print(server.welcomeMessage(name))
```

- 运行

```python
# 运行一个Pyro名称服务器(name server)
python -m Pyro4.naming
# 运行服务器
python server.py
# 运行客户端
python client.py

# 依次输入信息
PYRONAME:server
LiLei
```

### 链接对象

使用Pyro4创建一个对象链，其中的对象互相调用。

![使用Pyro4链接对象](images/使用Pyro4链接对象.png)

有4个对象：1个客户端，以及按链式拓扑分布的3个服务器，如上图所示，客户端将请求转发至Server1并启动了链式调用(chain call)，后者再将请求转发至Server2.然后，它再调用链中的下一个对象Server3.当Server3再次调用Server1时，链式调用结束。

要使用Pyro4实现一个对象链，需要5个python脚本。

- client

```python
# client.py
from __future__ import print_function
import Pyro4

# 调用链中的第一个元素(server_1)启动进程
obj = Pyro4.core.Proxy("PYRONAME:example.chain.A")
print("Result=%s" % obj.process(["hello"]))
```

- server

每个服务器中都有一个明显的参数this以及一个next参数，前者在对象链中表示自身，后者定义了链中的下一个服务器(this后面的那个服务器)

Server_1

```python
# server_1.py
from __future__ import print_function
import Pyro4
import chainTopology

# 服务器定义
this = "1"
next = "2"

# 与链中下一个元素之间的通信过程
servername = "example.chainTopology." + this
daemon = Pyro4.core.Daemon()
obj = chainTopology.Chain(this, next)
uri = daemon.register(obj)
ns = Pyro4.naming.locateNS()
ns.register(servername, uri)

# 进入服务循环
print("server_%s started " % this)
daemon.requstLoop()
```

Server_2

```python
# server_2.py
from __future__ import print_function
import Pyro4
import chainTopology


this = "2"
next = "3"

servername = "example.chainTopology." + this

daemon = Pyro4.core.Daemon()
obj = chainTopology.Chain(this, next)
uri = daemon.register(obj)
ns = Pyro4.naming.locateNS()
ns.register(servername, uri)

# 进入服务循环
print("server_%s started " % this)
daemon.requstLoop()
```

Server_3

```python
# server_3.py
from __future__ import print_function
import Pyro4
import chainTopology


this = "3"
next = "1"

servername = "example.chainTopology." + this

daemon = Pyro4.core.Daemon()
obj = chainTopology.Chain(this, next)
uri = daemon.register(obj)
ns = Pyro4.naming.locateNS()
ns.register(servername, uri)

# 进入服务循环
print("server_%s started " % this)
daemon.requstLoop()
```

chain对象

```python
# chainTopology.py
from __future__ import print_function
import Pyro4


class Chain(object):
    """支持服务器间的通信"""
    def __init__(self, name, next):
        self.name = name
        self.nextName = next
        self.next = None

    def process(self, message):
        if self.next is None:
            # 调用执行
            self.next = Pyro4.core.Proxy("PYRONAME:example.chain." + self.nextName)
        if self.name in message:
            # 若是链关闭(3到1的最后一次调用)
            print("Back at %s; the chain is closed!" % self.name)
            return ["complete at " + self.name]
        else:
            # 若链中还存在下一个元素
            print("%s forwarding the message to the object %s" % (self.name, self.nextName))
            message.append(self.name)
            result = self.next.process(message)
            result.insert(0, "passed on from " + self.name)
            return result
```

- 运行

```python
# Pyro4名称服务器
python -m Pyro4.naming
# 运行服务器
python server_1.py
python server_2.py
python server_3.py
# 运行客户端
python client.py
```

### 客户端/服务器

客户端-服务器应用指的是一种网络架构，其中客户端电脑或中断连接至服务器，使用某个特定服务，如遇其他客户端一起分享硬件或软件资源，共用相同的底层协议架构。在示例体中，服务器管理着一个在线购物站点，而客户端则管理在站点上注册并连接进行购物的客户。

- server

```python
# server.py
from __future__ import print_function
import Pyro4
import shop

# 定位Shop()对象
ns = Pyro4.naming.locateNS()
# 启用一个通信通道
daemon = Pyro4.core.Daemon()
uri = daemon.register(shop.Shop())
ns.register("example.shop.Shop", uri)
print(list(ns.list(prefix="example.shop.").keys()))
daemon.requestLoop()
```

- client

```python
# clinet.py
from __future__ import print_function
import sys
import Pyro4

# shop客户端
class Client(object):
    def __init__(self, name, cash):
        self.name = name
        self.cash = cash

    def doShopping_deposit_cash(self, Shop):
        print("\n*** %s is doing shopping with %s:" % (self.name, Shop.name()))
        print("Log on")
        Shop.logOn(self.name)
        print("Deposit money %s" % self.cash)
        Shop.deposit(self.name, self.cash)
        print("balance=%.2f" % Shop.balance(self.name))
        print("Deposit money %s" % self.cash)
        Shop.deposit(self.name, 50)
        print("balance=%.2f" % Shop.balance(self.name))
        print("Log out")
        Shop.logOut(self.name)

    def doShopping_buying_a_book(self, Shop):
        print("\n*** %s is doing shopping with %s:" % (self.name, Shop.name()))
        print("Log on")
        Shop.logOn(self.name)
        print("Deposit money %s" % self.cash)
        Shop.deposit(self.name, self.cash)
        print("balance=%.2f" % Shop.balance(self.name))
        print("%s is buying a book for %s" % (self.name, 37))
        Shop.buy(self.name, 37)
        print("Log out")
        Shop.logOut(self.name) 

if __name__ == "__main__":
    ns = Pyro4.naming.locateNS()
    uri = ns.lookup("example.shop.Shop")
    print(uri)
    Shop = Pyro4.core.Proxy(uri)
    # 实例化客户Meeta、Rashmi
    meeta = Client('Meeta', 50)
    rashmi = Client('Rashmi', 100)
    # 购买一本书
    rashmi.doShopping_buying_a_book(Shop)
    # 分两次存钱
    meeta.doShopping_deposit_cash(Shop)
    print("")
    print("")
    print("")
    print("")
	# 报告Meeta和Rashmi账户中的余额
    print("The accounts in the %s:" % Shop.name())
    accounts = Shop.allAccounts()
    for name in accounts.keys():
        print(" %s: %.2f" % (name, accounts[name]))
```

- Shop

```python
# shop.py
class Account(object):
    """每个客户都有自己的Account对象，该对象提供了管理客户储蓄的方法"""
    def __init__(self):
        self._balance = 0.0
    
    def pay(self, price):
        self._balance -= price

    def deposit(self, cash):
        self._balance += cash

    def balance(self):
        return self._balance


class Shop(object):
    """管理每个账户，提供登入、登出的方法，管理客户的资金，并购买物品"""
    def __init__(self):
        self.accounts = {}
        self.clients = ['Meeta', 'Rashmi', 'John', 'Ken']

    def name(self):
        return 'BuyAnythingOnline'

    def logOn(self, name):
        if name in self.clients:
            self.accounts[name] = Account()
        else:
            self.clients.append(name)
            self.accounts[name] = Account()

    def logOut(self, name):
        print('logout %s' % name)

    def deposit(self, name, amount):
        try:
            return self.accounts[name].deposit(amount)
        except KeyError:
            raise KeyError('unknown account')

    def balance(self, name):
        try:
            return self.accounts[name].balance()
        except KeyError:
            raise KeyError('unknown account')

    def allAccounts(self):
        accs = {}
        for name in self.accounts.keys():
            accs[name] = self.accounts[name].balance()
        return accs

    def buy(self, name, price):
        balance = self.accounts[name].balance()
        self.accounts[name].pay(price)
```

- 运行

```python
# 启动Pyro4名称服务器
python -m Pyro4.naming
# 启动服务器
python server.py
# 启动客户端
python client.py
```

## PyCSP

PyCSP是基于痛惜你的顺序进程(communicating seauential process,简称CSP)的一个python模块，它是通过消息传递方式构建并发程序的一种编程范式。具有如下特点

```
- 进程间的消息交换
- 通过线程使用共享内存
- 通过通道完成消息交换
```

通道支持

```
- 进程间交换值
- 进程同步
```

PyCSP允许使用不同类类型的通道:One2One,One2Any,Any2One,Any2Any.这些名称说明了可以通过通道进行通信的write和reader的个数

CSP是一种用于描述并发进程间交互的形式语言。属于竞争数学理论的范畴，叫做进程代数(algebra process)。在实践中，CSP被用作一种规格书写工具，并用于验证多种系统的竞争特性。受CSP理论启发而编写的编程语言Occam现在被广泛用于并发编程语言。[参考](http://www.usingcsp.com/cspbook.pdf)

### 安装

```python
# pip安装
pip install python-csp
# 源码安装(https://github.com/futurecore/python-csp)
python setup.py install
```

### 示例

使用python2.7

```python
# pycsp.parallel中有一个Any2Any通道类型，支持多进程(依附在通道的两端)通过它进行通信
from pycsp.parallel import *


# 使用装饰器表示一个进程。
# 在PyCSP中，每个生成的CSP进程是以某个OS线程的形式实现的。
@process
def processCounter(cout, limit):
    # cout用于重定向输出
    # limit定义要打印的项数
    for i in xrange(limit):
        cout(i)
    # poison语句意味着通道的这一端被污染了。之后所有这个通道上的读写操作都将抛出一个可以用于结束当前过程或断开通道连接的异常。若存在多个并发过程，可能会导致竞争条件(race condition)
    poison(cout)

@process
def processPrinter(cin):
    # cin表示要打印的项
    while True:
        print cin(),

# 创建通道A，这个新通道自动托管在当前的python解释器中。允许两个进程间进行通信
# 对于每个导入了pyscp.parallel模块的python解释器，只会列出负责处理python解释器中启动的所有通道的端口。不过，该模块并没有为通道提供可用的名称服务器。因此，如果要链接一个托管的通道必须知道正确的位置
# A = pyscp.Channel('B', connect=('localhost', 8888))
A = Channel('A')

# 会启动所有进程，只有在counter和process进程结束相互之间的通信时才会阻塞。
# 代表了CSP的一个基本思想：并行进程通过利用A通道同步I/O来实现同步。
# 一种实现方法是只在counter进程表示准备好向printer进程输出、printer进程表示准备好接收来自counter进程的输入时，才允许进行I/O操作。若果二者有一个不成立，已做好准备的进程将进入等待队列，直到另一个进程做好准备。
Parallel(
    processCounter(A.writer(), limit=5),
    processPrinter(A.reader())
)
# 每个PySCP应用会创建一个服务器线程，用于管理通过通道传来的通信。因此在结束PyCSP应用时调用shutdown()
shutdown()
```

PyCSP中有三种管理通道的方法

| 方法                   | 说明                                                         |
| ---------------------- | ------------------------------------------------------------ |
| `channel.Disconnect()` | 允许退出Python解释器。其用在某个客户端-服务器设置里，其中客户端在收到服务器的回复后，会断开与服务器的连接 |
| `channel.reader()`     | 创建并返回通道的reader端                                     |
| `channel.writer()`     | 创建并返回通道的writer端                                     |

PyCSP有两种追踪执行过程的方法

| 方法                                         | 说明             |
| -------------------------------------------- | ---------------- |
| `TraceInit(<filename>, stdout=<True|False>)` | 用于开启追踪过程 |
| `TraceQuit()`                                | 用于停止追踪过程 |

使用方法

```python
from pycsp.common.trace import *
TraceInit('trace.log')  # 打算追踪的进程
TraceQuit()
shutdown()
```

## Disco

Disco是一个基于谷歌推出的MapReduce框架的python模块，支持在计算机集群中管理大规模分布式数据。使用Disco便可的应用可以在经济型计算哦集群中运行，学习曲线非常短。事实上，与分布式进程相关的技术难点，如负载均衡、工作调度及通信协议，可完全由Disco进行管理，不需要开发者处理。

应用场景

```
- Web索引
- URL访问计数
- 分布式排序
```

Disco中实现的MapReduce算法如下所示

```
Map
主节点(master node)接受输入数据，将其拆分为更小的子任务，然后把工作分发给slave节点。单个map节点生成map()函数的中间结果，以[key, value]对的形式存储在一个分布式文件中。在这步最后，主节点将获得该文件的地址
Reduce
主节点收集结果，并将[key, value]对中共享同一个键的值整合在一起，然后按照键进行排序(字母顺序或用户自定义)。[key, IteratorList(value, value,...)]这种形式的键值对被传递给运行归约函数reduce()的节点
```

存储在文件中的输出数据可以作为新的map和reduce过程的输入数据，可以将多个MapReduce工作凭借在一起。

### 安装

依赖

```
- Linux/UNIX系统
- SSH守护程序和客户端
- Erlang/OTP R14A或更高版本
- >=python2.6.6或>=python3.2
```

安装

[参考](https://Disco.readthedocs.org/)

```shell
git clone git://github.com/Discoproject/Disco.git $Disco_Home
cd $Disco_Home
make
cd lib && python setup.py install -- user && cd ..
bin/Disco nodaemon
# 在Disco集群的所有服务器中启用无须密码登陆
# 若是单一机器安装
ssh-keygen -N '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
```

给定一段文本，统计文本中某些词的出现次数

```python
from Disco.core import Job, result_iterator

	# 将句子分割成一个或多个单词，不考虑标点符号，并且所有单词都转换成小写字母
    # 对一行文本执行map函数的结果是一系列元组
    def map(line, params):
        import string
        for word in line.split():
            strippedWord = word.translate(string.maketrans("", ""), string.punctuation) 
            # MapReduce框架可操作的数据集非常大，比单台机器上常见的内存要大很多，因此，map函数最后的yield关键字让Disco以更加聪明的方式管理数据。reduce函数接受2个参数，iter指的是可迭代对象(行为类似列表数据结构)。
            yield strippedWord, 1
	
    # 使用python函数将每个可迭代对象按照字母顺序进行排序
    def reduce(iter, params):
        from Disco.utils import kvgroup
        # 在排好序的列表上应用Disco中的kvgroup函数，依次将等同键的值归组在一起，最后，通过python函数计算出文本中每个单词的出现次数
        for word, counts in kvgroup(sorted(iter)):
            yield word, sum(counts)

if __name__ == "__main__":
    job = Job().run(input="There are known knows.\
                           These are things we know that we know.\
                           These are known unknown.\
                           That is to say,\
                           there are things that\
                           we know we do not know.\
                           But there are also unknown unknowns.\
                           There are things\
                           we do not know we do not know",
                    map=map,
                    reduce=reduce)
    # 将结果按照数字大小和字母顺序进行排序，并打印到两个输出文件中
    sort_in_numberical_order = open('SortNumberical.txt', 'w')
    sort_in_alphabetcally_order = open('SortAlphabetical.txt', 'w')

    wordCount = []
    for word, count in result_iterator(job.wait(show=True)):
        sort_in_alphabetcally_order.write('%s \t %d\n' % (str(word), int(count)))
        wordCount.append((word, count))
    sortedWordCount = sorted(wordCount, key=lambda count: count[1], reverse=True)
    for word, count in sortedWordCount:
        sort_in_numberical_order.write('%s \t %d\n' % (str(word), int(count)))
    sort_in_alphabetcally_order.close()
    sort_in_numberical_order.close()
```

## RPyc

Remote Python Call(RPyc)是一个用于远程过程调用和分布式计算的python模块。RPC的基础理念是，提供将控制权从一个程序(客户端)转交给另一个程序(服务器)的机制，类似于集中式程序中子协程(subroutine)的调用过程，如下图所示

![远程过程调用模式](images/远程过程调用模式.png)

这种方法的好处在于，它的语义和语法非常简单，而且类似集中式的函数调用。在调用过程时，客户端进程暂停，直到服务端进程执行完必要的计算，并返回计算的结果。该方法之所以有效，是应为客户端-服务器通信以过程调用的形式进行，而不是调用传输层，因此，通过将网络操作放在被称为stub的本地过程中，可以把全部细节隐藏起来，不需应用程序直接操作。RPyC的主要特性如下：

```
- 在语法透明性上，远程过程调用的语法与本地调用语法相同
- 在语义透明性上，远程过程调用在语义上等同本地调用
- 支持同步和异步通信
- 对称通信协议意味着客户端和服务端均可服务请求
```

### 安装

```python
# pip
pip install rpyc
# 源码
下载https://github.com/tomerfiliba/rpyc
python setup.py
```

### 示例

连接服务器

```python
c = rpyc.classic.connect(host, port)

# 创建一个与给定主机和端口的套接字连接。套接字定义了连接的端点。rpyc使用套接字与可能分布于不同机器中的其他程序进行通信。
```

在同一台机器上运行客户端和服务器

```python
import rpyc
import sys

# 连接服务器的客户端
c = rpyc.classic.connect("localhost")
# 在服务器上执行打印语句
c.execute("print('hi python cookbook')")
c.modules.sys.stdout = sys.stdout
c.execute("prit('hi here')")
```

- 运行

```shell
cd rpyc-master/bin
python rpyc_classic.py
```

