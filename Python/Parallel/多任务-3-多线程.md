[TOC]

# 多线程

## 概述

由于线程是操作系统直接支持的执行单元，因此，高级语言通常都内置多线程的支持，Python也不例外，并且，Python的线程是真正的Posix Thread，而不是模拟出来的线程。

```
Python的标准库提供了两个模块：_thread和threading，_thread是低级模块，threading是高级模块，对_thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。

避免_thread使用threading模块，原因：1.高级别的更先进，对多线程支持更完善；2.低级别的同步原语少，threading的多；3._thread模块在主线程结束时，所有线程会被强制结束，无警告也无征程清除工作。threading模块则不会。
```

- 线程的退出

```
1.当一个线程结束计算，自然退出。
2.调用_thread.exit()，退出。
3.退出进程的方法:sys.exit()或抛出SystemExit异常
```

- threading

```python
由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2…

_thread模块不支持守护线程，当主线程退出，所有子线程全部强制退出。threading模块支持守护线程。如果设定一个线程为守护线程，表示这个线程不重要，在进程退出时，不用等待这个线程退出。若主线程退出时不用等待子线程完成，则在线程Thread.start()前，设定Thread.setDaemon(True)。若一定要等待子线程的执行完成再退出主线程，则使用默认情况或显式调用Thread.setDaemon(False)。新的子线程会继承父线程的daemon标志。整个python在所有非守护线程退出后才会结束。
```

> 常用方法

标准库threading提供的常用方法

| 方法                             | 说明                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| `active_count()`、`activeCount()`    | 返回当前处于alive状态的Thread对象数量                        |
| `current_thread()`、`curentThread()` | 返回当前Thread对象                                           |
| `get_ident()`                      | 返回当前线程的线程标识符。线程标识符是一个非负整数，这个整数本身并无特殊含义，只是用来标识线程，可能会被循环利用 |
| `enumerate() `                     | 返回当前处理alive状态的所有与Thread对象列表                  |
| `local() `                         | 线程局部数据类                                               |
| `main_thread()`                    | 返回主线程对象，即启动python解释器的线程对象                 |
| `stack_size([size])`               | 返回创建线程时使用的栈的大小，若指定size参数，则用来指定后续创建的线程使用的栈大小，size必须是0(表示使用系统默认值)或大于32K的正整数 |
| `setprofile(func)`                 | 设置之后每个线程启动之前都会把func函数传递给`sys.setprofile()` |
| `settrace(func)`                   | 设置之后每个线程启动之前都会把func函数传递给`sys.settrace()`   |
| TIMEOUT_MAX                      | 线程同步获取锁时的最大允许等待时间                           |
| Thread                           | 线程类，用于创建和管理线程                                   |
| Event                            | 事件类，用于线程同步                                         |
| Condition                        | 条件类，用于线程同步                                         |
| Lock\Rlock                       | 锁类，用于线程同步                                           |
| Semaphore\BoundedSemaphore       | 信号量类，用于线程同步                                       |
| `Timer()`                        | 用于在指定时间之后调用一个函数                               |

## Thread

Thread对象的主要成员

| 成员                                                         | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `start()`                                                    | 自动调用run()方法，启动线程，执行线程代码。每个线程只能启动一次 |
| `run()`                                                      | 线程代码，用来实现线程的工鞥与业务逻辑，可以在子类中重写该方法来自定义线程的行为 |
| `__init__(self,group=None,target=None,name=None,args=(),kwargs=None,verbose=None)` | 构造方法                                                     |
| name                                                         | 读取或设置线程的名字                                         |
| ident                                                        | 线程标识，非0数字或None(线程未被启动)                        |
| daemon                                                       | 布尔值，标识线程是否是守护线程                               |
| `join(timeout=None)`                                         | 等待线程结束或超时返回                                       |
| `getName()`                                                  | 返回线程的名字                                               |
| `setName(name)`                                              | 设置线程的名字                                               |
| `isAlive()`                                                  | 布尔标志，表示这个线程是否还在运行中                         |
| `isDaemon()`                                                 | 返回线程的deemon标志                                         |
| `setDaemon(daemonic)`                                        | 把线程的daemon标志设置成daemonic                             |

- 构造函数

```
threading.Thread(group=None, target=None, name=None, args=(), kwargs={})
```

| name   | desc                                                         |
| ------ | ------------------------------------------------------------ |
| group  | None，是一个保留参数，供未来实现所用                         |
| target | 在启动一个线程活动时将会执行的函数                           |
| name   | 线程的名字，在默认情况下，形式为Thread-N的唯一的名字会赋给它 |
| args   | 传给目标的一个参数元组                                       |
| kwargs | 关键字参数字典，供目标函数所用                               |

- daemon

```
在多线程编程中，若子线程需要访问主线程中的资源(如变量),当退出程序时主线程结束后这些资源不再存在，子线程继续运行时会因为无法访问资源而引发异常导致崩溃。因此需要一种机制保证主线程结束时可以同时结束子线程，或者使得主线程等待子线程运行结束后再结束。daemon作用即此

在程序运行过程中有一个主线程，若在主线程中创建了子线程，当主线程结束时，根据子线程的daemon属性值的不同会发生如下情况之一：
1.若子线程的daemon为False,主线程结束时会检测该子线程是否结束，若还在运行，则主线程会等待子线程完成后再推出
2.若子线程的daemon为True,主线程运行结束时不对这个子线程进行检查而直接退出，同时所有daemon为True的子线程将随着主线程一起结束，而不论是否运行完成

属性daemon默认为False,若需要修改，必须在调用start()之前设置。上面的描述并不适用于IDLE环境中的交互模式或脚本运行模式，在该环境中的主线程只有在退出IDLE时才终止
```

- join

```
阻塞当前线程，等待被调线程结束或超时后再继续执行当前线程的后续代码，参数timeout用来指定最长等待时间，单位为秒。
方法join()返回后再调用isAlive()方法，若是True则说明线程人在运行并且join()方法是因为超时而返回的，若是False则说明join()方法是因为线程结束而返回的。
一个线程可以调用多次join()方法(若是线程已经结束，join()会立即返回),但不允许对当前线程调用join()，否则抛出异常
```

### Thread类实例化

创建线程对象的方法

```
1. 创建一个Thread实例，传给它一个函数
2. 创建一个Thread实例，传给它一个可调用的类的对象
3. 从Thread派生一个子类，创建这个子类的实例
```

创建了线程对象之后，可以调用其start()方法来启动，该方法自动调用该类对象的run()方法，此时该线程处于alive状态，直至线程的run()方法运行结束

```python
from threading import Thread
import time

def get_detail_html(url):
    print("get detail html started")
    time.sleep(2)
    print("get detail html end")


def get_detail_url(url):
    print("get detail url started")
    time.sleep(4)
    print("get detail url end")

    
if __name__ == "__main__":
    # 在主线程中，类实例化，创建线程，默认为非守护线程
    t1 = Thread(target=get_detail_html, args=("",))
    t1 = Thread(target=get_detail_url, args=("",))
    # 修改线程为守护线程,主线程退出时，kill守护线程
    t2.daemon = True  # 方法一：直接修改属性值
    t2.setDaemon(True)  # 方法二：使用函数修改
    start_time = time.time()
    # 线程开始执行
    t1.start()
    t2.start()
    # 是否阻塞当前主线程，等待子线程结束或超时
    t1.join()
    t2.join()
    print("last time: {}".foramt(time.time()-start_time))
```

### 集成Thread类

```
定义新的Thread类的子类
重写__init__(self, [,args])方法来添加额外的参数
重写run(self, [, args])方法来实现线程启动后需要做的事情
创建好Thread子类后，创建实例，通过start()方法开启新的线程，此方法会调用run()方法
```

实现1

```python
import time
import threading

class GetDetailHtml(threading.Thread):
    def __init__(self, name):
        super().__init__(name=name)

    def run(self):
        print("get detail html started")
        time.sleep(2)
        print("get detail html end")


class GetDetailUrl(threading.Thread):
    def __init__(self, name):
        super().__init__(name=name)

    def run(self):
        print("get detail url started")
        time.sleep(4)
        print("get detail url end")

if  __name__ == "__main__":
    thread1 = GetDetailHtml("get_detail_html")
    thread2 = GetDetailUrl("get_detail_url")
    start_time = time.time()
    thread1.start()
    thread2.start()
    thread1.join()
    thread2.join()
    print ("last time: {}".format(time.time()-start_time))
```

实现2

```python
import threading
import time

exitFlag = 0

# 继承Thread类，创建自定义线程类
class mythread(threading.Thread):  
    def __init__(self, threadID, name, counter):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.counter = counter
    
    # 重写run()方法
    def run(self):  
        print('Starting ' + self.name)
        print_time(self.name, self.counter, 5)
        print('Exiting ' + self.name)

def print_time(threadName, delay, counter):
    while counter:
        if exitFlag:
            thread.exit()
        time.sleep(delay)
        print('%s: %s' % (threadName, time.ctime(time.time())))
        counter -= 1

# 创建新线程
t1 = mythread(1, 'Thread-1', 1)
t2 = mythread(2, 'Thread-2', 2)  
# 启动新线程
t1.start()
t2.start()
print('Exiting Main Thread')
```

## 线程池

从`Python3.2`开始，标准库为我们提供了`concurrent.futures`模块，它提供了`ThreadPoolExecutor`和`ProcessPoolExecutor`两个类，实现了对`threading`和`multiprocessing`的进一步抽象，不仅可以帮我们自动调度线程，还可以做到：

1. 主线程可以获取某一个线程（或者任务的）的状态，以及返回值。
2. 当一个线程完成的时候，主线程能够立即知道。
3. 让多线程和多进程的编码接口一致

### ThreadPoolExecutor

[参考](https://www.jianshu.com/p/b9b3d66aa0be)

在python3.2之后，python引入了concurrent.futures模块，支持管理并发编程任务，如进程池和线程池、非确定性执行流以及多进程和线程同步。该模块包含以下几类

| 类及方法                      | 说明                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| `concurrent.futures.Executor` | 抽象类，提供异步执行调用的方法                               |
| `submit(function, argument)`  | 安排某个函数(可调用对象)使用给定参数执行，返回一个Future对象 |
| `map(function, argument)`     | 以异步模式使用给定参数来执行函数。与内置函数map(func, *iterables)等价的异步执行方法，多个func的调用可以并发执行 |
| `shutdown(wait=True)`         | 向执行器(executor)传递释放资源的信号。通知Executor对象执行完当前Future对象之后释放所有资源，若参数wait为True，则shutdown()方法等待执行结束并释放有关资源之后再返回，否则立即返回 |
| `concurrent.futures.Future`   | 封装一个可调用函数的异步执行。通过向执行器提交任务(带可选参数的函数)来实例化Future对象 |

执行器是一种抽象类，通过其子类来访问：线程或进程的`ExecutorPools`。实际上，实例化线程和进程是比较耗资源的任务，所以最好将这些资源聚集起来，把它们变成可重复使用的发射器(launcher)或执行器(执行器概念由此而来)，用于并行或并发执行任务。

`current.Futures`模块提供了Executor类的两个子类

```python
concurrent.futures.ThreadPoolExecutor(max_works)
# 异步式地管理一个线程池
concurrent.futures.ProcessPoolExecutor(max_works)
# 异步式地管理一个进程池

# 参数
max_works		用于异步执行调用的最大worker数量
```

简单使用

```python
from concurrent.futures import ThreadPoolExecutor
import time


def get_html(times):
    time.sleep(times)
    print("get page {}s finished".format(times))
    return times

executor = ThreadPoolExecutor(max_workers=2)  # 构造实例传入max_workers参数来设置线程池中最多能同时运行的线程数目。
task1 = executor.submit(get_html, (3))  # 通过submit函数提交执行的函数到线程池中，并返回该任务的句柄（concurrent.futures.Future对象）,submit函数立即返回，不阻塞
task2 = executor.submit(get_html, (2))
print(task1.done())  # 通过submit函数返回的任务句柄,done方法返回True/False,用于判定某个任务是否完成
print(task2.cancel())  # 通过submit函数返回的任务句柄,cancel方法用于取消某个任务,该任务没有放入线程池中才能取消成功
time.sleep(4)
print(task1.done())
print(task1.result())  # result方法可以获取task的执行结果,是阻塞的

# 执行结果
False  # 表明task1未执行完成
False  # 表明task2取消失败，因为已经放入了线程池中
get page 2s finished
get page 3s finished
True  # 由于在get page 3s finished之后才打印，所以此时task1必然完成了
3     # 得到task1的任务返回值
```

- as_completed

`as_completed()`方法是一个生成器，在没有任务完成的时候，会阻塞，在有某个任务完成的时候，会yield这个任务，就能执行for循环下面的语句，然后继续阻塞住，循环到所有的任务结束。从结果也可以看出，先完成的任务会先通知主线程。

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time


def get_html(times):
    time.sleep(times)
    print("get page {}s finished".format(times))
    return times

executor = ThreadPoolExecutor(max_workers=2)
urls = [3, 2, 4] # 并不是真的url
all_task = [executor.submit(get_html, (url)) for url in urls]

for future in as_completed(all_task):  
    data = future.result()
    print("in main: get page {}s success".format(data))

# 执行结果
get page 2s finished
in main: get page 2s success
get page 3s finished
in main: get page 3s success
get page 4s finished
in main: get page 4s success
```

- map

使用map方法，无需提前使用submit方法，map方法与python标准库中的map含义相同，都是将序列中的每个元素都执行同一个函数。上面的代码就是对urls的每个元素都执行get_html函数，并分配各线程池。可以看到执行结果与上面的as_completed方法的结果不同，输出顺序和urls列表的顺序相同，就算2s的任务先执行完成，也会先打印出3s的任务先完成，再打印2s的任务完成。

```python
from concurrent.futures import ThreadPoolExecutor
import time

# 参数times用来模拟网络请求的时间
def get_html(times):
    time.sleep(times)
    print("get page {}s finished".format(times))
    return times

executor = ThreadPoolExecutor(max_workers=2)
urls = [3, 2, 4] # 并不是真的url

for data in executor.map(get_html, urls):
    print("in main: get page {}s success".format(data))

# 执行结果
get page 2s finished
get page 3s finished
in main: get page 3s success
in main: get page 2s success
get page 4s finished
in main: get page 4s success
```

- wait

`wait`方法可以让主线程阻塞，直到满足设定的要求。

```python
wait(fs, timeout=None, return_when=ALL_COMPLETED)

# 参数
等待的任务序列、超时时间、等待条件。
return_when默认为ALL_COMPLETED，表明要等待所有的任务都结束FIRST_COMPLETED，表示第一个任务完成就停止等待
FIRST_EXCEPTION，表示第一个任务出现异常停止等待
```

代码

```python
from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED
import time


def get_html(times):
    time.sleep(times)
    print("get page {}s finished".format(times))
    return times

executor = ThreadPoolExecutor(max_workers=2)
urls = [3, 2, 4] # 并不是真的url
all_task = [executor.submit(get_html, (url)) for url in urls]
wait(all_task, return_when=ALL_COMPLETED) 
print("main")

# 执行结果 
get page 2s finished
get page 3s finished
get page 4s finished
main
```

综合示例

```python
import concurrent.futures
import time

# 创建一个数字列表，对于列表中的每个元素，执行计数程序，直到完成1000万次迭代，然后将得到的结果乘以10000000
number_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

def evaluate_item(x):
    # 计数， 仅为了执行一些操作而已
    result_item = count(x)
    print("item " + str(x) + " result " + str(result_item))

def count(number):
    for i in range(0, 10000000):
        i = i + 1
    return i*number


if __name__ == "__main__":
    # 线性执行
    start_time = time.clock()
    for item in number_list:
        evaluate_item(item)
    print("Sequential execution in " + str(time.clock() - start_time), "seconds")

    # 线程池执行
    # ThreadPoolExecutor使用其内部已经池化的线程执行给定的任务。它将管理在池子中工作的5个线程。
    # 每个线程从池子里接受并执行一个job。执行完成后，线程将从线程池获取要处理的下一个工作
    start_time_1 = time.clock()
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        for item in number_list:
            executor.submit(evaluate_item, item)
    print("Thread pool execution in " + str(time.clock() - start_time_1), "seconds")

    # 进程池执行
    # ProcessPoolExecutor使用的是multiprocessing模块，可以避开全局解释器锁，大幅降低执行时间
    start_time_2 = tiem.clock()
    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:
        for item in number_list:
            executor.submit(evaluate_item, item)
    print("Process pool execution in " + str(time.clock() - start_time_2), "seconds")
```

批量移动文件

```python
from concurrent.futures import ThreadPoolExecutor
from shutil import copy
from os import listdir
from os.path import isfile, json

with ThreadPoolExecutor(max_workers=4) as e:
    for f in (fn for fn in lisdir('C:\\test')):
        src = json('C:\\test', f)
        if isfile(src):
            # 目标文件夹存在
            dst = join('D:\\test', f)
            e.submit(copy, src, dst)
```

批量快速判断素数

```python
from concurrent.futures import ProcessPoolExecutor

PRIMES = [109999999, 108376355, 1276544678, 123555677, 234645542424]
def isPrime(n):
    if n%2 == 0:
        return False
    for i in range(3, int(n**0.5)+1, 2):
        if n%i == 0:
            return False
    return True

def main():
    with ProcessPoolExecutor() as executor:
        for number, prime in zip(PRIMES, executor.map(isPrime, PRIMES)):
            print('%d is prime: %s' % (number, prime))

if __name__ == "__main__":
    main()
```

## 线程间通信

### Variable

线程间的通信方式--共享变量（不推荐）

如果是各种数据的时候，也可首选使用共享变量而非queue

共享变量的操作并不是线程安全的操作，为了达到预期的效果必须在这些操作上加上一把锁，能够安照预期的效果在线程之间按照顺序进行同步

多进程中共享变量是行不通的

全局变量

```python
# 声通过声明全局变量global的方式进行通信，非常原始并且不够灵活
import time
import threading

detail_url_list = [] 

def get_detail_html():
    global detail_url_list
    while True:
        if len(detail_url_list):
            url = detail_url_list.pop()
            # for url in detail_url_list:
            print("get detail html started")
            time.sleep(2)
            print("get detail html end")

def get_detail_url():
    global detail_url_list
    while True:
        print("get url started")
        time.sleep(2)
        for i in range(20):
            detail_url_list.append("http://projectstedu.com/{id}".format(id=i))
        print("get detail url end")



if __name__=="__main__":
    thread_detail_url = threading.Thread(target=get_detail_url) 
    thread_detail_url.start()
    for i in range(10):
        html_thread = threading.Thread(target=get_detail_html)
        html_thread.start()
    start_time = time.time()
    print("last time: {}".format(time.time() - start_time))
```

变量参数

```python
# 通过引用变量参数的方式进行通信，足够灵活
import time
import threading

detail_url_list = [] 

def get_detail_html(detail_url_list):
    while True:
        if len(detail_url_list):
            url = detail_url_list.pop()
            # for url in detail_url_list:
            print("get detail html started")
            time.sleep(2)
            print("get detail html end")

def get_detail_url(detail_url_list): 
    while True:
        print("get url started")
        time.sleep(4)
        for i in range(20):
            detail_url_list.append("http://projectstedu.com/{id}".format(id=i))
        print("get detail url end")



if __name__=="__main__":
    thread_detail_url = threading.Thread(target=get_detail_url,args=(detail_url_list,)) 	thread_detail_url.start()
    for i in range(10):
        html_thread = threading.Thread(target=get_detail_html,args=(detail_url_list,))
        html_thread.start()
    start_time = time.time()
    print("last time: {}".format(time.time() - start_time))
```
变量配置
```python
# 使用单独文件对变量处理，便于多变量管理
import time
import threadin
from chaper11 import variables  # 不推荐：from chapter11.variables import detail_url_list, 避免无法看到其他线程修改此变量


def get_detail_html(): 
    while True:
        detail_url_list = variables.detail_url_list
        if len(detail_url_list):
            url = detail_url_list.pop()
            # for url in detail_url_list:
            print("get detail html started")
            time.sleep(2)
            print("get detail html end")

def get_detail_url():
    while True:
        detail_url_list = variables.detail_url_list
        print("get url started")
        time.sleep(4)
        for i in range(20):
            detail_url_list.append("http://projectstedu.com/{id}".format(id=i))
        print("get detail url end")



if __name__=="__main__":
    thread_detail_url = threading.Thread(target=get_detail_url) 	thread_detail_url.start()
    for i in range(10):
        html_thread = threading.Thread(target=get_detail_html)
        html_thread.start()
    start_time = time.time()
    print("last time: {}".format(time.time() - start_time))
```
### Queue
线程间的通信方式--通过queue的方式进行线程间同步（推荐）

线程间需要通信，使用全局变量需要加锁。

使用queue模块，可在线程间进行通信，并保证了线程安全。

```python
# queue是线程安全，不加锁，效率高，因为queue用了python中的deque() 双端队列，而deque（）则是线程安全的，在字节码的级别上就已经达到了线程安全
from queue import Queue
import time
import threading

detail_url_list = [] 

def get_detail_html(queue): 
    while True:
        url = queue.get()
        # for url in detail_url_list:
        print("get detail html started")
        time.sleep(2)
        print("get detail html end")


def get_detail_url(queue): 
    while True:
        print("get url started")
        time.sleep(4)
        for i in range(20):
            queue.put("http://projectstedu.com/{id}".format(id=i)) #阻塞等待有空闲空间为止（put，参数block默认为True，阻塞状态,可以设置timeout）
        print("get detail url end")



if __name__=="__main__":
    detail_url_queue = Queue(maxsize=1000)
    thread_detail_url = threading.Thread(target=get_detail_url,args=(detail_url_list,)) #线程1
    thread_detail_url.start()
    for i in range(10):
        html_thread = threading.Thread(target=get_detail_html,args=(detail_url_list,))
        html_thread.start()

    # detail_url_queue.task_done()  调用task_done()函数join()函数才会退出，停止退出的作用
    # detail_url_queue.join()  阻塞等待

    start_time = time.time()
    # 当主线程退出的时候，子线程kill掉
    print("last time: {}".format(time.time() - start_time))
```

## 线程间同步

各个线程可以访问进程中的公共变量，资源，所以使用多线程的过程中需要注意的问题是如何防止两个或两个以上的线程同时访问同一个数据，以免破坏数据的完整性。数据之间的相互制约包括
 1、直接制约关系，即一个线程的处理结果，为另一个线程的输入，因此线程之间直接制约着，这种关系可以称之为同步关系
 2、间接制约关系，即两个线程需要访问同一资源，该资源在同一时刻只能被一个线程访问，这种关系称之为线程间对资源的互斥访问，某种意义上说互斥是一种制约关系更小的同步

### Lock

- 互斥锁

```
当多个线程几乎同时修改某一个共享数据的时候，需要进行同步控制

线程同步能够保证多个线程安全访问竞争资源，最简单的同步机制是引入互斥锁。

互斥锁为资源引入一个状态：锁定/非锁定

某个线程要更改共享数据时，先将其锁定，此时资源的状态为“锁定”，其他线程不能更改；直到该线程释放资源，将资源的状态变成“非锁定”，其他的线程才能再次锁定该资源。互斥锁保证了每次只有一个线程进行写入操作，从而保证了多线程情况下数据的正确性。
```

threading模块中定义了Lock类，可以方便的处理锁定：

```python
# 创建锁
mutex = threading.Lock()
# 锁定
mutex.acquire()
# 释放
mutex.release()

# 注意：
若锁之前是unlocked状态，那么acquire会锁定并立即返回
若锁之前是locked状态，那么acquire会堵塞，直到这个锁被解锁为止
若锁之前是locked状态，那么release会上锁并立即返回
若锁之前是unlocked状态，release会抛出异常
```

使用互斥锁完成2个线程对同一个全局变量各加100万次的操作

```python
import threading
import time

g_num = 0

def test1(num):
    global g_num
    for i in range(num):
        mutex.acquire()  # 上锁
        g_num += 1
        mutex.release()  # 解锁

    print("---test1---g_num=%d"%g_num)

def test2(num):
    global g_num
    for i in range(num):
        mutex.acquire()  # 上锁
        g_num += 1
        mutex.release()  # 解锁

    print("---test2---g_num=%d"%g_num)

# 创建一个互斥锁,默认是未上锁的状态
mutex = threading.Lock()

# 创建2个线程，让他们各自对g_num加1000000次
p1 = threading.Thread(target=test1, args=(1000000,))
p1.start()

p2 = threading.Thread(target=test2, args=(1000000,))
p2.start()

# 等待计算完成
while len(threading.enumerate()) != 1:
    time.sleep(1)

print("2个线程对同一个全局变量操作之后的最终结果是:%s" % g_num)
```

- 死锁

```
锁的好处：
确保了某段关键代码只能由一个线程从头到尾完整地执行

锁的坏处：
阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了
由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁

避免死锁:
程序设计时要尽量避免（银行家算法）
添加超时时间等
```

### RLock

```
可重入锁RLock对象可被同一个线程acquire()多次。
当处于locked状态，某线程拥有该锁；当处于unlocked状态，该锁不属于任何线程。
RLock对象的acquire()/release()调用对可以嵌套，仅当最后一个或者最外层的release()执行结束，锁才会被设置为unlocked状态
若希望在类外面能实现线程安全的访问，同时又使用类里面相同的方法，可使用RLock()
```

代码

```python
import threading
import time

# 自定义线程类
class mythread(threading.Thread):
    def __init__(self):
        threading.Thread.__init__(self)
    
    # 重写run
    def run(self):
        global x 
        # 获取锁，若成功则进入临界区
        lock.acquire()
        x = x + 3
        print(x)
        # 退出临界区，释放锁
        lock.release()
        
lock = threading.RLock()
# 也可以使用Lock类实现
# lock = threading.Lock()

# 存放多个线程的列表
t1 = []
for i in range(10):
    # 创建线程并添加到列表
    t = mythread()
    t1.append(t)
    
# 多个线程互斥访问变量
x = 0
# 启动列表中的所有线程
for i in t1:
    i.start()
```

### Condition

条件标识了应用中状态的改变。这种同步机制是，一个线程等待特定的条件，另一个线程通知它条件已经发生。一旦条件发生，线程就会获取到锁，从而排他性地访问共享资源。

使用condition对象可以在某些事件触发后才处理数据或执行特定的功能代码，可以用于不同线程之间的通信或通知，以实现更高级别的同步

condition对象的方法

```python
acquire()
# 锁定

release()
# 释放

wait(timeout=None)
# 释放锁，并阻塞当前线程知道超时或其他线程针对同一个condition对象调用notify()/notify_all()，被唤醒的线程会重新尝试获取锁并在成功获取锁之后结束wait()方法，然后继续执行

wait_for(predicate, timeout=None)
# 阻塞当前线程直到超时或条件得到满足

notify(n=1)
# 唤醒等待该condition对象的一个或多个线程，该方法不负责释放锁

notify_all()
# 唤醒等待该condition对象的所有线程
```

条件同步机制的python内核实现

```python
# 若是没有向内部类_Condition的构造方法传递锁对象，那么它就会创建一个RLock()对象。此外，在调用acquire()与released()时会对锁进行管理
class _Condition(_Verbose):
    def __init__(self, lock=None, verbose=None):
        _Verbose.__init__(self, verbose)
        if lock is None:
            lock = RLock()
        self.__lock = lock
```

生产者/消费者队列，生产者消费者共享一个列表，生产者在列表尾部添加元素，消费者从列表首部获取并删除元素，若列表长度到了20表示已满，生产者等待，若列表为空则消费者等待

```python
import threading
from random import randint
from time import sleep

# 自定义生产者线程类
class Producer(threading.Thread):
    def __init__(self, threadname):
        threading.Thread.__init__(self, name=threadname)
        
    def run(self):
        global x
        while True:
            # 获取锁
            con.acquire()
            # 假设共享列表中最多能容纳20个元素
            if len(x) == 20:
                # 若共享列表已满，生产者等待
                con.wait()
                print('Producer is waiting...')
            else:
                print('Producer:', end=' ')
                # 生产新元素，添加至共享列表
                x.append(randint(1, 1000))
                print(x)
                sleep(1)
                # 唤醒等待条件的线程
                con.notify()
            # 释放锁
            con.release()
         
# 自定义消费者线程类
class Consumer(threading.Thread):
    def __init__(self, threadname):
        threading.Thread.__init__(self, name=threadname)
        
    def run(self):
        global x
        while True:
            # 获取锁
            con.acquire()
            if not x:
                # 等待
                con.wait()
                print('Consumer is waiting...')
            else:
                print(x.pop(0))
                print(x)
                sleep(2)
                con.notify()
            con.release()
            
# 创建Condition对象以及生产者消费者线程
con = threading.Condition()
x = []
p = Producer('Producer')
c = Consumer('Consumer')
p.start()
c.start()
p.join()
c.join()
```

示例2

```python
# coding:utf8
from threading import Thread, Condition
import time

items = []
condition = Condition()

class Consumer(Thread):
    def __init__(self):
        Thread.__init__(self)

    def consume(self):
        global condition
        global items
        # 获取共享资源
        condition.acquire()
        if len(items) == 0:
            # 等待
            condition.wait()
            print('Consumer notify: no item to consume')
        items.pop()
        print('Consumer notify: consumed 1 item')
        print('Consumer notify: items to consume are ' + str(len(items)))
        # 消费者状态通知到生产者
        condition.notify()
        # 释放共享资源
        condition.release()

    def run(self):
        for i in range(0, 20):
            time.sleep(10)
            self.consume()


class Producer(Thread):
    def __init__(self):
        Thread.__init__(self)

    def produce(self):
        global condition
        global items
        # 获取共享资源
        condition.acquire()
        if len(items) == 10:
            # 等待状态
            condition.wait()
            print('Producer notify: items producted are ' + str(len(items)))
            print('Producer notify: stop the production!!')
        items.append(1)
        print('Producer notify: total items producted ' + str(len(items)))
        condition.notify()
        condition.release()

    def run(self):
        for i in range(0, 20):
            time.sleep(5)
            self.produce()

if __name__ == "__main__":
    producer = Producer()
    consumer = Consumer()
    producer.start()
    consumer.start()
    producer.join()
    consumer.join()
```

协同读诗

```python
import threading

class XiaoAi(threading.Thread):
    def __init__(self, cond):
        super().__init__(name="小爱")
        self.cond = cond

    def run(self):
        with self.cond:
            self.cond.wait()
            print("{} : 在 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 好啊 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 君住长江尾 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 共饮长江水 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 此恨何时已 ".format(self.name))
            self.cond.notify()

            self.cond.wait()
            print("{} : 定不负相思意 ".format(self.name))
            self.cond.notify()

class TianMao(threading.Thread):
    def __init__(self, cond):
        super().__init__(name="天猫精灵")
        self.cond = cond

    def run(self):
        with self.cond:
            print("{} : 小爱同学 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 我们来对古诗吧 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 我住长江头 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 日日思君不见君 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 此水几时休 ".format(self.name))
            self.cond.notify()
            self.cond.wait()

            print("{} : 只愿君心似我心 ".format(self.name))
            self.cond.notify()
            self.cond.wait()


if __name__ == "__main__":
    cond = threading.Condition()
    xiaoai = XiaoAi(cond)
    tianmao = TianMao(cond)

    #启动顺序很重要
    #在调用with cond之后才能调用wait或者notify方法
    #condition有两层锁， 一把底层锁会在线程调用了wait方法的时候释放， 上面的锁会在每次调用wait的时候分配一把并放入到cond的等待队列中，等到notify方法的唤醒
    xiaoai.start()
    tianmao.start()
```

### Semaphore

信号量是一个由操作系统管理的抽象数据类型，用于同步多个线程对共享资源与数据。本质上，信号量是由一个内部变量构成，它标识出了对其所关联的资源的并发访问量。

当一个线程想要访问与一个信号量所关联的资源时，它必须调用`acquire()`操作，该操作会使信号量的内部变量值-1，如果值为非负数，那么就允许访问资源。如果值为负数，则线程就会挂起，同时等待另一个线程释放该资源。

当一个线程使用完数据或是共享资源，它必须通过`release()`操作释放资源。通过这种方式，信号量的内部变量会+1，信号量队列中的第一个等待线程就可以访问共享资源了。

信号量机制可以正常工作的前提是等待与信号操作要在原子块中执行，若不是这样，就会导致异常。适用于需要控制特定资源的并发访问线程数量的场合。

Semaphore对象可以调用任意次release()方法，而BoundedSemaphore对象可以保证计数器的值不超过特定的值。与Lock/RLock、Condition对象一样，也支持上下文管理协议，支持with关键字

信号量的一种特别实用方式是互斥锁，互斥指的是内部变量的初始化值为1的信号量，它可以实现对数据与资源访问的互斥操作。不过使用信号量会导致死锁的发生。

- Semaphore

方法

```python
acquire(blocking=True, timeout=None)

# 获取信号。
# 当blocking=True时：如果调用时计数器大于零，则将其减1并立即返回。如果在调用时计数器为零，则阻塞并等待，直到其他线程调用release()使其大于零。这是通过适当的互锁来完成的，因此如果多个acquire()被阻塞，release()将只唤醒其中一个，这个过程会随机选择一个，因此不应该依赖阻塞线程的被唤醒顺序。返回值为True。
# 当blocking=False时，不会阻塞。如果调用acquire()时计数器为零，则会立即返回False.如果设置了timeout参数，它将阻塞最多timeout秒。如果在该时间段内没有获取锁，则返回False，否则返回True。

release()
# 释放信号，使计数器递增1。当计数器为零并有另一个线程等待计数器大于零时，唤醒该线程。
```

示例1

```python
# 实现线程交替等待
# coding:utf8
import threading
import time
import random

# 可选参数为内部变量counter赋予了初始值
# 其默认值为1
# 若赋的值小于0，就会导致ValueError
semaphore = threading.Semaphore(0)

def consumer():
    print("consumer is waiting")
    # 获取到信号量
    semaphore.acquire()
    # 消费者访问共享资源
    print("Consumer notify: consumed item number %s " % item)

def producer():
    global item
    time.sleep(10)
    # 创建一个随机数
    item = random.randint(0, 1000)
    print('producer notify: produced item number %s' % item)
    # 释放信号量，将内部的counter值加1。
    # 当其值=0，另一个线程就会再次等待它的值变为大于0，并唤醒该线程
    semaphore.release()

if __name__ == "__main__":    
    for i in range(0, 5):
        t1 = threading.Thread(target=producer)
        t2 = threading.Thread(target=consumer)
        t1.start()
        t2.start()
        t1.join()
        t2.join()
    print('Program terminated')
```

示例2

```python
# 实现同一时间段只有有限个线程访问
import time
import threading

s1=threading.Semaphore(5)	#添加一个计数器

def foo():
	s1.acquire()	#计数器获得锁
	time.sleep(2)	#程序休眠2秒
	print("ok",time.ctime())
	s1.release()	#计数器释放锁


for i in range(20):
	t1=threading.Thread(target=foo,args=())	#创建线程
	t1.start()	#启动线程
```

- BoundedSemaphore

方法

```python
BoundedSemaphore(value=1)
# 实现有界信号对象。有界信号对象确保计数器不超过初始值value，否则抛出ValueError。
# 大多数情况下，该对象用于保护有限容量的资源。
```

代码

```python
# coding:utf8
import threading
import time

def worker():
    with sema:
        print(time.ctime())
        time.sleep(3)

# 同一时刻最多允许2个线程访问特定资源
sema = threading.BoundedSemaphore(2)

for i in range(10):
    t = threading.Thread(target=worker)
    t.start()
```

### with

当有两个相关的操作需要对一个代码块成对执行时，可以借助with语句，来精确地分配和释放资源。

在多线程中可以使用with语句的对象为：Lock,RLock,Condition,Semaphore

```python
# coding:utf8
import threading
import logging

logging.basicConfig(level=logging.DEBUG, format='(%(threadName)-10s) %(message)s',)

def threading_with(statement):
    """带with语句"""
    with statement:
        logging.debug('%s acquired via with' % statement)

def threading_not_with(statement):
    """不带with语句"""
    statement.acquire()
    try:
        logging.debug('%s acquired directly' % statement)
    finally:
        statement.release()

if __name__ == "__main__":
    # 创建一个测试集合
    lock = threading.Lock()
    rlock = threading.RLock()
    condition = threading.Condition()
    mutex = threading.Semaphore(1)
    threading_synchronization_list = [lock, rlock, condition, mutex]

    # 在for循环中，调用threading_with与threading_no_with函数
    for statement in threading_synchronization_list:
        t1 = threading.Thread(target=threading_with, args=(statement,))
        t2 = threading.Thread(target=threading_not_with, args=(statement,))
        t1.start()
        t2.start()
        t1.join()
        t2.join()
```

### Event

事件是用于线程间通信的对象。一个线程会等待信号，同时另一个线程会发出信号。基本上，事件对象会管理一个内部标志，可以通过`set()`将其设置为true，也可以通过`clear()`将其重制为false。`wait()`方法会一直阻塞，直到标志变为true为止。

Event对象的方法

```python
set()
# 设置Event对象内部的信号标志为真
clear()
# 清除Event对象内部的信号标志，将其设置为假
isSet()
# 判断其内部信号标志状态
wait()
# 在其内部信号状态为真时立即执行并返回，若Event对象的内部标志为假，就一直等待至超时或内部信号标志为真
```

代码

```python
import threading

# 自定义线程类
class mythread(threading.Thread):
    def __init__(self, threadname):
        threading.Thread.__init__(self, name=threadname)

    def run(self):
        global myevent
        # 根据Event对象是否已设置做出不同的响应
        if myevent.isSet():
            # 清除标志
            myevent.clear()
            # 等待
            myevent.wait()
            print(self.getName() + ' set')
        else:
            print(self.getName() + ' not set')
            # 设置标志
            myevent.set()

myevent = threading.Event()
# 设置标志
myevent.set()

for i in range(10):
    t = mythread(str(i))
    t.start()
```

示例2

```python
# coding:utf8
from threading import Thread, Event
import time
import random

items = []
event = Event()

class Consumer(Thread):
    def __init__(self, items, event):
        Thread.__init__(self)
        self.items = items
        self.event = event

    def run(self):
        while True:
            time.sleep(2)
            self.event.wait()
            item = self.items.pop()
            print('Consumer notify: %d poped from list by %s' % (item, self.name))


class Producer(Thread):
    def __init__(self, items, event):
        Thread.__init__(self)
        self.items = items
        self.event = event

    def run(self):
        global items
        for i in range(100):
            time.sleep(2)
            item = random.randint(0, 256)
            self.items.append(item)
            print('Producer notify: item N %d appended to list by %s' %(item, self.name))
            print('Producer notify: event set by %s' % self.name)
            self.event.set()
            print('Produce notify: event cleared by %s \n' % self.name)
            self.event.clear()

if __name__ == "__main__":
    producer = Producer(items, event)
    consumer = Consumer(items, event)
    producer.start()
    consumer.start()
    producer.join()
    consumer.join()
```

### Queue

虽然python线程模块提供了很多同步原语，包括信号量、条件变量、事件与锁，但是使用队列模块可能是一个最佳方式。队列使用起来很容易，并且使得线程编程更加安全，因为它们会对单个线程对资源的所有访问进行过滤，并且支持更加整洁且可读性更棒的设计模式。

Queue 模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列 PriorityQueue。

这些队列都实现了锁原语，能够在多线程中直接使用，可以使用队列来实现线程间的同步。

队列分类

| 类                           | 原理     | 说明                       |
| ---------------------------- | -------- | -------------------------- |
| Queue.Queue(maxsize)         | 双向列表 | FIFO(先进先出队列)         |
| Queue.LifoQueue(maxsize)     | list     | LIFO(后进先出)             |
| Queue.PriorityQueue(maxsize) | 堆       | 优先级队列(优先度低的先出) |

常用方法

| 方法                                   | 说明                                                         |
| -------------------------------------- | ------------------------------------------------------------ |
| `__init__(self, maxsize=0)`            | 初始化队列长度，maxsize为0时长度无限                         |
| `empty()`                              | 若队列为空，返回True，反之False                              |
| `full()`                               | 若队列满了，返回True，反之False                              |
| `qsize()`                              | 返回队列的大小(并不可靠)                                     |
| `get([block][,timeout])`               | 从队头获取并删除元素<br>block为true：timeout为None时候，阻塞当前线程直到队列中有可用元素；timeout为非负时候，等了timeout的时间还没有可用元素时候抛出一个Empty异常；<br>block为false：timeout为None时候，队列为空则抛出Empty异常；timeout为非负时候，等待timeout时候后没有可用元素则抛出Empty异常 |
| `get_nowait()`                         | 相当于Queue.get(False)                                       |
| ` put(item, block=True, timeout=None)` | 在队尾插入一个元素<br>block为true：timeout为None时候，阻塞当前线程直到队列中有可用位置；timeout为非负时候，等了timeout时间还没有可用位置时候抛出一个Full异常；<br>block为false：timeout为None时候，队列没有位置则抛出Full异常；timeout为非负时候，等待timeout时候后还是没有可用位置则抛出Full异常 |
| `put_nowait(item)`                     | 相当于Queue.put(item,False)                                  |
| `join()`                               | 阻塞当前线程直到队列的任务全部完成了                         |
| `task_done()`                          | 通知队列任务的完成情况，当完成时候唤醒被join阻塞的线程       |

> 样例

Demo1

```python
import threading,time,queue


q = queue.Queue()

def producer():
    n = 0
    while n < 5:
        n += 1
        q.put(n)
        print('Producer has created %s' % n)
        time.sleep(0.1)
        
def consumer():
    count = 0
    while count < 5:
        count += 1
        data = q.get()
        print('consumer has uses %s' % data)
        time.sleep(0.2)
    
if __name__ == "__main__":
    p = threading.Thread(target=producer, name='')
    c = threading.Thread(target=consumer, name='')
    p.start()
    c.start()
    p.join()
    c.join()
```

Demo2

```python
import threading,time,queue


class myThread (threading.Thread):
    def __init__(self, threadID, name, q):
        threading.Thread.__init__(self)
        self.threadID = threadID
        self.name = name
        self.q = q
    def run(self):
        print ("开启线程：" + self.name)
        process_data(self.name, self.q)
        print ("退出线程：" + self.name)

def process_data(threadName, q):
    while not exitFlag:
        queueLock.acquire()
        if not workQueue.empty():
            data = q.get()
            queueLock.release()
            print ("%s processing %s" % (threadName, data))
        else:
            queueLock.release()
        time.sleep(1)
        
def main():
    global exitFlag
	exitFlag = 0
	threadList = ["Thread-1", "Thread-2", "Thread-3"]
	nameList = ["One", "Two", "Three", "Four", "Five"]
	threads = []
	threadID = 1

	# 创建新线程
	for tName in threadList:
    	thread = myThread(threadID, tName, workQueue)
    	thread.start()
    	threads.append(thread)
    	threadID += 1

	# 填充队列
	queueLock.acquire()
	for word in nameList:
    	workQueue.put(word)
	queueLock.release()

	# 等待队列清空
	while not workQueue.empty():
    	pass

	# 通知线程是时候退出
	exitFlag = 1

	# 等待所有线程完成
	for t in threads:
    	t.join()
	print ("退出主线程")

if __name__ == "__main__":
    queueLock = threading.Lock()
	workQueue = queue.Queue(10)
    mian()

************************************
开启线程：Thread-1
开启线程：Thread-2
开启线程：Thread-3
Thread-3 processing One
Thread-1 processing Two
Thread-2 processing Three
Thread-3 processing Four
Thread-1 processing Five
退出线程：Thread-3
退出线程：Thread-2
退出线程：Thread-1
退出主线程
```

Demo3

```python
import threading
import time
import queue


# 自定义生产者线程类
class Producer(threading.Thread):
    def __init__(self, threadname):
        threading.Thread.__init__(self,name=threadname)

    def run(self):
        global myqueue
        # 在队尾追加元素
        time.sleep(1)
        try:
            myqueue.put(self.getName(), timeout=1)
            print(self.getName(), 'put ', self.getName(), ' to queue.')
        except:
            pass

# 自定义消费者线程类
class Consumer(threading.Thread):
    def __init__(self, threadname):
        threading.Thread.__init__(self,name=threadname) 

    def run(self):
        global myqueue
        # 在队列首部获取元素
        time.sleep(0.1)
        try:
            print(self.getName, 'get ', myqueue.get(timeout=1.1), 'from queue.')
        except:
            pass

# 创建双线列表
myqueue = queue.Queue(5)
# 创建生产者消费者线程
plist = []
clist = []
for i in range(10):
    p = Producer('Producer' + str(i))
    plist.append(p)
    c = Consumer('Consumer' + str(i))
    clist.append(c)
# 依次启动生产者消费者线程
for p, c in zip(plist, clist):
    p.start()
    c.start()
```

demo4

```python
from threading import Thread, Event
from queue import Queue
import time
import random

class Producer(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue

    def run(self):
        for i in range(10):
            item = random.randint(0, 256)
            # 向队列中插入数据
            self.queue.put(item)
            print('Producer notify: item N %d appended to queue by %s \n' % (item, self.name))
            time.sleep(1)

class Consumer(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue

    def run(self):
        while True:
            # 从队列中获取整数
            item = self.queue.get()
            print('Consumer notify: %d poped from queue by %s' % (item, self.name))
            # 标识开始对其处理
            self.queue.task_done()

if __name__ == '__main__':
    queue = Queue()
    t1 = Producer(queue)
    t2 = Consumer(queue)
    t3 = Consumer(queue)
    t4 = Consumer(queue)
    t1.start()
    t2.start() 
    t3.start()
    t4.start()
    t1.join()
    t2.join()
    t3.join()
    t4.join()
```

### Barrier

Barrier对象常用来实现这样的线程同步，多个线程运行到某个时间点以后每个线程都需要等着其他线程都准备好以后再同时进行下一步动作。

```python
import threading
import random
import time

def worker(arg):
    # 假设每个线程需要不同的时间来完成准备工作
    time.sleep(random.randint(1,20))
    # 假设已知任何线程的准备工作最多需要20s
    # 每个线程调用wait()时，返回值不一样
    r = b.wait(20)
    if r == 0:
        print(arg)

def printOk():
    print('ok')

# 允许3个线程等待
# 如果线程调用wait()时没有指定超时时间，默认20s
b = threading.Barrier(parties=3,action=printOk, timeout=20)

# 创建并启动3个线程，线程数量必须与Barrier对象的parties一致
for i in range(3):
    t = threading.Thread(target=worker, args=(1,))
    t.start()
```

服务器启动需要一定的时间，在服务器做好准备工作之前不允许客户端发起连接请求

```python
import threading
import random
import time

b = threading.Barrier(2,timeout=5)

def server():
    # 启动服务器，准备接受客户端连接，代码略
    b.wait()
    while True:
        # 接收客户端连接，处理客户端请求，代码略
        pass

def client():
    # 等待服务器启动
    b.wait()
    while True:
        # 建立连接，和服务器进行通信
        pass

# 分别创建并启动服务器线程和客户端线程
threading.Thread(target=server).start()
threading.Thread(target=client).start()
```

## threadlocal

在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁。

一个`ThreadLocal`变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。`ThreadLocal`解决了参数在一个线程中各个函数之间互相传递的问题。

`ThreadLocal`最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。

```python
# 在函数调用的时候，传递起来很麻烦：
def process_student(name):
    std = Student(name)
    # std是局部变量，但是每个函数都要用它，因此必须传进去：
    do_task_1(std)
    do_task_2(std)

def do_task_1(std):
    do_subtask_1(std)
    do_subtask_2(std)

def do_task_2(std):
    do_subtask_2(std)
    do_subtask_2(std)
    

# 用一个全局dict存放所有的Student对象，然后以thread自身作为key获得线程对应的Student对象
global_dict = {}

def std_thread(name):
    std = Student(name)
    # 把std放到全局变量global_dict中：  
    global_dict[threading.current_thread()] = std
    do_task_1()
    do_task_2()

def do_task_1():
    # 不传入std，而是根据当前线程查找：
    std = global_dict[threading.current_thread()]
    ...

def do_task_2():
    # 任何函数都可以查找出当前线程的std变量：
    std = global_dict[threading.current_thread()]
    ...
```

全局变量`local_school`就是一个`ThreadLocal`对象，每个`Thread`对它都可以读写`student`属性，但互不影响。你可以把`local_school`看成全局变量，但每个属性如`local_school.student`都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，`ThreadLocal`内部会处理。

可以理解为全局变量`local_school`是一个`dict`，不但可以用`local_school.student`，还可以绑定其他变量，如`local_school.teacher`等等。

```python
import threading

# 创建全局ThreadLocal对象:
local_school = threading.local()

def process_student():
    # 获取当前线程关联的student:
    std = local_school.student
    print('Hello, %s (in %s)' % (std, threading.current_thread().name))

def process_thread(name):
    # 绑定ThreadLocal的student:
    local_school.student = name
    process_student()

t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')
t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()
```

## 多线程版UDP聊天器

```python
import socket
import threading


def send_msg(udp_socket):
    """获取键盘数据，并将其发送给对方"""
    while True:
        # 1. 从键盘输入数据
        msg = input("\n请输入要发送的数据:")
        # 2. 输入对方的ip地址
        dest_ip = input("\n请输入对方的ip地址:")
        # 3. 输入对方的port
        dest_port = int(input("\n请输入对方的port:"))
        # 4. 发送数据
        udp_socket.sendto(msg.encode("utf-8"), (dest_ip, dest_port))


def recv_msg(udp_socket):
    """接收数据并显示"""
    while True:
        # 1. 接收数据
        recv_msg = udp_socket.recvfrom(1024)
        # 2. 解码
        recv_ip = recv_msg[1]
        recv_msg = recv_msg[0].decode("utf-8")
        # 3. 显示接收到的数据
        print(">>>%s:%s" % (str(recv_ip), recv_msg))


def main():
    # 1. 创建套接字
    udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    # 2. 绑定本地信息
    udp_socket.bind(("", 7890))

    # 3. 创建一个子线程用来接收数据
    t = threading.Thread(target=recv_msg, args=(udp_socket,))
    t.start()
    # 4. 让主线程用来检测键盘数据并且发送
    send_msg(udp_socket)

if __name__ == "__main__":
    main()

```

## 多进程与多线程

一般情况多进程的内存资源是相互独立，多线程可以共享一个进程中的内存资源

```python
from multiprocessing import Process
import threading
import time

lock = threading.Lock()

def run(info_list, n):
  	lock.acquire()
    info_list.append(n)
    lock.release()
    print('%s\n'%info_list)
    
if __name__=='__main__':
  	info = []
    for i in range(10):
      	p = Process(target=run ,args=[info, i])
        p.start()
        p.join()
    time.sleep(1) # 为了输出整齐让主进程的执行等一下子进程
    print('----threading----')
    for i in range(10):
      p = threading.Thread(target=run, args=[info, i])
      p.start()
      p.join()
```

